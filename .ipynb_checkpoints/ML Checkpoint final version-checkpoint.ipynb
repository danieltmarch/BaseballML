{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriented-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-theater",
   "metadata": {},
   "source": [
    "## Table for data entries and abbreviations\n",
    "\n",
    "#### Batting Data: G AB R H 2B 3B HR RBI BB IBB SO HBP SH SF XI ROE GDP SB CS AVG OBP SLG HAND\n",
    "\n",
    "0: G: Games, total game played <br/>\n",
    "1: AB: At bat, Total times at bat <br/>\n",
    "2: R: Runs, total runs scored <br/>\n",
    "3: H: Hits, total fair play hits <br/>\n",
    "4: 2B: Double, reaching 2nd base from batting <br/>\n",
    "5: 3B: Triple, reaching 3rd base from batting <br/>\n",
    "6: HR: Home run, scoring straight from batting (includes in field home runs) <br/>\n",
    "7: RBI: Runs batted in, total runs from this player's at bat <br/>\n",
    "8: BB: Walks, total times walked (includes intentional walks) <br/>\n",
    "9: IBB: Intentional Walk, intentionally walking batter to first base <br/>\n",
    "10: SO: Strike out, total times struck out at base <br/>\n",
    "11: HBP: Hit by pitch, total times <br/>\n",
    "12: SH: Sacrifice bunt, bunt resulting in the batter being out but advances another runner <br/>\n",
    "13: SF: Sacrifice fly, fly ball resulting in the batter being out but advances another runner <br/>\n",
    "14: XI: ?, (almost all players have 0 for this statistic) <br/>\n",
    "15: ROE: Reached on error, total times on base due to an error <br/>\n",
    "16: GDP: Grounded into double play <br/>\n",
    "17: SB: Stolen base, total bases stolen <br/>\n",
    "18: CS: Caught stealing, Total times getting out when stealing.<br/>\n",
    "19: AVG: Batting average, (total hits / total at bats) <br/>\n",
    "20: OBP: On base percentage, (total times on base / total at bats) <br/>\n",
    "21: SLG: Slugging percentage, bases per at bat ((1B + 2*2B + 3*3B + 4*HR) / AB) <br/>\n",
    "22: HAND: Handedness, batting hand (1 = right, -1 = left) <br/>\n",
    "\n",
    "\n",
    "\n",
    "#### Pitching Data: G GS CG SHO GF SV IP H BFP HR R ER BB IB SO SH SF WP HBP BK 2B 3B GDP ROE W L ERA RS PW HAND\n",
    "\n",
    "0: G: Games played, total games played <br/>\n",
    "1: GS: Games Started, threw the first pitch <br/>\n",
    "2: CG: Complete game, pitched for the entire game <br/>\n",
    "3: SHO: Shutout, pitches entire game without opposition scoring <br/>\n",
    "4: GF: Games Finished, threw the last pitch (not counted if there was only 1 pitcher for the game) <br/>\n",
    "5: SV: save, relief pitcher resulting in a win under certain conditions, https://www.mlb.com/glossary/standard-stats/save <br/>\n",
    "6: IP: Innings pitched, total innings pitched (can be partial) <br/>\n",
    "7: H: Hits, total hits allowed <br/>\n",
    "8: BFP: Total batters face, total batters at plate when pitching <br/>\n",
    "9: HR: Home runs allowed <br/>\n",
    "10: R: Runs allowed?, total runs allowed <br/>\n",
    "11: ER: Earned Run, total runs scored by the opposition due to the pitcher <br/>\n",
    "12: BB: Walk, total walks <br/>\n",
    "13: IB: Intentional walk? <br/>\n",
    "14: SO: Strikeout, total batters struck out <br/>\n",
    "15: SH: Sacrifice bunt, bunt resulting in the batter being out but advances another runner <br/>\n",
    "16: SF: Sacrifice fly, fly ball resulting in the batter being out but advances another runner <br/>\n",
    "17: WP: Wild pitches, pitch out of range for the catcher causing a runner to advance <br/>\n",
    "18: HBP: Hit by pitch?, times batter is hit by a pitch <br/>\n",
    "19: BK: Balk, number of illegal actions <br/>\n",
    "20: 2B: Doubles allowed <br/>\n",
    "21: 3B: Triples allowed <br/>\n",
    "22: GDP: Grounded double plays? <br/>\n",
    "23: ROE: Reached on error?, number of batters on base due to an error <br/>\n",
    "24: W: Win, pitched while their team took the team and won the game <br/>\n",
    "25: L: Loss, pitched while their team lost the lead and lost the game <br/>\n",
    "26: ERA: Earned run average, (allowed runs * 9 / innings pitched ) <br/>\n",
    "27: RS: Run support?, average opposition score (per game, not per inning) <br/>\n",
    "28: PW: Total player rating, linear weighting of multiple statistics, https://en.wikipedia.org/wiki/Total_player_rating <br/>\n",
    "29: HAND: Handedness, Pitching hand (1 = right, -1 = left) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optimum-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromFile(fileName, pitchingDataList, battingDataList):\n",
    "    fileData=np.loadtxt(fileName, delimiter=',') \n",
    "    [N,dim]=np.shape(fileData) #set up matrix from file\n",
    "    \n",
    "    fileX = np.zeros((N, dim))\n",
    "    dataY = np.zeros((N))\n",
    "    \n",
    "    fileX = fileData[:, 0:dim - 1] #remove output from the x array\n",
    "    dataY[:] = fileData[:, dim - 1]\n",
    "    \n",
    "    dataX = np.zeros((N, 2*len(pitchingDataList) + 18*len(battingDataList)))\n",
    "    dataXIndex = 0\n",
    "    for i in pitchingDataList: #add data for home pitcher\n",
    "        dataX[:,dataXIndex] = fileX[:,i]\n",
    "        dataXIndex = dataXIndex + 1\n",
    "    for i in range(9): #add data for home batters\n",
    "        for j in battingDataList:\n",
    "            dataX[:,dataXIndex] = fileX[:,(30 + 23*i + j)]\n",
    "            dataXIndex = dataXIndex + 1\n",
    "    for i in pitchingDataList: #add data for away pitcher\n",
    "        dataX[:,dataXIndex] = fileX[:,(30 + 23*9 + i)]\n",
    "        dataXIndex = dataXIndex + 1\n",
    "    for i in range(9): #add data for away batters\n",
    "        for j in battingDataList:\n",
    "            dataX[:,dataXIndex] = fileX[:,(2*30 + 23*(9+i) + j)]\n",
    "            dataXIndex = dataXIndex + 1\n",
    "    \n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanAndStd(data): #get the mean and standard deviation of data columns\n",
    "    means = [] #mean for each column\n",
    "    stds = [] #standard deviation for each column\n",
    "    for i in range(np.shape(data)[1]):\n",
    "        mean = sum(data[:,i]) / len(data) \n",
    "        means.append(mean)\n",
    "        stds.append( np.sqrt( sum((mean - data[:,i])**2)/len(data)) )\n",
    "    return means, stds\n",
    "\n",
    "def applyMeanAndStd(data, means, stds):\n",
    "    newData = data\n",
    "    for i in range(np.shape(newData)[1]):\n",
    "        newData[:,i] = (data[:,i] - means[i])/stds[i] #normalize so that mean = 0, std = 1\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "drawn-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structureGameData(gameData, batSize, pitSize): #take a single game and break into 2 pitching lists and 18 batting lists\n",
    "    index = 0\n",
    "    game = []\n",
    "    game.append(gameData[index : index + pitSize]) #add home pitcher\n",
    "    index = index + pitSize\n",
    "    for i in range(9): #add home batters\n",
    "        game.append(gameData[index : index + batSize])\n",
    "        index = index + batSize\n",
    "    game.append(gameData[index : index + pitSize]) #add away pitcher\n",
    "    index = index + pitSize\n",
    "    for i in range(9): #add away batters\n",
    "        game.append(gameData[index : index + batSize])\n",
    "        index = index + batSize\n",
    "    \n",
    "    return game\n",
    "\n",
    "# WARNING: this function is specific to the current data lists, if the list changes the function should as well\n",
    "def reformatGameData(games, batData, pitData):\n",
    "    newGames = np.zeros((len(games), np.shape(games)[1] - 1*20)) #drop 20 per entry since we remove at bats and inning pitched\n",
    "    \n",
    "    pitSize = len(pitData)\n",
    "    batSize = len(batData)\n",
    "\n",
    "    for gameNum in range(len(games)):\n",
    "        game = games[gameNum]\n",
    "        gameStruct = structureGameData(game, batSize, pitSize)\n",
    "        \n",
    "        for batter in range(1 + 0, 1 + 9): #for each home batter\n",
    "            for i in range(1, 10): #all data points except: at bats, bat avr%, hand will be divided by the # of at bats\n",
    "                if(gameStruct[batter][0] != 0):\n",
    "                    gameStruct[batter][i] = gameStruct[batter][i] / gameStruct[batter][0]\n",
    "        for batter in range(11 + 0, 11 + 9): #for each away batter\n",
    "            for i in range(1, 10): #all data points except: at bats, bat avr%, hand will be divided by the # of at bats\n",
    "                if(gameStruct[batter][0] != 0):\n",
    "                    gameStruct[batter][i] = gameStruct[batter][i] / gameStruct[batter][0]\n",
    "                \n",
    "        for i in range(1,7): #for home and away pitcher\n",
    "            if(gameStruct[0][0] != 0):\n",
    "                gameStruct[0][i] = gameStruct[0][i] / gameStruct[0][0]\n",
    "            if(gameStruct[10][0] != 0):\n",
    "                gameStruct[10][i] = gameStruct[10][i] / gameStruct[10][0]\n",
    "        \n",
    "        for i in range(len(gameStruct)): #throw away the first element of each list (either at bats, or innings pitched)\n",
    "            gameStruct[i] = gameStruct[i][1:]\n",
    "        flatGameStruct = []\n",
    "        for elem in gameStruct: #flatten out list of lists\n",
    "            for elem2 in elem: #list elements of list\n",
    "                flatGameStruct.append(elem2)\n",
    "        \n",
    "        newGames[gameNum] = np.asarray(flatGameStruct) #flatten out since gameStruct is a list of lists\n",
    "    return newGames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "unavailable-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\train.txt\"\n",
    "valFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\val.txt\"\n",
    "#testFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\test.txt\"\n",
    "\n",
    "batDataList = [1, 3, 4, 5, 6, 7, 9, 10, 17, 18, 19, 22] \n",
    "# at bats, hits, doubles, triples, home runs, rbi, intentional walks, strike outs, stolen bases, \n",
    "#...times caught stealing, batting avr %, handedness\n",
    "\n",
    "#batDataList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22] #all parameters\n",
    "\n",
    "pitDataList = [6, 7, 20, 21, 9, 10, 14, 29] \n",
    "#innings pitched, hits allowed, doubles allowed, triples allowed, home runs allowed, runs allowed, strikeouts, handedness\n",
    "#pitDataList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29] #all parameters\n",
    "\n",
    "trainX, trainY = getDataFromFile(trainFileName, pitDataList, batDataList) # ~ 32000 examples\n",
    "valX, valY = getDataFromFile(valFileName, pitDataList, batDataList) #8000 examples\n",
    "#testX, testY = getDataFromFile(testFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "prostate-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat data\n",
    "trainX = reformatGameData(trainX, batDataList, pitDataList)\n",
    "valX = reformatGameData(valX, batDataList, pitDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "addressed-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "dataMeans, dataStds = getMeanAndStd(trainX)\n",
    "trainX = applyMeanAndStd(trainX, dataMeans, dataStds)\n",
    "valX = applyMeanAndStd(valX, dataMeans, dataStds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-stephen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "super-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(trainX, trainY, testX, testY, model, epochCount): #run and graph model results\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    historyData = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=epochCount, verbose = 1)\n",
    "    eIn = historyData.history[\"accuracy\"]\n",
    "    eOut = historyData.history[\"val_accuracy\"]\n",
    "    \n",
    "    for i in range(len(eIn)):\n",
    "        eIn[i] = 1-eIn[i]\n",
    "    for i in range(len(eOut)):\n",
    "        eOut[i] = 1-eOut[i]\n",
    "\n",
    "    print('Train error:', eIn[-1])\n",
    "    print('Test error: ', eOut[-1])\n",
    "    \n",
    "    #return error data to be plot later\n",
    "    return eIn, eOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "caroline-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1018/1018 [==============================] - 4s 3ms/step - loss: 0.8021 - accuracy: 0.5225 - val_loss: 0.7447 - val_accuracy: 0.5493\n",
      "Epoch 2/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.7386 - accuracy: 0.5568 - val_loss: 0.7292 - val_accuracy: 0.5680\n",
      "Epoch 3/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.7275 - accuracy: 0.5587 - val_loss: 0.7185 - val_accuracy: 0.5559\n",
      "Epoch 4/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.7125 - accuracy: 0.5685 - val_loss: 0.7056 - val_accuracy: 0.5696\n",
      "Epoch 5/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.7027 - accuracy: 0.5651 - val_loss: 0.6988 - val_accuracy: 0.5630\n",
      "Epoch 6/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6969 - accuracy: 0.5605 - val_loss: 0.6914 - val_accuracy: 0.5646\n",
      "Epoch 7/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6901 - accuracy: 0.5644 - val_loss: 0.6878 - val_accuracy: 0.5669\n",
      "Epoch 8/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6864 - accuracy: 0.5693 - val_loss: 0.6877 - val_accuracy: 0.5605\n",
      "Epoch 9/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6849 - accuracy: 0.5718 - val_loss: 0.6861 - val_accuracy: 0.5649\n",
      "Epoch 10/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6835 - accuracy: 0.5699 - val_loss: 0.6854 - val_accuracy: 0.5645\n",
      "Epoch 11/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6818 - accuracy: 0.5709 - val_loss: 0.6857 - val_accuracy: 0.5621\n",
      "Epoch 12/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6849 - accuracy: 0.5693 - val_loss: 0.6848 - val_accuracy: 0.5641\n",
      "Epoch 13/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6812 - accuracy: 0.5722 - val_loss: 0.6841 - val_accuracy: 0.5645\n",
      "Epoch 14/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6818 - accuracy: 0.5704 - val_loss: 0.6846 - val_accuracy: 0.5656\n",
      "Epoch 15/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6819 - accuracy: 0.5740 - val_loss: 0.6847 - val_accuracy: 0.5688\n",
      "Epoch 16/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5702 - val_loss: 0.6852 - val_accuracy: 0.5679\n",
      "Epoch 17/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.5731 - val_loss: 0.6856 - val_accuracy: 0.5619\n",
      "Epoch 18/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6817 - accuracy: 0.5762 - val_loss: 0.6838 - val_accuracy: 0.5655\n",
      "Epoch 19/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5753 - val_loss: 0.6852 - val_accuracy: 0.5638\n",
      "Epoch 20/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6815 - accuracy: 0.5750 - val_loss: 0.6865 - val_accuracy: 0.5611\n",
      "Epoch 21/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6842 - accuracy: 0.5680 - val_loss: 0.6848 - val_accuracy: 0.5573\n",
      "Epoch 22/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6818 - accuracy: 0.5687 - val_loss: 0.6840 - val_accuracy: 0.5654\n",
      "Epoch 23/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6822 - accuracy: 0.5668 - val_loss: 0.6841 - val_accuracy: 0.5679\n",
      "Epoch 24/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5748 - val_loss: 0.6841 - val_accuracy: 0.5640\n",
      "Epoch 25/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5784 - val_loss: 0.6837 - val_accuracy: 0.5663\n",
      "Epoch 26/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6815 - accuracy: 0.5694 - val_loss: 0.6832 - val_accuracy: 0.5707\n",
      "Epoch 27/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5735 - val_loss: 0.6847 - val_accuracy: 0.5676\n",
      "Epoch 28/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6815 - accuracy: 0.5752 - val_loss: 0.6833 - val_accuracy: 0.5673\n",
      "Epoch 29/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5689 - val_loss: 0.6835 - val_accuracy: 0.5631\n",
      "Epoch 30/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5767 - val_loss: 0.6870 - val_accuracy: 0.5641: 0s - loss:\n",
      "Epoch 31/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6843 - accuracy: 0.5679 - val_loss: 0.6842 - val_accuracy: 0.5659\n",
      "Epoch 32/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5732 - val_loss: 0.6846 - val_accuracy: 0.5674\n",
      "Epoch 33/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6814 - accuracy: 0.5698 - val_loss: 0.6842 - val_accuracy: 0.5673\n",
      "Epoch 34/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6814 - accuracy: 0.5699 - val_loss: 0.6850 - val_accuracy: 0.5629\n",
      "Epoch 35/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5775 - val_loss: 0.6838 - val_accuracy: 0.5660\n",
      "Epoch 36/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5740 - val_loss: 0.6838 - val_accuracy: 0.5689\n",
      "Epoch 37/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6827 - accuracy: 0.5694 - val_loss: 0.6855 - val_accuracy: 0.5644\n",
      "Epoch 38/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6825 - accuracy: 0.5732 - val_loss: 0.6836 - val_accuracy: 0.5701\n",
      "Epoch 39/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5737 - val_loss: 0.6864 - val_accuracy: 0.5649\n",
      "Epoch 40/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5761 - val_loss: 0.6838 - val_accuracy: 0.5698\n",
      "Epoch 41/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5740 - val_loss: 0.6840 - val_accuracy: 0.5646\n",
      "Epoch 42/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5750 - val_loss: 0.6920 - val_accuracy: 0.5446\n",
      "Epoch 43/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6814 - accuracy: 0.5711 - val_loss: 0.6856 - val_accuracy: 0.5615\n",
      "Epoch 44/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6817 - accuracy: 0.5723 - val_loss: 0.6837 - val_accuracy: 0.5696\n",
      "Epoch 45/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5747 - val_loss: 0.6839 - val_accuracy: 0.5655\n",
      "Epoch 46/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5737 - val_loss: 0.6851 - val_accuracy: 0.5642\n",
      "Epoch 47/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6821 - accuracy: 0.5695 - val_loss: 0.6842 - val_accuracy: 0.5676\n",
      "Epoch 48/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5735 - val_loss: 0.6858 - val_accuracy: 0.5656\n",
      "Epoch 49/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5717 - val_loss: 0.6839 - val_accuracy: 0.5670\n",
      "Epoch 50/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5705 - val_loss: 0.6836 - val_accuracy: 0.5641\n",
      "Epoch 51/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5806 - val_loss: 0.6838 - val_accuracy: 0.5701\n",
      "Epoch 52/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.5714 - val_loss: 0.6831 - val_accuracy: 0.5669\n",
      "Epoch 53/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5737 - val_loss: 0.6849 - val_accuracy: 0.5666\n",
      "Epoch 54/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.5717 - val_loss: 0.6834 - val_accuracy: 0.5655\n",
      "Epoch 55/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5719 - val_loss: 0.6851 - val_accuracy: 0.5680\n",
      "Epoch 56/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5705 - val_loss: 0.6839 - val_accuracy: 0.5639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5751 - val_loss: 0.6840 - val_accuracy: 0.5673\n",
      "Epoch 58/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5747 - val_loss: 0.6839 - val_accuracy: 0.5615\n",
      "Epoch 59/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5747 - val_loss: 0.6835 - val_accuracy: 0.5702\n",
      "Epoch 60/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5724 - val_loss: 0.6845 - val_accuracy: 0.5639\n",
      "Epoch 61/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5717 - val_loss: 0.6837 - val_accuracy: 0.5661\n",
      "Epoch 62/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5741 - val_loss: 0.6838 - val_accuracy: 0.5677\n",
      "Epoch 63/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6782 - accuracy: 0.5779 - val_loss: 0.6841 - val_accuracy: 0.5645\n",
      "Epoch 64/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5720 - val_loss: 0.6847 - val_accuracy: 0.5681\n",
      "Epoch 65/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6828 - accuracy: 0.5682 - val_loss: 0.6859 - val_accuracy: 0.5646\n",
      "Epoch 66/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6807 - accuracy: 0.5742 - val_loss: 0.6835 - val_accuracy: 0.5671\n",
      "Epoch 67/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6790 - accuracy: 0.5778 - val_loss: 0.6840 - val_accuracy: 0.5674\n",
      "Epoch 68/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5772 - val_loss: 0.6856 - val_accuracy: 0.5634\n",
      "Epoch 69/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5748 - val_loss: 0.6838 - val_accuracy: 0.5656\n",
      "Epoch 70/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5749 - val_loss: 0.6836 - val_accuracy: 0.5661\n",
      "Epoch 71/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5699 - val_loss: 0.6841 - val_accuracy: 0.5646\n",
      "Epoch 72/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5724 - val_loss: 0.6835 - val_accuracy: 0.5710\n",
      "Epoch 73/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6821 - accuracy: 0.5723 - val_loss: 0.6846 - val_accuracy: 0.5686\n",
      "Epoch 74/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5721 - val_loss: 0.6832 - val_accuracy: 0.5666\n",
      "Epoch 75/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5758 - val_loss: 0.6833 - val_accuracy: 0.5673\n",
      "Epoch 76/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5729 - val_loss: 0.6833 - val_accuracy: 0.5671\n",
      "Epoch 77/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6780 - accuracy: 0.5791 - val_loss: 0.6841 - val_accuracy: 0.5667\n",
      "Epoch 78/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5789 - val_loss: 0.6835 - val_accuracy: 0.5676\n",
      "Epoch 79/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6841 - accuracy: 0.5677 - val_loss: 0.6841 - val_accuracy: 0.5663\n",
      "Epoch 80/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5727 - val_loss: 0.6842 - val_accuracy: 0.56650s -\n",
      "Epoch 81/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5732 - val_loss: 0.6845 - val_accuracy: 0.5661\n",
      "Epoch 82/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5728 - val_loss: 0.6849 - val_accuracy: 0.5652\n",
      "Epoch 83/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5799 - val_loss: 0.6832 - val_accuracy: 0.5694\n",
      "Epoch 84/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6818 - accuracy: 0.5696 - val_loss: 0.6840 - val_accuracy: 0.5661\n",
      "Epoch 85/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6824 - accuracy: 0.5739 - val_loss: 0.6837 - val_accuracy: 0.5655\n",
      "Epoch 86/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5716 - val_loss: 0.6844 - val_accuracy: 0.5660\n",
      "Epoch 87/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5734 - val_loss: 0.6858 - val_accuracy: 0.5633\n",
      "Epoch 88/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6826 - accuracy: 0.5727 - val_loss: 0.6834 - val_accuracy: 0.5670\n",
      "Epoch 89/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6783 - accuracy: 0.5769 - val_loss: 0.6838 - val_accuracy: 0.5677\n",
      "Epoch 90/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5767 - val_loss: 0.6846 - val_accuracy: 0.5625\n",
      "Epoch 91/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5741 - val_loss: 0.6845 - val_accuracy: 0.5642\n",
      "Epoch 92/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6817 - accuracy: 0.5751 - val_loss: 0.6838 - val_accuracy: 0.5660\n",
      "Epoch 93/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5720 - val_loss: 0.6835 - val_accuracy: 0.5612\n",
      "Epoch 94/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5712 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 95/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6839 - accuracy: 0.5693 - val_loss: 0.6845 - val_accuracy: 0.5688\n",
      "Epoch 96/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5715 - val_loss: 0.6842 - val_accuracy: 0.5667\n",
      "Epoch 97/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5712 - val_loss: 0.6861 - val_accuracy: 0.5625\n",
      "Epoch 98/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5759 - val_loss: 0.6836 - val_accuracy: 0.5663\n",
      "Epoch 99/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5732 - val_loss: 0.6839 - val_accuracy: 0.5684\n",
      "Epoch 100/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5754 - val_loss: 0.6835 - val_accuracy: 0.5664\n",
      "Epoch 101/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5761 - val_loss: 0.6839 - val_accuracy: 0.5670\n",
      "Epoch 102/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5730 - val_loss: 0.6836 - val_accuracy: 0.5645\n",
      "Epoch 103/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6789 - accuracy: 0.5758 - val_loss: 0.6844 - val_accuracy: 0.5646\n",
      "Epoch 104/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.5709 - val_loss: 0.6834 - val_accuracy: 0.5681\n",
      "Epoch 105/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5707 - val_loss: 0.6859 - val_accuracy: 0.5646\n",
      "Epoch 106/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5714 - val_loss: 0.6843 - val_accuracy: 0.5677\n",
      "Epoch 107/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6804 - accuracy: 0.5736 - val_loss: 0.6844 - val_accuracy: 0.5680\n",
      "Epoch 108/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5784 - val_loss: 0.6836 - val_accuracy: 0.5684\n",
      "Epoch 109/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.5824 - val_loss: 0.6836 - val_accuracy: 0.5635\n",
      "Epoch 110/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5752 - val_loss: 0.6841 - val_accuracy: 0.5691\n",
      "Epoch 111/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6814 - accuracy: 0.5719 - val_loss: 0.6834 - val_accuracy: 0.5698\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5705 - val_loss: 0.6841 - val_accuracy: 0.5656\n",
      "Epoch 113/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5757 - val_loss: 0.6840 - val_accuracy: 0.5666\n",
      "Epoch 114/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5729 - val_loss: 0.6835 - val_accuracy: 0.5655\n",
      "Epoch 115/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5702 - val_loss: 0.6856 - val_accuracy: 0.5633\n",
      "Epoch 116/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5757 - val_loss: 0.6834 - val_accuracy: 0.5671\n",
      "Epoch 117/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6781 - accuracy: 0.5758 - val_loss: 0.6843 - val_accuracy: 0.5646\n",
      "Epoch 118/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5740 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 119/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5771 - val_loss: 0.6845 - val_accuracy: 0.5646\n",
      "Epoch 120/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5786 - val_loss: 0.6833 - val_accuracy: 0.5660\n",
      "Epoch 121/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6770 - accuracy: 0.5803 - val_loss: 0.6841 - val_accuracy: 0.5654\n",
      "Epoch 122/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5754 - val_loss: 0.6835 - val_accuracy: 0.5680\n",
      "Epoch 123/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5743 - val_loss: 0.6838 - val_accuracy: 0.5675\n",
      "Epoch 124/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6827 - accuracy: 0.5714 - val_loss: 0.6837 - val_accuracy: 0.5680\n",
      "Epoch 125/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5764 - val_loss: 0.6835 - val_accuracy: 0.5685\n",
      "Epoch 126/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6783 - accuracy: 0.5735 - val_loss: 0.6836 - val_accuracy: 0.5675\n",
      "Epoch 127/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5677 - val_loss: 0.6839 - val_accuracy: 0.5677\n",
      "Epoch 128/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6794 - accuracy: 0.5759 - val_loss: 0.6844 - val_accuracy: 0.5644\n",
      "Epoch 129/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5694 - val_loss: 0.6840 - val_accuracy: 0.5677\n",
      "Epoch 130/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5695 - val_loss: 0.6837 - val_accuracy: 0.5671\n",
      "Epoch 131/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5710 - val_loss: 0.6834 - val_accuracy: 0.5680\n",
      "Epoch 132/1000\n",
      "1018/1018 [==============================] - 4s 4ms/step - loss: 0.6797 - accuracy: 0.5727 - val_loss: 0.6866 - val_accuracy: 0.5635\n",
      "Epoch 133/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6826 - accuracy: 0.5675 - val_loss: 0.6835 - val_accuracy: 0.5664\n",
      "Epoch 134/1000\n",
      "1018/1018 [==============================] - 4s 3ms/step - loss: 0.6805 - accuracy: 0.5751 - val_loss: 0.6841 - val_accuracy: 0.5663\n",
      "Epoch 135/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6791 - accuracy: 0.5753 - val_loss: 0.6835 - val_accuracy: 0.5652\n",
      "Epoch 136/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5813 - val_loss: 0.6836 - val_accuracy: 0.5661\n",
      "Epoch 137/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6815 - accuracy: 0.5713 - val_loss: 0.6833 - val_accuracy: 0.5660\n",
      "Epoch 138/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5758 - val_loss: 0.6837 - val_accuracy: 0.5675\n",
      "Epoch 139/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5764 - val_loss: 0.6837 - val_accuracy: 0.5669\n",
      "Epoch 140/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5717 - val_loss: 0.6836 - val_accuracy: 0.5681\n",
      "Epoch 141/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5700 - val_loss: 0.6842 - val_accuracy: 0.5660\n",
      "Epoch 142/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5759 - val_loss: 0.6838 - val_accuracy: 0.5666\n",
      "Epoch 143/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6820 - accuracy: 0.5699 - val_loss: 0.6843 - val_accuracy: 0.5688\n",
      "Epoch 144/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6821 - accuracy: 0.5690 - val_loss: 0.6843 - val_accuracy: 0.5694\n",
      "Epoch 145/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5767 - val_loss: 0.6841 - val_accuracy: 0.5670\n",
      "Epoch 146/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5725 - val_loss: 0.6868 - val_accuracy: 0.5601 0.6810 - \n",
      "Epoch 147/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5694 - val_loss: 0.6831 - val_accuracy: 0.5684\n",
      "Epoch 148/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5776 - val_loss: 0.6838 - val_accuracy: 0.5680\n",
      "Epoch 149/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6790 - accuracy: 0.5773 - val_loss: 0.6839 - val_accuracy: 0.5696\n",
      "Epoch 150/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5769 - val_loss: 0.6837 - val_accuracy: 0.5648\n",
      "Epoch 151/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5739 - val_loss: 0.6836 - val_accuracy: 0.5656\n",
      "Epoch 152/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6802 - accuracy: 0.5731 - val_loss: 0.6851 - val_accuracy: 0.5630\n",
      "Epoch 153/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6790 - accuracy: 0.5760 - val_loss: 0.6849 - val_accuracy: 0.5621\n",
      "Epoch 154/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6794 - accuracy: 0.5752 - val_loss: 0.6837 - val_accuracy: 0.5659\n",
      "Epoch 155/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5770 - val_loss: 0.6860 - val_accuracy: 0.5666\n",
      "Epoch 156/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6786 - accuracy: 0.5769 - val_loss: 0.6836 - val_accuracy: 0.5652\n",
      "Epoch 157/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6817 - accuracy: 0.5721 - val_loss: 0.6846 - val_accuracy: 0.5670\n",
      "Epoch 158/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5729 - val_loss: 0.6835 - val_accuracy: 0.5689\n",
      "Epoch 159/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5741 - val_loss: 0.6833 - val_accuracy: 0.5673\n",
      "Epoch 160/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6781 - accuracy: 0.5763 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 161/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5754 - val_loss: 0.6837 - val_accuracy: 0.5690\n",
      "Epoch 162/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6773 - accuracy: 0.5781 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 163/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5773 - val_loss: 0.6833 - val_accuracy: 0.5685\n",
      "Epoch 164/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5751 - val_loss: 0.6866 - val_accuracy: 0.5645\n",
      "Epoch 165/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5720 - val_loss: 0.6836 - val_accuracy: 0.5659\n",
      "Epoch 166/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5741 - val_loss: 0.6836 - val_accuracy: 0.5677\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5737 - val_loss: 0.6845 - val_accuracy: 0.5651\n",
      "Epoch 168/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5755 - val_loss: 0.6845 - val_accuracy: 0.5667\n",
      "Epoch 169/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5703 - val_loss: 0.6856 - val_accuracy: 0.5665\n",
      "Epoch 170/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5783 - val_loss: 0.6836 - val_accuracy: 0.5675\n",
      "Epoch 171/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5764 - val_loss: 0.6843 - val_accuracy: 0.5684\n",
      "Epoch 172/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5753 - val_loss: 0.6833 - val_accuracy: 0.5679\n",
      "Epoch 173/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5729 - val_loss: 0.6846 - val_accuracy: 0.5600\n",
      "Epoch 174/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5699 - val_loss: 0.6842 - val_accuracy: 0.5669\n",
      "Epoch 175/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5709 - val_loss: 0.6837 - val_accuracy: 0.5673\n",
      "Epoch 176/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6791 - accuracy: 0.5729 - val_loss: 0.6831 - val_accuracy: 0.5664\n",
      "Epoch 177/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5748 - val_loss: 0.6845 - val_accuracy: 0.5644\n",
      "Epoch 178/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.5736 - val_loss: 0.6837 - val_accuracy: 0.5654\n",
      "Epoch 179/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5723 - val_loss: 0.6839 - val_accuracy: 0.5695\n",
      "Epoch 180/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6804 - accuracy: 0.5686 - val_loss: 0.6854 - val_accuracy: 0.5619\n",
      "Epoch 181/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5712 - val_loss: 0.6839 - val_accuracy: 0.5681\n",
      "Epoch 182/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5761 - val_loss: 0.6839 - val_accuracy: 0.5663\n",
      "Epoch 183/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5789 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 184/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5758 - val_loss: 0.6833 - val_accuracy: 0.5676\n",
      "Epoch 185/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6791 - accuracy: 0.5754 - val_loss: 0.6851 - val_accuracy: 0.5625\n",
      "Epoch 186/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5745 - val_loss: 0.6839 - val_accuracy: 0.5689\n",
      "Epoch 187/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5699 - val_loss: 0.6837 - val_accuracy: 0.5661\n",
      "Epoch 188/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5744 - val_loss: 0.6842 - val_accuracy: 0.5679\n",
      "Epoch 189/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6812 - accuracy: 0.5687 - val_loss: 0.6846 - val_accuracy: 0.5684\n",
      "Epoch 190/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.5698 - val_loss: 0.6849 - val_accuracy: 0.5655\n",
      "Epoch 191/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5755 - val_loss: 0.6885 - val_accuracy: 0.5576\n",
      "Epoch 192/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6817 - accuracy: 0.5758 - val_loss: 0.6842 - val_accuracy: 0.5676\n",
      "Epoch 193/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5740 - val_loss: 0.6830 - val_accuracy: 0.5665\n",
      "Epoch 194/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6812 - accuracy: 0.5720 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 195/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5695 - val_loss: 0.6847 - val_accuracy: 0.5681\n",
      "Epoch 196/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6815 - accuracy: 0.5686 - val_loss: 0.6841 - val_accuracy: 0.5651\n",
      "Epoch 197/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5722 - val_loss: 0.6834 - val_accuracy: 0.5692\n",
      "Epoch 198/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5778 - val_loss: 0.6860 - val_accuracy: 0.5638\n",
      "Epoch 199/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5738 - val_loss: 0.6851 - val_accuracy: 0.5633\n",
      "Epoch 200/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5712 - val_loss: 0.6840 - val_accuracy: 0.5665\n",
      "Epoch 201/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6786 - accuracy: 0.5782 - val_loss: 0.6840 - val_accuracy: 0.5670\n",
      "Epoch 202/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5731 - val_loss: 0.6834 - val_accuracy: 0.5661\n",
      "Epoch 203/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5759 - val_loss: 0.6846 - val_accuracy: 0.5685\n",
      "Epoch 204/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6829 - accuracy: 0.5740 - val_loss: 0.6840 - val_accuracy: 0.5631\n",
      "Epoch 205/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5724 - val_loss: 0.6832 - val_accuracy: 0.5677\n",
      "Epoch 206/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6773 - accuracy: 0.5771 - val_loss: 0.6833 - val_accuracy: 0.5680\n",
      "Epoch 207/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5734 - val_loss: 0.6837 - val_accuracy: 0.5684\n",
      "Epoch 208/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6777 - accuracy: 0.5788 - val_loss: 0.6865 - val_accuracy: 0.5648\n",
      "Epoch 209/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5734 - val_loss: 0.6839 - val_accuracy: 0.5656\n",
      "Epoch 210/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6791 - accuracy: 0.5753 - val_loss: 0.6845 - val_accuracy: 0.5664\n",
      "Epoch 211/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5786 - val_loss: 0.6832 - val_accuracy: 0.5684\n",
      "Epoch 212/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5780 - val_loss: 0.6839 - val_accuracy: 0.5681\n",
      "Epoch 213/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6812 - accuracy: 0.5696 - val_loss: 0.6842 - val_accuracy: 0.5680\n",
      "Epoch 214/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5760 - val_loss: 0.6841 - val_accuracy: 0.5659\n",
      "Epoch 215/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5735 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 216/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5753 - val_loss: 0.6841 - val_accuracy: 0.5641\n",
      "Epoch 217/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5799 - val_loss: 0.6840 - val_accuracy: 0.5667\n",
      "Epoch 218/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5743 - val_loss: 0.6833 - val_accuracy: 0.5689\n",
      "Epoch 219/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6778 - accuracy: 0.5748 - val_loss: 0.6840 - val_accuracy: 0.5679\n",
      "Epoch 220/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5764 - val_loss: 0.6858 - val_accuracy: 0.5630\n",
      "Epoch 221/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6817 - accuracy: 0.5705 - val_loss: 0.6839 - val_accuracy: 0.5664\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6794 - accuracy: 0.5713 - val_loss: 0.6841 - val_accuracy: 0.5689\n",
      "Epoch 223/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5757 - val_loss: 0.6832 - val_accuracy: 0.5685\n",
      "Epoch 224/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5690 - val_loss: 0.6854 - val_accuracy: 0.5633\n",
      "Epoch 225/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5742 - val_loss: 0.6845 - val_accuracy: 0.5675\n",
      "Epoch 226/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5714 - val_loss: 0.6829 - val_accuracy: 0.5661\n",
      "Epoch 227/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5731 - val_loss: 0.6832 - val_accuracy: 0.5681\n",
      "Epoch 228/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5764 - val_loss: 0.6836 - val_accuracy: 0.5674\n",
      "Epoch 229/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6818 - accuracy: 0.5716 - val_loss: 0.6835 - val_accuracy: 0.5711\n",
      "Epoch 230/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5768 - val_loss: 0.6834 - val_accuracy: 0.5674\n",
      "Epoch 231/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6845 - val_accuracy: 0.5681\n",
      "Epoch 232/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5733 - val_loss: 0.6837 - val_accuracy: 0.5663\n",
      "Epoch 233/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5761 - val_loss: 0.6835 - val_accuracy: 0.5704\n",
      "Epoch 234/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5731 - val_loss: 0.6850 - val_accuracy: 0.5651\n",
      "Epoch 235/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5754 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 236/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5784 - val_loss: 0.6838 - val_accuracy: 0.5670\n",
      "Epoch 237/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5756 - val_loss: 0.6833 - val_accuracy: 0.5661\n",
      "Epoch 238/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5784 - val_loss: 0.6841 - val_accuracy: 0.5681\n",
      "Epoch 239/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.5690 - val_loss: 0.6838 - val_accuracy: 0.5642\n",
      "Epoch 240/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5750 - val_loss: 0.6836 - val_accuracy: 0.5676\n",
      "Epoch 241/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5714 - val_loss: 0.6837 - val_accuracy: 0.5676\n",
      "Epoch 242/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6811 - accuracy: 0.5699 - val_loss: 0.6836 - val_accuracy: 0.5635\n",
      "Epoch 243/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5720 - val_loss: 0.6839 - val_accuracy: 0.5656\n",
      "Epoch 244/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5782 - val_loss: 0.6832 - val_accuracy: 0.5696\n",
      "Epoch 245/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5739 - val_loss: 0.6846 - val_accuracy: 0.5669\n",
      "Epoch 246/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5742 - val_loss: 0.6834 - val_accuracy: 0.5663\n",
      "Epoch 247/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5719 - val_loss: 0.6837 - val_accuracy: 0.5665\n",
      "Epoch 248/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5749 - val_loss: 0.6846 - val_accuracy: 0.5675\n",
      "Epoch 249/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5744 - val_loss: 0.6836 - val_accuracy: 0.5669\n",
      "Epoch 250/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5768 - val_loss: 0.6834 - val_accuracy: 0.5659\n",
      "Epoch 251/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6811 - accuracy: 0.5718 - val_loss: 0.6835 - val_accuracy: 0.5664\n",
      "Epoch 252/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5758 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 253/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5727 - val_loss: 0.6835 - val_accuracy: 0.5666\n",
      "Epoch 254/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5753 - val_loss: 0.6845 - val_accuracy: 0.5633\n",
      "Epoch 255/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5734 - val_loss: 0.6834 - val_accuracy: 0.5685\n",
      "Epoch 256/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5717 - val_loss: 0.6829 - val_accuracy: 0.5663\n",
      "Epoch 257/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5754 - val_loss: 0.6845 - val_accuracy: 0.5652\n",
      "Epoch 258/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5749 - val_loss: 0.6832 - val_accuracy: 0.5686\n",
      "Epoch 259/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5768 - val_loss: 0.6833 - val_accuracy: 0.5670\n",
      "Epoch 260/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6783 - accuracy: 0.5758 - val_loss: 0.6833 - val_accuracy: 0.5675\n",
      "Epoch 261/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5767 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 262/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5730 - val_loss: 0.6840 - val_accuracy: 0.5677\n",
      "Epoch 263/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5710 - val_loss: 0.6836 - val_accuracy: 0.5677\n",
      "Epoch 264/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5723 - val_loss: 0.6834 - val_accuracy: 0.5680\n",
      "Epoch 265/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5782 - val_loss: 0.6861 - val_accuracy: 0.5671\n",
      "Epoch 266/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5732 - val_loss: 0.6840 - val_accuracy: 0.5673\n",
      "Epoch 267/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5721 - val_loss: 0.6833 - val_accuracy: 0.5713\n",
      "Epoch 268/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5717 - val_loss: 0.6832 - val_accuracy: 0.5661\n",
      "Epoch 269/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5735 - val_loss: 0.6851 - val_accuracy: 0.5671\n",
      "Epoch 270/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5771 - val_loss: 0.6834 - val_accuracy: 0.5645\n",
      "Epoch 271/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5719 - val_loss: 0.6830 - val_accuracy: 0.5666\n",
      "Epoch 272/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6781 - accuracy: 0.5757 - val_loss: 0.6840 - val_accuracy: 0.5640\n",
      "Epoch 273/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5779 - val_loss: 0.6834 - val_accuracy: 0.5670\n",
      "Epoch 274/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5780 - val_loss: 0.6842 - val_accuracy: 0.5698\n",
      "Epoch 275/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5703 - val_loss: 0.6837 - val_accuracy: 0.5677\n",
      "Epoch 276/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5710 - val_loss: 0.6840 - val_accuracy: 0.5644\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6821 - accuracy: 0.5764 - val_loss: 0.6837 - val_accuracy: 0.5679\n",
      "Epoch 278/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6811 - accuracy: 0.5738 - val_loss: 0.6835 - val_accuracy: 0.5679\n",
      "Epoch 279/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5737 - val_loss: 0.6834 - val_accuracy: 0.5674\n",
      "Epoch 280/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6807 - accuracy: 0.5729 - val_loss: 0.6833 - val_accuracy: 0.5695\n",
      "Epoch 281/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5747 - val_loss: 0.6836 - val_accuracy: 0.5671\n",
      "Epoch 282/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5736 - val_loss: 0.6836 - val_accuracy: 0.5681\n",
      "Epoch 283/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6777 - accuracy: 0.5753 - val_loss: 0.6837 - val_accuracy: 0.5695\n",
      "Epoch 284/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5771 - val_loss: 0.6833 - val_accuracy: 0.5685\n",
      "Epoch 285/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5777 - val_loss: 0.6834 - val_accuracy: 0.5698\n",
      "Epoch 286/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5740 - val_loss: 0.6857 - val_accuracy: 0.5651\n",
      "Epoch 287/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6783 - accuracy: 0.5749 - val_loss: 0.6833 - val_accuracy: 0.5660\n",
      "Epoch 288/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5774 - val_loss: 0.6832 - val_accuracy: 0.5670\n",
      "Epoch 289/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5745 - val_loss: 0.6840 - val_accuracy: 0.5663\n",
      "Epoch 290/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5730 - val_loss: 0.6847 - val_accuracy: 0.5646\n",
      "Epoch 291/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5791 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 292/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5738 - val_loss: 0.6856 - val_accuracy: 0.5652\n",
      "Epoch 293/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5738 - val_loss: 0.6846 - val_accuracy: 0.5651\n",
      "Epoch 294/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5682 - val_loss: 0.6849 - val_accuracy: 0.5626\n",
      "Epoch 295/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5725 - val_loss: 0.6842 - val_accuracy: 0.5660\n",
      "Epoch 296/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5700 - val_loss: 0.6835 - val_accuracy: 0.5685\n",
      "Epoch 297/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6837 - accuracy: 0.5694 - val_loss: 0.6841 - val_accuracy: 0.5648\n",
      "Epoch 298/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6773 - accuracy: 0.5781 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 299/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5714 - val_loss: 0.6833 - val_accuracy: 0.5692\n",
      "Epoch 300/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5746 - val_loss: 0.6846 - val_accuracy: 0.5663\n",
      "Epoch 301/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5738 - val_loss: 0.6833 - val_accuracy: 0.5670\n",
      "Epoch 302/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5768 - val_loss: 0.6833 - val_accuracy: 0.5638\n",
      "Epoch 303/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5737 - val_loss: 0.6852 - val_accuracy: 0.5699\n",
      "Epoch 304/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5712 - val_loss: 0.6839 - val_accuracy: 0.5661\n",
      "Epoch 305/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5731 - val_loss: 0.6841 - val_accuracy: 0.5639\n",
      "Epoch 306/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5786 - val_loss: 0.6857 - val_accuracy: 0.5646\n",
      "Epoch 307/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5715 - val_loss: 0.6831 - val_accuracy: 0.5676\n",
      "Epoch 308/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5694 - val_loss: 0.6842 - val_accuracy: 0.5646\n",
      "Epoch 309/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5770 - val_loss: 0.6840 - val_accuracy: 0.5664\n",
      "Epoch 310/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5755 - val_loss: 0.6838 - val_accuracy: 0.5664\n",
      "Epoch 311/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5730 - val_loss: 0.6837 - val_accuracy: 0.5636\n",
      "Epoch 312/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5749 - val_loss: 0.6835 - val_accuracy: 0.5673\n",
      "Epoch 313/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5706 - val_loss: 0.6834 - val_accuracy: 0.5674\n",
      "Epoch 314/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5774 - val_loss: 0.6832 - val_accuracy: 0.5664\n",
      "Epoch 315/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5746 - val_loss: 0.6844 - val_accuracy: 0.5649\n",
      "Epoch 316/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5733 - val_loss: 0.6831 - val_accuracy: 0.5669\n",
      "Epoch 317/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5761 - val_loss: 0.6852 - val_accuracy: 0.5660\n",
      "Epoch 318/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5717 - val_loss: 0.6835 - val_accuracy: 0.5671\n",
      "Epoch 319/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5778 - val_loss: 0.6832 - val_accuracy: 0.5658\n",
      "Epoch 320/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5774 - val_loss: 0.6834 - val_accuracy: 0.5673\n",
      "Epoch 321/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5752 - val_loss: 0.6841 - val_accuracy: 0.5673\n",
      "Epoch 322/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5742 - val_loss: 0.6838 - val_accuracy: 0.5673\n",
      "Epoch 323/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5736 - val_loss: 0.6846 - val_accuracy: 0.5660\n",
      "Epoch 324/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5728 - val_loss: 0.6853 - val_accuracy: 0.5665\n",
      "Epoch 325/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5743 - val_loss: 0.6838 - val_accuracy: 0.5680\n",
      "Epoch 326/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5680 - val_loss: 0.6837 - val_accuracy: 0.5659\n",
      "Epoch 327/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5671 - val_loss: 0.6836 - val_accuracy: 0.5667\n",
      "Epoch 328/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5772 - val_loss: 0.6833 - val_accuracy: 0.5696\n",
      "Epoch 329/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6819 - accuracy: 0.5706 - val_loss: 0.6836 - val_accuracy: 0.5715\n",
      "Epoch 330/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6815 - accuracy: 0.5748 - val_loss: 0.6845 - val_accuracy: 0.5691\n",
      "Epoch 331/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5765 - val_loss: 0.6844 - val_accuracy: 0.5641\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5755 - val_loss: 0.6830 - val_accuracy: 0.5655\n",
      "Epoch 333/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5714 - val_loss: 0.6832 - val_accuracy: 0.5676\n",
      "Epoch 334/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5754 - val_loss: 0.6841 - val_accuracy: 0.5655\n",
      "Epoch 335/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5730 - val_loss: 0.6846 - val_accuracy: 0.5674\n",
      "Epoch 336/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5726 - val_loss: 0.6846 - val_accuracy: 0.5652\n",
      "Epoch 337/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5699 - val_loss: 0.6837 - val_accuracy: 0.5665\n",
      "Epoch 338/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5747 - val_loss: 0.6851 - val_accuracy: 0.5634\n",
      "Epoch 339/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5739 - val_loss: 0.6832 - val_accuracy: 0.5669\n",
      "Epoch 340/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5750 - val_loss: 0.6836 - val_accuracy: 0.5676\n",
      "Epoch 341/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5774 - val_loss: 0.6834 - val_accuracy: 0.5681\n",
      "Epoch 342/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5739 - val_loss: 0.6835 - val_accuracy: 0.5663\n",
      "Epoch 343/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6782 - accuracy: 0.5784 - val_loss: 0.6834 - val_accuracy: 0.5666\n",
      "Epoch 344/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5770 - val_loss: 0.6833 - val_accuracy: 0.5664\n",
      "Epoch 345/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5709 - val_loss: 0.6859 - val_accuracy: 0.5664\n",
      "Epoch 346/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6820 - accuracy: 0.5734 - val_loss: 0.6833 - val_accuracy: 0.5659\n",
      "Epoch 347/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5764 - val_loss: 0.6832 - val_accuracy: 0.5665\n",
      "Epoch 348/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6777 - accuracy: 0.5766 - val_loss: 0.6835 - val_accuracy: 0.5684\n",
      "Epoch 349/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5737 - val_loss: 0.6833 - val_accuracy: 0.5673\n",
      "Epoch 350/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5732 - val_loss: 0.6839 - val_accuracy: 0.5656\n",
      "Epoch 351/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5757 - val_loss: 0.6832 - val_accuracy: 0.5691\n",
      "Epoch 352/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5734 - val_loss: 0.6848 - val_accuracy: 0.5673\n",
      "Epoch 353/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5764 - val_loss: 0.6838 - val_accuracy: 0.5694\n",
      "Epoch 354/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5731 - val_loss: 0.6839 - val_accuracy: 0.5681\n",
      "Epoch 355/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5700 - val_loss: 0.6832 - val_accuracy: 0.5695\n",
      "Epoch 356/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5725 - val_loss: 0.6834 - val_accuracy: 0.5695\n",
      "Epoch 357/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5720 - val_loss: 0.6837 - val_accuracy: 0.5666\n",
      "Epoch 358/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5714 - val_loss: 0.6842 - val_accuracy: 0.5684\n",
      "Epoch 359/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5771 - val_loss: 0.6837 - val_accuracy: 0.5660\n",
      "Epoch 360/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5750 - val_loss: 0.6832 - val_accuracy: 0.5692\n",
      "Epoch 361/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6798 - accuracy: 0.5744 - val_loss: 0.6837 - val_accuracy: 0.5671\n",
      "Epoch 362/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5699 - val_loss: 0.6835 - val_accuracy: 0.5670\n",
      "Epoch 363/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5764 - val_loss: 0.6844 - val_accuracy: 0.5669\n",
      "Epoch 364/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5769 - val_loss: 0.6836 - val_accuracy: 0.5659\n",
      "Epoch 365/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6777 - accuracy: 0.5755 - val_loss: 0.6837 - val_accuracy: 0.5655\n",
      "Epoch 366/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5726 - val_loss: 0.6842 - val_accuracy: 0.5655\n",
      "Epoch 367/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6817 - accuracy: 0.5702 - val_loss: 0.6833 - val_accuracy: 0.5680\n",
      "Epoch 368/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5733 - val_loss: 0.6835 - val_accuracy: 0.5686\n",
      "Epoch 369/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5727 - val_loss: 0.6850 - val_accuracy: 0.5646\n",
      "Epoch 370/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5774 - val_loss: 0.6833 - val_accuracy: 0.5658\n",
      "Epoch 371/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6773 - accuracy: 0.5782 - val_loss: 0.6830 - val_accuracy: 0.5690\n",
      "Epoch 372/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5717 - val_loss: 0.6849 - val_accuracy: 0.5635\n",
      "Epoch 373/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5719 - val_loss: 0.6841 - val_accuracy: 0.5667\n",
      "Epoch 374/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5735 - val_loss: 0.6831 - val_accuracy: 0.5666\n",
      "Epoch 375/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5740 - val_loss: 0.6831 - val_accuracy: 0.5685\n",
      "Epoch 376/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5755 - val_loss: 0.6857 - val_accuracy: 0.5659\n",
      "Epoch 377/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6811 - accuracy: 0.5712 - val_loss: 0.6837 - val_accuracy: 0.5663\n",
      "Epoch 378/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5759 - val_loss: 0.6834 - val_accuracy: 0.5700\n",
      "Epoch 379/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5765 - val_loss: 0.6835 - val_accuracy: 0.5675\n",
      "Epoch 380/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5768 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 381/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5739 - val_loss: 0.6862 - val_accuracy: 0.5649\n",
      "Epoch 382/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5813 - val_loss: 0.6837 - val_accuracy: 0.5669\n",
      "Epoch 383/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5804 - val_loss: 0.6832 - val_accuracy: 0.5659\n",
      "Epoch 384/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5741 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 385/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.5700 - val_loss: 0.6845 - val_accuracy: 0.5652\n",
      "Epoch 386/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5736 - val_loss: 0.6838 - val_accuracy: 0.5661\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5768 - val_loss: 0.6840 - val_accuracy: 0.5694\n",
      "Epoch 388/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.5795 - val_loss: 0.6835 - val_accuracy: 0.5670\n",
      "Epoch 389/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5758 - val_loss: 0.6837 - val_accuracy: 0.5631\n",
      "Epoch 390/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5774 - val_loss: 0.6835 - val_accuracy: 0.5664\n",
      "Epoch 391/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5766 - val_loss: 0.6870 - val_accuracy: 0.5656\n",
      "Epoch 392/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6830 - accuracy: 0.5706 - val_loss: 0.6852 - val_accuracy: 0.5636\n",
      "Epoch 393/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5734 - val_loss: 0.6833 - val_accuracy: 0.5691\n",
      "Epoch 394/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5751 - val_loss: 0.6845 - val_accuracy: 0.5641\n",
      "Epoch 395/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5770 - val_loss: 0.6834 - val_accuracy: 0.5710\n",
      "Epoch 396/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5779 - val_loss: 0.6830 - val_accuracy: 0.5669\n",
      "Epoch 397/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5793 - val_loss: 0.6839 - val_accuracy: 0.5673\n",
      "Epoch 398/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5744 - val_loss: 0.6833 - val_accuracy: 0.5675\n",
      "Epoch 399/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5788 - val_loss: 0.6832 - val_accuracy: 0.5664\n",
      "Epoch 400/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6777 - accuracy: 0.5792 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 401/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5758 - val_loss: 0.6840 - val_accuracy: 0.5660\n",
      "Epoch 402/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5725 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 403/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5763 - val_loss: 0.6832 - val_accuracy: 0.5664\n",
      "Epoch 404/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5734 - val_loss: 0.6832 - val_accuracy: 0.5677\n",
      "Epoch 405/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5758 - val_loss: 0.6841 - val_accuracy: 0.5685\n",
      "Epoch 406/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6794 - accuracy: 0.5768 - val_loss: 0.6831 - val_accuracy: 0.5665\n",
      "Epoch 407/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5766 - val_loss: 0.6832 - val_accuracy: 0.5675\n",
      "Epoch 408/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5732 - val_loss: 0.6838 - val_accuracy: 0.5699\n",
      "Epoch 409/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6816 - accuracy: 0.5710 - val_loss: 0.6857 - val_accuracy: 0.5638\n",
      "Epoch 410/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5743 - val_loss: 0.6834 - val_accuracy: 0.5648\n",
      "Epoch 411/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5708 - val_loss: 0.6856 - val_accuracy: 0.5651\n",
      "Epoch 412/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5749 - val_loss: 0.6836 - val_accuracy: 0.5665\n",
      "Epoch 413/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5717 - val_loss: 0.6837 - val_accuracy: 0.5675\n",
      "Epoch 414/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6771 - accuracy: 0.5810 - val_loss: 0.6832 - val_accuracy: 0.5695\n",
      "Epoch 415/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5741 - val_loss: 0.6837 - val_accuracy: 0.5663\n",
      "Epoch 416/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6821 - accuracy: 0.5723 - val_loss: 0.6856 - val_accuracy: 0.5649\n",
      "Epoch 417/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5761 - val_loss: 0.6834 - val_accuracy: 0.5676\n",
      "Epoch 418/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5811 - val_loss: 0.6837 - val_accuracy: 0.5660\n",
      "Epoch 419/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5741 - val_loss: 0.6843 - val_accuracy: 0.5665\n",
      "Epoch 420/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5746 - val_loss: 0.6839 - val_accuracy: 0.5640\n",
      "Epoch 421/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6770 - accuracy: 0.5773 - val_loss: 0.6847 - val_accuracy: 0.5630\n",
      "Epoch 422/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5750 - val_loss: 0.6833 - val_accuracy: 0.5692\n",
      "Epoch 423/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5791 - val_loss: 0.6850 - val_accuracy: 0.5631\n",
      "Epoch 424/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5721 - val_loss: 0.6832 - val_accuracy: 0.5679\n",
      "Epoch 425/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 426/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6774 - accuracy: 0.5792 - val_loss: 0.6831 - val_accuracy: 0.5666\n",
      "Epoch 427/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5726 - val_loss: 0.6851 - val_accuracy: 0.5659\n",
      "Epoch 428/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5773 - val_loss: 0.6834 - val_accuracy: 0.5664\n",
      "Epoch 429/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5715 - val_loss: 0.6833 - val_accuracy: 0.5681\n",
      "Epoch 430/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5793 - val_loss: 0.6836 - val_accuracy: 0.5689\n",
      "Epoch 431/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5714 - val_loss: 0.6840 - val_accuracy: 0.5669\n",
      "Epoch 432/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5773 - val_loss: 0.6843 - val_accuracy: 0.5635\n",
      "Epoch 433/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5759 - val_loss: 0.6838 - val_accuracy: 0.5656\n",
      "Epoch 434/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5730 - val_loss: 0.6830 - val_accuracy: 0.5667\n",
      "Epoch 435/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5708 - val_loss: 0.6852 - val_accuracy: 0.5649\n",
      "Epoch 436/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5772 - val_loss: 0.6832 - val_accuracy: 0.5676\n",
      "Epoch 437/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5715 - val_loss: 0.6837 - val_accuracy: 0.5661\n",
      "Epoch 438/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5735 - val_loss: 0.6841 - val_accuracy: 0.5667\n",
      "Epoch 439/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5748 - val_loss: 0.6840 - val_accuracy: 0.5650\n",
      "Epoch 440/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5799 - val_loss: 0.6833 - val_accuracy: 0.5665\n",
      "Epoch 441/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5747 - val_loss: 0.6838 - val_accuracy: 0.5690\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5707 - val_loss: 0.6844 - val_accuracy: 0.5665\n",
      "Epoch 443/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5703 - val_loss: 0.6841 - val_accuracy: 0.5654\n",
      "Epoch 444/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5699 - val_loss: 0.6829 - val_accuracy: 0.5671\n",
      "Epoch 445/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5747 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 446/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5703 - val_loss: 0.6842 - val_accuracy: 0.5688\n",
      "Epoch 447/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5796 - val_loss: 0.6830 - val_accuracy: 0.5676\n",
      "Epoch 448/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5765 - val_loss: 0.6835 - val_accuracy: 0.5673\n",
      "Epoch 449/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5749 - val_loss: 0.6831 - val_accuracy: 0.5664\n",
      "Epoch 450/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5747 - val_loss: 0.6861 - val_accuracy: 0.5614\n",
      "Epoch 451/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5700 - val_loss: 0.6842 - val_accuracy: 0.5659\n",
      "Epoch 452/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5742 - val_loss: 0.6837 - val_accuracy: 0.5660\n",
      "Epoch 453/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5744 - val_loss: 0.6834 - val_accuracy: 0.5676\n",
      "Epoch 454/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5761 - val_loss: 0.6833 - val_accuracy: 0.5664\n",
      "Epoch 455/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5735 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 456/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5742 - val_loss: 0.6843 - val_accuracy: 0.5656\n",
      "Epoch 457/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5742 - val_loss: 0.6842 - val_accuracy: 0.5640\n",
      "Epoch 458/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5756 - val_loss: 0.6842 - val_accuracy: 0.5669\n",
      "Epoch 459/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5758 - val_loss: 0.6833 - val_accuracy: 0.5692\n",
      "Epoch 460/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5744 - val_loss: 0.6836 - val_accuracy: 0.5688\n",
      "Epoch 461/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5778 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 462/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5758 - val_loss: 0.6836 - val_accuracy: 0.5686\n",
      "Epoch 463/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5759 - val_loss: 0.6837 - val_accuracy: 0.5654\n",
      "Epoch 464/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5782 - val_loss: 0.6836 - val_accuracy: 0.5704\n",
      "Epoch 465/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.5786 - val_loss: 0.6835 - val_accuracy: 0.5650\n",
      "Epoch 466/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5733 - val_loss: 0.6854 - val_accuracy: 0.5645\n",
      "Epoch 467/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5781 - val_loss: 0.6833 - val_accuracy: 0.5685\n",
      "Epoch 468/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5791 - val_loss: 0.6833 - val_accuracy: 0.5664\n",
      "Epoch 469/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.5794 - val_loss: 0.6840 - val_accuracy: 0.5702\n",
      "Epoch 470/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6782 - accuracy: 0.5766 - val_loss: 0.6833 - val_accuracy: 0.5688\n",
      "Epoch 471/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5779 - val_loss: 0.6840 - val_accuracy: 0.5677\n",
      "Epoch 472/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6819 - accuracy: 0.5690 - val_loss: 0.6842 - val_accuracy: 0.5671\n",
      "Epoch 473/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5713 - val_loss: 0.6835 - val_accuracy: 0.5671\n",
      "Epoch 474/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5756 - val_loss: 0.6839 - val_accuracy: 0.5638\n",
      "Epoch 475/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5765 - val_loss: 0.6844 - val_accuracy: 0.5658\n",
      "Epoch 476/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5723 - val_loss: 0.6836 - val_accuracy: 0.5684\n",
      "Epoch 477/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5758 - val_loss: 0.6846 - val_accuracy: 0.5627\n",
      "Epoch 478/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5711 - val_loss: 0.6838 - val_accuracy: 0.5671\n",
      "Epoch 479/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5731 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 480/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5722 - val_loss: 0.6836 - val_accuracy: 0.5686\n",
      "Epoch 481/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6766 - accuracy: 0.5788 - val_loss: 0.6831 - val_accuracy: 0.5675\n",
      "Epoch 482/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5676 - val_loss: 0.6913 - val_accuracy: 0.5601\n",
      "Epoch 483/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6828 - accuracy: 0.5757 - val_loss: 0.6837 - val_accuracy: 0.5644\n",
      "Epoch 484/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6811 - accuracy: 0.5721 - val_loss: 0.6838 - val_accuracy: 0.5652\n",
      "Epoch 485/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6822 - accuracy: 0.5678 - val_loss: 0.6839 - val_accuracy: 0.5685\n",
      "Epoch 486/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5778 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 487/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5723 - val_loss: 0.6859 - val_accuracy: 0.5623\n",
      "Epoch 488/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6822 - accuracy: 0.5719 - val_loss: 0.6839 - val_accuracy: 0.5652\n",
      "Epoch 489/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5754 - val_loss: 0.6831 - val_accuracy: 0.5673\n",
      "Epoch 490/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5730 - val_loss: 0.6834 - val_accuracy: 0.5677\n",
      "Epoch 491/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5785 - val_loss: 0.6838 - val_accuracy: 0.5659\n",
      "Epoch 492/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5742 - val_loss: 0.6834 - val_accuracy: 0.5679\n",
      "Epoch 493/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5750 - val_loss: 0.6841 - val_accuracy: 0.5658\n",
      "Epoch 494/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5761 - val_loss: 0.6835 - val_accuracy: 0.5670\n",
      "Epoch 495/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5750 - val_loss: 0.6838 - val_accuracy: 0.5666\n",
      "Epoch 496/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5733 - val_loss: 0.6836 - val_accuracy: 0.5656\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5810 - val_loss: 0.6833 - val_accuracy: 0.5681\n",
      "Epoch 498/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5744 - val_loss: 0.6839 - val_accuracy: 0.5694\n",
      "Epoch 499/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5784 - val_loss: 0.6841 - val_accuracy: 0.5649\n",
      "Epoch 500/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5705 - val_loss: 0.6833 - val_accuracy: 0.5666\n",
      "Epoch 501/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6773 - accuracy: 0.5749 - val_loss: 0.6834 - val_accuracy: 0.5670\n",
      "Epoch 502/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5768 - val_loss: 0.6832 - val_accuracy: 0.5685\n",
      "Epoch 503/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5756 - val_loss: 0.6835 - val_accuracy: 0.5689\n",
      "Epoch 504/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5732 - val_loss: 0.6834 - val_accuracy: 0.5696\n",
      "Epoch 505/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6809 - accuracy: 0.5777 - val_loss: 0.6837 - val_accuracy: 0.5671\n",
      "Epoch 506/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5719 - val_loss: 0.6837 - val_accuracy: 0.5684\n",
      "Epoch 507/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5767 - val_loss: 0.6850 - val_accuracy: 0.5671\n",
      "Epoch 508/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5791 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 509/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5779 - val_loss: 0.6837 - val_accuracy: 0.5658\n",
      "Epoch 510/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5717 - val_loss: 0.6859 - val_accuracy: 0.5661\n",
      "Epoch 511/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5756 - val_loss: 0.6836 - val_accuracy: 0.5688\n",
      "Epoch 512/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5738 - val_loss: 0.6833 - val_accuracy: 0.5671\n",
      "Epoch 513/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5760 - val_loss: 0.6839 - val_accuracy: 0.5695\n",
      "Epoch 514/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5776 - val_loss: 0.6838 - val_accuracy: 0.5665\n",
      "Epoch 515/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5748 - val_loss: 0.6830 - val_accuracy: 0.5675\n",
      "Epoch 516/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5773 - val_loss: 0.6834 - val_accuracy: 0.5650\n",
      "Epoch 517/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5753 - val_loss: 0.6843 - val_accuracy: 0.5651\n",
      "Epoch 518/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6817 - accuracy: 0.5705 - val_loss: 0.6835 - val_accuracy: 0.5656\n",
      "Epoch 519/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5764 - val_loss: 0.6831 - val_accuracy: 0.5690\n",
      "Epoch 520/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6770 - accuracy: 0.5773 - val_loss: 0.6829 - val_accuracy: 0.5656\n",
      "Epoch 521/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5745 - val_loss: 0.6847 - val_accuracy: 0.5685\n",
      "Epoch 522/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5737 - val_loss: 0.6850 - val_accuracy: 0.5649\n",
      "Epoch 523/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5748 - val_loss: 0.6838 - val_accuracy: 0.5666\n",
      "Epoch 524/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5677 - val_loss: 0.6835 - val_accuracy: 0.5673\n",
      "Epoch 525/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5744 - val_loss: 0.6838 - val_accuracy: 0.5641\n",
      "Epoch 526/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5759 - val_loss: 0.6853 - val_accuracy: 0.5661\n",
      "Epoch 527/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5762 - val_loss: 0.6830 - val_accuracy: 0.5680\n",
      "Epoch 528/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5725 - val_loss: 0.6832 - val_accuracy: 0.5655\n",
      "Epoch 529/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5763 - val_loss: 0.6839 - val_accuracy: 0.5669\n",
      "Epoch 530/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5760 - val_loss: 0.6832 - val_accuracy: 0.5684\n",
      "Epoch 531/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5781 - val_loss: 0.6836 - val_accuracy: 0.5686\n",
      "Epoch 532/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5761 - val_loss: 0.6839 - val_accuracy: 0.5667\n",
      "Epoch 533/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5777 - val_loss: 0.6834 - val_accuracy: 0.5640\n",
      "Epoch 534/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5833 - val_loss: 0.6834 - val_accuracy: 0.5644\n",
      "Epoch 535/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5701 - val_loss: 0.6840 - val_accuracy: 0.5675\n",
      "Epoch 536/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5732 - val_loss: 0.6834 - val_accuracy: 0.5660\n",
      "Epoch 537/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6786 - accuracy: 0.5794 - val_loss: 0.6839 - val_accuracy: 0.5675\n",
      "Epoch 538/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5793 - val_loss: 0.6844 - val_accuracy: 0.5663\n",
      "Epoch 539/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.5682 - val_loss: 0.6836 - val_accuracy: 0.5681\n",
      "Epoch 540/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5743 - val_loss: 0.6831 - val_accuracy: 0.5664\n",
      "Epoch 541/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5727 - val_loss: 0.6848 - val_accuracy: 0.5673\n",
      "Epoch 542/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5689 - val_loss: 0.6833 - val_accuracy: 0.5652\n",
      "Epoch 543/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5724 - val_loss: 0.6849 - val_accuracy: 0.5709\n",
      "Epoch 544/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5710 - val_loss: 0.6833 - val_accuracy: 0.5670\n",
      "Epoch 545/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5764 - val_loss: 0.6838 - val_accuracy: 0.5666\n",
      "Epoch 546/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6827 - accuracy: 0.5705 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 547/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5759 - val_loss: 0.6833 - val_accuracy: 0.5655\n",
      "Epoch 548/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5728 - val_loss: 0.6831 - val_accuracy: 0.5694\n",
      "Epoch 549/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5729 - val_loss: 0.6858 - val_accuracy: 0.5677\n",
      "Epoch 550/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5732 - val_loss: 0.6833 - val_accuracy: 0.5673\n",
      "Epoch 551/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5777 - val_loss: 0.6830 - val_accuracy: 0.5680\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5728 - val_loss: 0.6838 - val_accuracy: 0.5667\n",
      "Epoch 553/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.5718 - val_loss: 0.6830 - val_accuracy: 0.5692\n",
      "Epoch 554/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5724 - val_loss: 0.6837 - val_accuracy: 0.5691\n",
      "Epoch 555/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5720 - val_loss: 0.6834 - val_accuracy: 0.5666\n",
      "Epoch 556/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6767 - accuracy: 0.5789 - val_loss: 0.6829 - val_accuracy: 0.5674\n",
      "Epoch 557/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5771 - val_loss: 0.6839 - val_accuracy: 0.5690\n",
      "Epoch 558/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6815 - accuracy: 0.5677 - val_loss: 0.6837 - val_accuracy: 0.5710\n",
      "Epoch 559/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5766 - val_loss: 0.6839 - val_accuracy: 0.5679\n",
      "Epoch 560/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5754 - val_loss: 0.6831 - val_accuracy: 0.5679\n",
      "Epoch 561/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5715 - val_loss: 0.6853 - val_accuracy: 0.5655\n",
      "Epoch 562/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5750 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 563/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5708 - val_loss: 0.6831 - val_accuracy: 0.5680\n",
      "Epoch 564/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5726 - val_loss: 0.6837 - val_accuracy: 0.5688\n",
      "Epoch 565/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6807 - accuracy: 0.5718 - val_loss: 0.6838 - val_accuracy: 0.5677\n",
      "Epoch 566/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6791 - accuracy: 0.5723 - val_loss: 0.6833 - val_accuracy: 0.5659\n",
      "Epoch 567/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5741 - val_loss: 0.6842 - val_accuracy: 0.5690\n",
      "Epoch 568/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5789 - val_loss: 0.6836 - val_accuracy: 0.5691\n",
      "Epoch 569/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5739 - val_loss: 0.6836 - val_accuracy: 0.5677\n",
      "Epoch 570/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5749 - val_loss: 0.6834 - val_accuracy: 0.5692\n",
      "Epoch 571/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5735 - val_loss: 0.6840 - val_accuracy: 0.5673\n",
      "Epoch 572/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5735 - val_loss: 0.6839 - val_accuracy: 0.5642\n",
      "Epoch 573/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5749 - val_loss: 0.6834 - val_accuracy: 0.5675\n",
      "Epoch 574/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5740 - val_loss: 0.6833 - val_accuracy: 0.5666\n",
      "Epoch 575/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5710 - val_loss: 0.6839 - val_accuracy: 0.5670\n",
      "Epoch 576/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5683 - val_loss: 0.6835 - val_accuracy: 0.5663\n",
      "Epoch 577/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5742 - val_loss: 0.6849 - val_accuracy: 0.5641\n",
      "Epoch 578/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5786 - val_loss: 0.6833 - val_accuracy: 0.5690\n",
      "Epoch 579/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5755 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 580/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5775 - val_loss: 0.6837 - val_accuracy: 0.5644\n",
      "Epoch 581/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5791 - val_loss: 0.6840 - val_accuracy: 0.5679\n",
      "Epoch 582/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5702 - val_loss: 0.6835 - val_accuracy: 0.5692\n",
      "Epoch 583/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5728 - val_loss: 0.6867 - val_accuracy: 0.5658\n",
      "Epoch 584/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5760 - val_loss: 0.6829 - val_accuracy: 0.5679\n",
      "Epoch 585/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5749 - val_loss: 0.6829 - val_accuracy: 0.5671\n",
      "Epoch 586/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5746 - val_loss: 0.6832 - val_accuracy: 0.5673\n",
      "Epoch 587/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5732 - val_loss: 0.6855 - val_accuracy: 0.5649\n",
      "Epoch 588/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5793 - val_loss: 0.6834 - val_accuracy: 0.5685\n",
      "Epoch 589/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5746 - val_loss: 0.6840 - val_accuracy: 0.5709\n",
      "Epoch 590/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5759 - val_loss: 0.6841 - val_accuracy: 0.5651\n",
      "Epoch 591/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6836 - accuracy: 0.5707 - val_loss: 0.6844 - val_accuracy: 0.5650\n",
      "Epoch 592/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5797 - val_loss: 0.6833 - val_accuracy: 0.5696\n",
      "Epoch 593/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5759 - val_loss: 0.6829 - val_accuracy: 0.5677\n",
      "Epoch 594/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5773 - val_loss: 0.6835 - val_accuracy: 0.5673\n",
      "Epoch 595/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5753 - val_loss: 0.6859 - val_accuracy: 0.5624\n",
      "Epoch 596/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6829 - accuracy: 0.5696 - val_loss: 0.6835 - val_accuracy: 0.5674\n",
      "Epoch 597/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6763 - accuracy: 0.5811 - val_loss: 0.6833 - val_accuracy: 0.5688\n",
      "Epoch 598/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5797 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 599/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5776 - val_loss: 0.6840 - val_accuracy: 0.5633\n",
      "Epoch 600/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5733 - val_loss: 0.6838 - val_accuracy: 0.5675\n",
      "Epoch 601/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5744 - val_loss: 0.6845 - val_accuracy: 0.5683\n",
      "Epoch 602/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5801 - val_loss: 0.6832 - val_accuracy: 0.5690\n",
      "Epoch 603/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5768 - val_loss: 0.6831 - val_accuracy: 0.5674\n",
      "Epoch 604/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5735 - val_loss: 0.6835 - val_accuracy: 0.5644\n",
      "Epoch 605/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5730 - val_loss: 0.6838 - val_accuracy: 0.5665\n",
      "Epoch 606/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5764 - val_loss: 0.6860 - val_accuracy: 0.5666\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5763 - val_loss: 0.6832 - val_accuracy: 0.5681\n",
      "Epoch 608/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5720 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 609/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5731 - val_loss: 0.6834 - val_accuracy: 0.5671\n",
      "Epoch 610/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5761 - val_loss: 0.6841 - val_accuracy: 0.5649\n",
      "Epoch 611/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5776 - val_loss: 0.6836 - val_accuracy: 0.5663\n",
      "Epoch 612/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5791 - val_loss: 0.6854 - val_accuracy: 0.5651\n",
      "Epoch 613/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6816 - accuracy: 0.5732 - val_loss: 0.6838 - val_accuracy: 0.5620\n",
      "Epoch 614/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5710 - val_loss: 0.6836 - val_accuracy: 0.5671\n",
      "Epoch 615/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5738 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 616/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5757 - val_loss: 0.6857 - val_accuracy: 0.5665\n",
      "Epoch 617/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5732 - val_loss: 0.6836 - val_accuracy: 0.5686\n",
      "Epoch 618/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5732 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 619/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5756 - val_loss: 0.6834 - val_accuracy: 0.5676\n",
      "Epoch 620/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5708 - val_loss: 0.6836 - val_accuracy: 0.5694\n",
      "Epoch 621/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5722 - val_loss: 0.6837 - val_accuracy: 0.5656\n",
      "Epoch 622/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6817 - accuracy: 0.5701 - val_loss: 0.6841 - val_accuracy: 0.5660\n",
      "Epoch 623/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5707 - val_loss: 0.6840 - val_accuracy: 0.5655\n",
      "Epoch 624/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5763 - val_loss: 0.6832 - val_accuracy: 0.5650\n",
      "Epoch 625/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.5769 - val_loss: 0.6847 - val_accuracy: 0.5674\n",
      "Epoch 626/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5775 - val_loss: 0.6835 - val_accuracy: 0.5671\n",
      "Epoch 627/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5787 - val_loss: 0.6833 - val_accuracy: 0.5666\n",
      "Epoch 628/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5747 - val_loss: 0.6842 - val_accuracy: 0.5666\n",
      "Epoch 629/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5762 - val_loss: 0.6839 - val_accuracy: 0.5690\n",
      "Epoch 630/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6824 - accuracy: 0.5758 - val_loss: 0.6837 - val_accuracy: 0.5677\n",
      "Epoch 631/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5802 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 632/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5729 - val_loss: 0.6838 - val_accuracy: 0.5675\n",
      "Epoch 633/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5752 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 634/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5760 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 635/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5750 - val_loss: 0.6836 - val_accuracy: 0.5638\n",
      "Epoch 636/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5706 - val_loss: 0.6831 - val_accuracy: 0.5688\n",
      "Epoch 637/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5689 - val_loss: 0.6850 - val_accuracy: 0.5655\n",
      "Epoch 638/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6799 - accuracy: 0.5726 - val_loss: 0.6831 - val_accuracy: 0.5666\n",
      "Epoch 639/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6775 - accuracy: 0.5777 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 640/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5779 - val_loss: 0.6833 - val_accuracy: 0.5656\n",
      "Epoch 641/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5737 - val_loss: 0.6837 - val_accuracy: 0.5661\n",
      "Epoch 642/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6816 - accuracy: 0.5752 - val_loss: 0.6845 - val_accuracy: 0.5639\n",
      "Epoch 643/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5768 - val_loss: 0.6830 - val_accuracy: 0.5655\n",
      "Epoch 644/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5811 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 645/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5720 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 646/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5754 - val_loss: 0.6834 - val_accuracy: 0.5679\n",
      "Epoch 647/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5765 - val_loss: 0.6831 - val_accuracy: 0.5665\n",
      "Epoch 648/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5739 - val_loss: 0.6835 - val_accuracy: 0.5694\n",
      "Epoch 649/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6817 - accuracy: 0.5724 - val_loss: 0.6835 - val_accuracy: 0.5664\n",
      "Epoch 650/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5720 - val_loss: 0.6831 - val_accuracy: 0.5665\n",
      "Epoch 651/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5773 - val_loss: 0.6838 - val_accuracy: 0.5674\n",
      "Epoch 652/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5709 - val_loss: 0.6840 - val_accuracy: 0.5658\n",
      "Epoch 653/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5774 - val_loss: 0.6871 - val_accuracy: 0.5586\n",
      "Epoch 654/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5713 - val_loss: 0.6839 - val_accuracy: 0.5667\n",
      "Epoch 655/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5756 - val_loss: 0.6832 - val_accuracy: 0.5659\n",
      "Epoch 656/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5787 - val_loss: 0.6832 - val_accuracy: 0.5665\n",
      "Epoch 657/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5747 - val_loss: 0.6844 - val_accuracy: 0.5644\n",
      "Epoch 658/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5792 - val_loss: 0.6832 - val_accuracy: 0.5640\n",
      "Epoch 659/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5763 - val_loss: 0.6831 - val_accuracy: 0.5685\n",
      "Epoch 660/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5726 - val_loss: 0.6838 - val_accuracy: 0.5692\n",
      "Epoch 661/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5701 - val_loss: 0.6853 - val_accuracy: 0.5689\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5739 - val_loss: 0.6830 - val_accuracy: 0.5696\n",
      "Epoch 663/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5763 - val_loss: 0.6835 - val_accuracy: 0.5676\n",
      "Epoch 664/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5731 - val_loss: 0.6843 - val_accuracy: 0.5679\n",
      "Epoch 665/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5790 - val_loss: 0.6830 - val_accuracy: 0.5679\n",
      "Epoch 666/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5736 - val_loss: 0.6854 - val_accuracy: 0.5676\n",
      "Epoch 667/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5745 - val_loss: 0.6842 - val_accuracy: 0.5674\n",
      "Epoch 668/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5737 - val_loss: 0.6834 - val_accuracy: 0.5660\n",
      "Epoch 669/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5732 - val_loss: 0.6834 - val_accuracy: 0.5685\n",
      "Epoch 670/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5732 - val_loss: 0.6834 - val_accuracy: 0.5656\n",
      "Epoch 671/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5688 - val_loss: 0.6847 - val_accuracy: 0.5652\n",
      "Epoch 672/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5799 - val_loss: 0.6835 - val_accuracy: 0.5666\n",
      "Epoch 673/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6790 - accuracy: 0.5747 - val_loss: 0.6829 - val_accuracy: 0.5663\n",
      "Epoch 674/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5740 - val_loss: 0.6866 - val_accuracy: 0.5641\n",
      "Epoch 675/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5711 - val_loss: 0.6831 - val_accuracy: 0.5695\n",
      "Epoch 676/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5723 - val_loss: 0.6836 - val_accuracy: 0.5671\n",
      "Epoch 677/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6773 - accuracy: 0.5767 - val_loss: 0.6843 - val_accuracy: 0.5664\n",
      "Epoch 678/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6800 - accuracy: 0.5763 - val_loss: 0.6836 - val_accuracy: 0.5700\n",
      "Epoch 679/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5682 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 680/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6818 - accuracy: 0.5699 - val_loss: 0.6834 - val_accuracy: 0.5671\n",
      "Epoch 681/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5735 - val_loss: 0.6836 - val_accuracy: 0.5685\n",
      "Epoch 682/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5745 - val_loss: 0.6843 - val_accuracy: 0.5684\n",
      "Epoch 683/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6822 - accuracy: 0.5697 - val_loss: 0.6835 - val_accuracy: 0.5666\n",
      "Epoch 684/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5743 - val_loss: 0.6837 - val_accuracy: 0.5673\n",
      "Epoch 685/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.5777 - val_loss: 0.6837 - val_accuracy: 0.5652\n",
      "Epoch 686/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5754 - val_loss: 0.6831 - val_accuracy: 0.5675\n",
      "Epoch 687/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6764 - accuracy: 0.5810 - val_loss: 0.6860 - val_accuracy: 0.5602\n",
      "Epoch 688/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5717 - val_loss: 0.6831 - val_accuracy: 0.5648\n",
      "Epoch 689/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5812 - val_loss: 0.6831 - val_accuracy: 0.5651\n",
      "Epoch 690/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5743 - val_loss: 0.6838 - val_accuracy: 0.5655\n",
      "Epoch 691/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5718 - val_loss: 0.6844 - val_accuracy: 0.5644\n",
      "Epoch 692/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5702 - val_loss: 0.6831 - val_accuracy: 0.5666\n",
      "Epoch 693/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5737 - val_loss: 0.6831 - val_accuracy: 0.5700\n",
      "Epoch 694/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6773 - accuracy: 0.5775 - val_loss: 0.6832 - val_accuracy: 0.5675\n",
      "Epoch 695/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5767 - val_loss: 0.6840 - val_accuracy: 0.5639\n",
      "Epoch 696/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5756 - val_loss: 0.6830 - val_accuracy: 0.5665\n",
      "Epoch 697/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5794 - val_loss: 0.6840 - val_accuracy: 0.5667\n",
      "Epoch 698/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5730 - val_loss: 0.6832 - val_accuracy: 0.5711\n",
      "Epoch 699/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5732 - val_loss: 0.6834 - val_accuracy: 0.5675\n",
      "Epoch 700/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6779 - accuracy: 0.5785 - val_loss: 0.6831 - val_accuracy: 0.5658\n",
      "Epoch 701/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6765 - accuracy: 0.5822 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 702/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5764 - val_loss: 0.6834 - val_accuracy: 0.5681\n",
      "Epoch 703/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6778 - accuracy: 0.5779 - val_loss: 0.6841 - val_accuracy: 0.5639\n",
      "Epoch 704/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5778 - val_loss: 0.6838 - val_accuracy: 0.5658\n",
      "Epoch 705/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5749 - val_loss: 0.6846 - val_accuracy: 0.5689\n",
      "Epoch 706/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5765 - val_loss: 0.6831 - val_accuracy: 0.5685\n",
      "Epoch 707/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5747 - val_loss: 0.6833 - val_accuracy: 0.5664\n",
      "Epoch 708/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5733 - val_loss: 0.6836 - val_accuracy: 0.5669\n",
      "Epoch 709/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5770 - val_loss: 0.6852 - val_accuracy: 0.5646\n",
      "Epoch 710/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5711 - val_loss: 0.6833 - val_accuracy: 0.5670\n",
      "Epoch 711/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5691 - val_loss: 0.6831 - val_accuracy: 0.5654\n",
      "Epoch 712/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5775 - val_loss: 0.6860 - val_accuracy: 0.5626\n",
      "Epoch 713/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5729 - val_loss: 0.6844 - val_accuracy: 0.5648\n",
      "Epoch 714/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5738 - val_loss: 0.6839 - val_accuracy: 0.5652\n",
      "Epoch 715/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5736 - val_loss: 0.6837 - val_accuracy: 0.5685\n",
      "Epoch 716/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5787 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5754 - val_loss: 0.6845 - val_accuracy: 0.5689\n",
      "Epoch 718/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5749 - val_loss: 0.6833 - val_accuracy: 0.5680\n",
      "Epoch 719/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5701 - val_loss: 0.6854 - val_accuracy: 0.5627\n",
      "Epoch 720/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5762 - val_loss: 0.6832 - val_accuracy: 0.5663\n",
      "Epoch 721/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5702 - val_loss: 0.6840 - val_accuracy: 0.5670\n",
      "Epoch 722/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5748 - val_loss: 0.6833 - val_accuracy: 0.5695\n",
      "Epoch 723/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5780 - val_loss: 0.6833 - val_accuracy: 0.5646\n",
      "Epoch 724/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5752 - val_loss: 0.6831 - val_accuracy: 0.5701\n",
      "Epoch 725/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5742 - val_loss: 0.6836 - val_accuracy: 0.5681\n",
      "Epoch 726/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6821 - accuracy: 0.5721 - val_loss: 0.6839 - val_accuracy: 0.5677\n",
      "Epoch 727/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5715 - val_loss: 0.6836 - val_accuracy: 0.5671\n",
      "Epoch 728/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5673 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 729/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6780 - accuracy: 0.5782 - val_loss: 0.6829 - val_accuracy: 0.5664\n",
      "Epoch 730/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5811 - val_loss: 0.6853 - val_accuracy: 0.5641\n",
      "Epoch 731/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5739 - val_loss: 0.6835 - val_accuracy: 0.5660\n",
      "Epoch 732/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5766 - val_loss: 0.6834 - val_accuracy: 0.5656\n",
      "Epoch 733/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6811 - accuracy: 0.5696 - val_loss: 0.6833 - val_accuracy: 0.5660\n",
      "Epoch 734/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6817 - accuracy: 0.5721 - val_loss: 0.6850 - val_accuracy: 0.5667\n",
      "Epoch 735/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5748 - val_loss: 0.6836 - val_accuracy: 0.5680\n",
      "Epoch 736/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5768 - val_loss: 0.6834 - val_accuracy: 0.5654\n",
      "Epoch 737/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6794 - accuracy: 0.5698 - val_loss: 0.6835 - val_accuracy: 0.5673\n",
      "Epoch 738/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5728 - val_loss: 0.6838 - val_accuracy: 0.5704\n",
      "Epoch 739/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5741 - val_loss: 0.6836 - val_accuracy: 0.5686\n",
      "Epoch 740/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5743 - val_loss: 0.6832 - val_accuracy: 0.5691\n",
      "Epoch 741/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5786 - val_loss: 0.6837 - val_accuracy: 0.5660\n",
      "Epoch 742/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5750 - val_loss: 0.6837 - val_accuracy: 0.5681\n",
      "Epoch 743/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6785 - accuracy: 0.5782 - val_loss: 0.6834 - val_accuracy: 0.5675\n",
      "Epoch 744/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5745 - val_loss: 0.6835 - val_accuracy: 0.5691\n",
      "Epoch 745/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5733 - val_loss: 0.6844 - val_accuracy: 0.5648\n",
      "Epoch 746/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5733 - val_loss: 0.6832 - val_accuracy: 0.5686\n",
      "Epoch 747/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6782 - accuracy: 0.5778 - val_loss: 0.6841 - val_accuracy: 0.5666\n",
      "Epoch 748/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6818 - accuracy: 0.5692 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 749/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5731 - val_loss: 0.6840 - val_accuracy: 0.5636\n",
      "Epoch 750/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5762 - val_loss: 0.6834 - val_accuracy: 0.5661\n",
      "Epoch 751/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5796 - val_loss: 0.6833 - val_accuracy: 0.5656\n",
      "Epoch 752/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5766 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 753/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5804 - val_loss: 0.6843 - val_accuracy: 0.5694\n",
      "Epoch 754/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5707 - val_loss: 0.6833 - val_accuracy: 0.5674\n",
      "Epoch 755/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6791 - accuracy: 0.5757 - val_loss: 0.6878 - val_accuracy: 0.5601\n",
      "Epoch 756/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5745 - val_loss: 0.6833 - val_accuracy: 0.5681\n",
      "Epoch 757/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5754 - val_loss: 0.6830 - val_accuracy: 0.5655\n",
      "Epoch 758/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6807 - accuracy: 0.5712 - val_loss: 0.7109 - val_accuracy: 0.5376\n",
      "Epoch 759/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5748 - val_loss: 0.6835 - val_accuracy: 0.5674\n",
      "Epoch 760/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5762 - val_loss: 0.6831 - val_accuracy: 0.5674\n",
      "Epoch 761/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5732 - val_loss: 0.6847 - val_accuracy: 0.5656\n",
      "Epoch 762/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5705 - val_loss: 0.6831 - val_accuracy: 0.5685\n",
      "Epoch 763/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5703 - val_loss: 0.6830 - val_accuracy: 0.5663\n",
      "Epoch 764/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5688 - val_loss: 0.6836 - val_accuracy: 0.5692\n",
      "Epoch 765/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5755 - val_loss: 0.6831 - val_accuracy: 0.5663\n",
      "Epoch 766/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6769 - accuracy: 0.5797 - val_loss: 0.6863 - val_accuracy: 0.5677\n",
      "Epoch 767/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6832 - accuracy: 0.5730 - val_loss: 0.6835 - val_accuracy: 0.5666\n",
      "Epoch 768/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5751 - val_loss: 0.6832 - val_accuracy: 0.5683\n",
      "Epoch 769/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5757 - val_loss: 0.6830 - val_accuracy: 0.5681\n",
      "Epoch 770/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5751 - val_loss: 0.6839 - val_accuracy: 0.5648\n",
      "Epoch 771/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6815 - accuracy: 0.5683 - val_loss: 0.6838 - val_accuracy: 0.5683\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5736 - val_loss: 0.6830 - val_accuracy: 0.5675\n",
      "Epoch 773/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5762 - val_loss: 0.6830 - val_accuracy: 0.5655\n",
      "Epoch 774/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5770 - val_loss: 0.6835 - val_accuracy: 0.5658\n",
      "Epoch 775/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5741 - val_loss: 0.6832 - val_accuracy: 0.5680\n",
      "Epoch 776/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5703 - val_loss: 0.6838 - val_accuracy: 0.5655\n",
      "Epoch 777/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5766 - val_loss: 0.6834 - val_accuracy: 0.5676\n",
      "Epoch 778/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5780 - val_loss: 0.6830 - val_accuracy: 0.5683\n",
      "Epoch 779/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5738 - val_loss: 0.6830 - val_accuracy: 0.5666\n",
      "Epoch 780/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5798 - val_loss: 0.6840 - val_accuracy: 0.5671\n",
      "Epoch 781/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5746 - val_loss: 0.6832 - val_accuracy: 0.5673\n",
      "Epoch 782/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6777 - accuracy: 0.5779 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 783/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5776 - val_loss: 0.6840 - val_accuracy: 0.5670\n",
      "Epoch 784/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5739 - val_loss: 0.6865 - val_accuracy: 0.5630\n",
      "Epoch 785/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5694 - val_loss: 0.6834 - val_accuracy: 0.5680\n",
      "Epoch 786/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5739 - val_loss: 0.6834 - val_accuracy: 0.5673\n",
      "Epoch 787/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5767 - val_loss: 0.6841 - val_accuracy: 0.5675\n",
      "Epoch 788/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5785 - val_loss: 0.6830 - val_accuracy: 0.5659\n",
      "Epoch 789/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5753 - val_loss: 0.6836 - val_accuracy: 0.5648\n",
      "Epoch 790/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5770 - val_loss: 0.6834 - val_accuracy: 0.5671\n",
      "Epoch 791/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5754 - val_loss: 0.6848 - val_accuracy: 0.5700\n",
      "Epoch 792/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5747 - val_loss: 0.6834 - val_accuracy: 0.5684\n",
      "Epoch 793/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5801 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 794/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5736 - val_loss: 0.6834 - val_accuracy: 0.5671\n",
      "Epoch 795/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5741 - val_loss: 0.6864 - val_accuracy: 0.5645\n",
      "Epoch 796/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5751 - val_loss: 0.6832 - val_accuracy: 0.5666\n",
      "Epoch 797/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5782 - val_loss: 0.6830 - val_accuracy: 0.5666\n",
      "Epoch 798/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5723 - val_loss: 0.6835 - val_accuracy: 0.5665\n",
      "Epoch 799/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5801 - val_loss: 0.6840 - val_accuracy: 0.5696\n",
      "Epoch 800/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5763 - val_loss: 0.6832 - val_accuracy: 0.5684\n",
      "Epoch 801/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5769 - val_loss: 0.6836 - val_accuracy: 0.5674\n",
      "Epoch 802/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5730 - val_loss: 0.6850 - val_accuracy: 0.5671\n",
      "Epoch 803/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5746 - val_loss: 0.6839 - val_accuracy: 0.5674\n",
      "Epoch 804/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6801 - accuracy: 0.5753 - val_loss: 0.6831 - val_accuracy: 0.5686\n",
      "Epoch 805/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6777 - accuracy: 0.5783 - val_loss: 0.6830 - val_accuracy: 0.5688\n",
      "Epoch 806/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5750 - val_loss: 0.6858 - val_accuracy: 0.5661\n",
      "Epoch 807/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6809 - accuracy: 0.5756 - val_loss: 0.6840 - val_accuracy: 0.5680\n",
      "Epoch 808/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5756 - val_loss: 0.6835 - val_accuracy: 0.5644\n",
      "Epoch 809/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5742 - val_loss: 0.6837 - val_accuracy: 0.5660\n",
      "Epoch 810/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5750 - val_loss: 0.6841 - val_accuracy: 0.5660\n",
      "Epoch 811/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5727 - val_loss: 0.6834 - val_accuracy: 0.5663\n",
      "Epoch 812/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6821 - accuracy: 0.5760 - val_loss: 0.6842 - val_accuracy: 0.5658\n",
      "Epoch 813/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5780 - val_loss: 0.6829 - val_accuracy: 0.5671\n",
      "Epoch 814/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5763 - val_loss: 0.6832 - val_accuracy: 0.5681\n",
      "Epoch 815/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5744 - val_loss: 0.6833 - val_accuracy: 0.5669\n",
      "Epoch 816/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5726 - val_loss: 0.6835 - val_accuracy: 0.5677\n",
      "Epoch 817/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5728 - val_loss: 0.6837 - val_accuracy: 0.5676\n",
      "Epoch 818/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5827 - val_loss: 0.6843 - val_accuracy: 0.5686\n",
      "Epoch 819/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6822 - accuracy: 0.5711 - val_loss: 0.6847 - val_accuracy: 0.5642\n",
      "Epoch 820/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5751 - val_loss: 0.6835 - val_accuracy: 0.5652\n",
      "Epoch 821/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5754 - val_loss: 0.6837 - val_accuracy: 0.5679\n",
      "Epoch 822/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5766 - val_loss: 0.6835 - val_accuracy: 0.5646\n",
      "Epoch 823/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5775 - val_loss: 0.6836 - val_accuracy: 0.5626\n",
      "Epoch 824/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5761 - val_loss: 0.6838 - val_accuracy: 0.5680\n",
      "Epoch 825/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5729 - val_loss: 0.6833 - val_accuracy: 0.5660\n",
      "Epoch 826/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5761 - val_loss: 0.6848 - val_accuracy: 0.5671\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5717 - val_loss: 0.6863 - val_accuracy: 0.5608\n",
      "Epoch 828/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5772 - val_loss: 0.6838 - val_accuracy: 0.5702\n",
      "Epoch 829/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5768 - val_loss: 0.6840 - val_accuracy: 0.5634\n",
      "Epoch 830/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5761 - val_loss: 0.6839 - val_accuracy: 0.5669\n",
      "Epoch 831/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5748 - val_loss: 0.6833 - val_accuracy: 0.5664\n",
      "Epoch 832/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5776 - val_loss: 0.6836 - val_accuracy: 0.5679\n",
      "Epoch 833/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5738 - val_loss: 0.6833 - val_accuracy: 0.5640\n",
      "Epoch 834/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5728 - val_loss: 0.6880 - val_accuracy: 0.5652\n",
      "Epoch 835/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5771 - val_loss: 0.6837 - val_accuracy: 0.5671\n",
      "Epoch 836/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5771 - val_loss: 0.6835 - val_accuracy: 0.5692\n",
      "Epoch 837/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6815 - accuracy: 0.5678 - val_loss: 0.6841 - val_accuracy: 0.5665\n",
      "Epoch 838/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5750 - val_loss: 0.6845 - val_accuracy: 0.5694\n",
      "Epoch 839/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5738 - val_loss: 0.6833 - val_accuracy: 0.5656\n",
      "Epoch 840/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5756 - val_loss: 0.6837 - val_accuracy: 0.5677\n",
      "Epoch 841/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5732 - val_loss: 0.6843 - val_accuracy: 0.5656\n",
      "Epoch 842/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5758 - val_loss: 0.6835 - val_accuracy: 0.5679\n",
      "Epoch 843/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5713 - val_loss: 0.6830 - val_accuracy: 0.5673\n",
      "Epoch 844/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5741 - val_loss: 0.6845 - val_accuracy: 0.5649\n",
      "Epoch 845/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6802 - accuracy: 0.5694 - val_loss: 0.6836 - val_accuracy: 0.5655\n",
      "Epoch 846/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5766 - val_loss: 0.6829 - val_accuracy: 0.5689\n",
      "Epoch 847/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5750 - val_loss: 0.6831 - val_accuracy: 0.5676\n",
      "Epoch 848/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5744 - val_loss: 0.6844 - val_accuracy: 0.5659\n",
      "Epoch 849/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5725 - val_loss: 0.6833 - val_accuracy: 0.5709\n",
      "Epoch 850/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.5731 - val_loss: 0.6848 - val_accuracy: 0.5609\n",
      "Epoch 851/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5725 - val_loss: 0.6833 - val_accuracy: 0.5640\n",
      "Epoch 852/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5759 - val_loss: 0.6832 - val_accuracy: 0.5673\n",
      "Epoch 853/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6776 - accuracy: 0.5784 - val_loss: 0.6832 - val_accuracy: 0.5667\n",
      "Epoch 854/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5754 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 855/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5749 - val_loss: 0.6835 - val_accuracy: 0.5694\n",
      "Epoch 856/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5749 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 857/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6773 - accuracy: 0.5815 - val_loss: 0.6834 - val_accuracy: 0.5681\n",
      "Epoch 858/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5747 - val_loss: 0.6849 - val_accuracy: 0.5685\n",
      "Epoch 859/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6833 - accuracy: 0.5705 - val_loss: 0.6837 - val_accuracy: 0.5674\n",
      "Epoch 860/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5756 - val_loss: 0.6829 - val_accuracy: 0.5656\n",
      "Epoch 861/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5709 - val_loss: 0.6828 - val_accuracy: 0.5663\n",
      "Epoch 862/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5719 - val_loss: 0.6841 - val_accuracy: 0.5664\n",
      "Epoch 863/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6825 - accuracy: 0.5735 - val_loss: 0.6840 - val_accuracy: 0.5645\n",
      "Epoch 864/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5753 - val_loss: 0.6834 - val_accuracy: 0.5673\n",
      "Epoch 865/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5715 - val_loss: 0.6837 - val_accuracy: 0.5669\n",
      "Epoch 866/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5708 - val_loss: 0.6834 - val_accuracy: 0.5661\n",
      "Epoch 867/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5747 - val_loss: 0.6843 - val_accuracy: 0.5654\n",
      "Epoch 868/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5745 - val_loss: 0.6833 - val_accuracy: 0.5670\n",
      "Epoch 869/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5759 - val_loss: 0.6831 - val_accuracy: 0.5655\n",
      "Epoch 870/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5752 - val_loss: 0.6836 - val_accuracy: 0.5663\n",
      "Epoch 871/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5753 - val_loss: 0.6842 - val_accuracy: 0.5675\n",
      "Epoch 872/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5718 - val_loss: 0.6841 - val_accuracy: 0.5652\n",
      "Epoch 873/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6789 - accuracy: 0.5732 - val_loss: 0.6861 - val_accuracy: 0.5658\n",
      "Epoch 874/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5711 - val_loss: 0.6834 - val_accuracy: 0.5673\n",
      "Epoch 875/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5754 - val_loss: 0.6833 - val_accuracy: 0.5669\n",
      "Epoch 876/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5708 - val_loss: 0.6839 - val_accuracy: 0.5616\n",
      "Epoch 877/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6808 - accuracy: 0.5687 - val_loss: 0.6843 - val_accuracy: 0.5656\n",
      "Epoch 878/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5732 - val_loss: 0.6837 - val_accuracy: 0.5664\n",
      "Epoch 879/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5727 - val_loss: 0.6830 - val_accuracy: 0.5667\n",
      "Epoch 880/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5737 - val_loss: 0.6846 - val_accuracy: 0.5640\n",
      "Epoch 881/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5726 - val_loss: 0.6834 - val_accuracy: 0.5663\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5749 - val_loss: 0.6834 - val_accuracy: 0.5651\n",
      "Epoch 883/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5739 - val_loss: 0.6829 - val_accuracy: 0.5680\n",
      "Epoch 884/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5742 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 885/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6814 - accuracy: 0.5710 - val_loss: 0.6839 - val_accuracy: 0.5670\n",
      "Epoch 886/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.5778 - val_loss: 0.6832 - val_accuracy: 0.5694\n",
      "Epoch 887/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5719 - val_loss: 0.6835 - val_accuracy: 0.5663\n",
      "Epoch 888/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5770 - val_loss: 0.6837 - val_accuracy: 0.5669\n",
      "Epoch 889/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5749 - val_loss: 0.6840 - val_accuracy: 0.5660\n",
      "Epoch 890/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5746 - val_loss: 0.6834 - val_accuracy: 0.5664\n",
      "Epoch 891/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5748 - val_loss: 0.6845 - val_accuracy: 0.5680\n",
      "Epoch 892/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5773 - val_loss: 0.6831 - val_accuracy: 0.5705\n",
      "Epoch 893/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5743 - val_loss: 0.6840 - val_accuracy: 0.5694\n",
      "Epoch 894/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5707 - val_loss: 0.6833 - val_accuracy: 0.5677\n",
      "Epoch 895/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5745 - val_loss: 0.6831 - val_accuracy: 0.5684\n",
      "Epoch 896/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6812 - accuracy: 0.5701 - val_loss: 0.6836 - val_accuracy: 0.5664\n",
      "Epoch 897/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5716 - val_loss: 0.6838 - val_accuracy: 0.5666\n",
      "Epoch 898/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5770 - val_loss: 0.6836 - val_accuracy: 0.5670\n",
      "Epoch 899/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5752 - val_loss: 0.6835 - val_accuracy: 0.5638\n",
      "Epoch 900/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5755 - val_loss: 0.6832 - val_accuracy: 0.5677\n",
      "Epoch 901/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5683 - val_loss: 0.6835 - val_accuracy: 0.5681\n",
      "Epoch 902/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5725 - val_loss: 0.6845 - val_accuracy: 0.5689\n",
      "Epoch 903/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6794 - accuracy: 0.5781 - val_loss: 0.6831 - val_accuracy: 0.5655\n",
      "Epoch 904/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5725 - val_loss: 0.6838 - val_accuracy: 0.5670\n",
      "Epoch 905/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5735 - val_loss: 0.6836 - val_accuracy: 0.5663\n",
      "Epoch 906/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5748 - val_loss: 0.6851 - val_accuracy: 0.5642\n",
      "Epoch 907/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5745 - val_loss: 0.6830 - val_accuracy: 0.5673\n",
      "Epoch 908/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5733 - val_loss: 0.6835 - val_accuracy: 0.5675\n",
      "Epoch 909/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5758 - val_loss: 0.6889 - val_accuracy: 0.5599\n",
      "Epoch 910/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5761 - val_loss: 0.6830 - val_accuracy: 0.5652\n",
      "Epoch 911/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5769 - val_loss: 0.6854 - val_accuracy: 0.5654\n",
      "Epoch 912/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5698 - val_loss: 0.6848 - val_accuracy: 0.5627\n",
      "Epoch 913/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5749 - val_loss: 0.6841 - val_accuracy: 0.5621\n",
      "Epoch 914/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5761 - val_loss: 0.6831 - val_accuracy: 0.5698\n",
      "Epoch 915/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5731 - val_loss: 0.6834 - val_accuracy: 0.5663\n",
      "Epoch 916/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5742 - val_loss: 0.6860 - val_accuracy: 0.5648\n",
      "Epoch 917/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5713 - val_loss: 0.6838 - val_accuracy: 0.5667\n",
      "Epoch 918/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5764 - val_loss: 0.6840 - val_accuracy: 0.5699\n",
      "Epoch 919/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5787 - val_loss: 0.6835 - val_accuracy: 0.5686\n",
      "Epoch 920/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5736 - val_loss: 0.6841 - val_accuracy: 0.5642\n",
      "Epoch 921/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5663 - val_loss: 0.6835 - val_accuracy: 0.5679\n",
      "Epoch 922/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5756 - val_loss: 0.6845 - val_accuracy: 0.5663\n",
      "Epoch 923/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6802 - accuracy: 0.5749 - val_loss: 0.6844 - val_accuracy: 0.5683\n",
      "Epoch 924/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5718 - val_loss: 0.6830 - val_accuracy: 0.5660\n",
      "Epoch 925/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5736 - val_loss: 0.6842 - val_accuracy: 0.5665\n",
      "Epoch 926/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5726 - val_loss: 0.6838 - val_accuracy: 0.5650\n",
      "Epoch 927/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6760 - accuracy: 0.5808 - val_loss: 0.6831 - val_accuracy: 0.5681\n",
      "Epoch 928/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5738 - val_loss: 0.6837 - val_accuracy: 0.5685\n",
      "Epoch 929/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5763 - val_loss: 0.6834 - val_accuracy: 0.5667\n",
      "Epoch 930/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5727 - val_loss: 0.6840 - val_accuracy: 0.5677\n",
      "Epoch 931/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5723 - val_loss: 0.6838 - val_accuracy: 0.5670\n",
      "Epoch 932/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5686 - val_loss: 0.6836 - val_accuracy: 0.5646\n",
      "Epoch 933/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5732 - val_loss: 0.6837 - val_accuracy: 0.5684\n",
      "Epoch 934/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.5740 - val_loss: 0.6845 - val_accuracy: 0.5649\n",
      "Epoch 935/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6817 - accuracy: 0.5718 - val_loss: 0.6835 - val_accuracy: 0.5688\n",
      "Epoch 936/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6813 - accuracy: 0.5747 - val_loss: 0.6832 - val_accuracy: 0.5676\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5745 - val_loss: 0.6837 - val_accuracy: 0.5670\n",
      "Epoch 938/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6800 - accuracy: 0.5694 - val_loss: 0.6839 - val_accuracy: 0.5705\n",
      "Epoch 939/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5786 - val_loss: 0.6833 - val_accuracy: 0.5683\n",
      "Epoch 940/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5726 - val_loss: 0.6835 - val_accuracy: 0.5661\n",
      "Epoch 941/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5739 - val_loss: 0.6833 - val_accuracy: 0.5679\n",
      "Epoch 942/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5763 - val_loss: 0.6830 - val_accuracy: 0.5675\n",
      "Epoch 943/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6805 - accuracy: 0.5743 - val_loss: 0.6843 - val_accuracy: 0.5665\n",
      "Epoch 944/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5769 - val_loss: 0.6842 - val_accuracy: 0.5659\n",
      "Epoch 945/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5740 - val_loss: 0.6829 - val_accuracy: 0.5683\n",
      "Epoch 946/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6767 - accuracy: 0.5778 - val_loss: 0.6833 - val_accuracy: 0.5670\n",
      "Epoch 947/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6796 - accuracy: 0.5725 - val_loss: 0.6835 - val_accuracy: 0.5696\n",
      "Epoch 948/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5702 - val_loss: 0.6838 - val_accuracy: 0.5670\n",
      "Epoch 949/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5748 - val_loss: 0.6830 - val_accuracy: 0.5677\n",
      "Epoch 950/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5736 - val_loss: 0.6842 - val_accuracy: 0.5642\n",
      "Epoch 951/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5778 - val_loss: 0.6834 - val_accuracy: 0.5651\n",
      "Epoch 952/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6763 - accuracy: 0.5770 - val_loss: 0.6829 - val_accuracy: 0.5670\n",
      "Epoch 953/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5769 - val_loss: 0.6840 - val_accuracy: 0.5669\n",
      "Epoch 954/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5756 - val_loss: 0.6831 - val_accuracy: 0.5656\n",
      "Epoch 955/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5781 - val_loss: 0.6832 - val_accuracy: 0.5677\n",
      "Epoch 956/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5771 - val_loss: 0.6835 - val_accuracy: 0.5688\n",
      "Epoch 957/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5743 - val_loss: 0.6838 - val_accuracy: 0.5695\n",
      "Epoch 958/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6790 - accuracy: 0.5719 - val_loss: 0.6834 - val_accuracy: 0.5651\n",
      "Epoch 959/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5784 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 960/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5754 - val_loss: 0.6841 - val_accuracy: 0.5649\n",
      "Epoch 961/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6795 - accuracy: 0.5775 - val_loss: 0.6831 - val_accuracy: 0.5670\n",
      "Epoch 962/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5764 - val_loss: 0.6833 - val_accuracy: 0.5684\n",
      "Epoch 963/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5774 - val_loss: 0.6835 - val_accuracy: 0.5667\n",
      "Epoch 964/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6801 - accuracy: 0.5764 - val_loss: 0.6847 - val_accuracy: 0.5679\n",
      "Epoch 965/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5719 - val_loss: 0.6835 - val_accuracy: 0.5704\n",
      "Epoch 966/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5707 - val_loss: 0.6834 - val_accuracy: 0.5669\n",
      "Epoch 967/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6798 - accuracy: 0.5761 - val_loss: 0.6842 - val_accuracy: 0.5679\n",
      "Epoch 968/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6804 - accuracy: 0.5775 - val_loss: 0.6837 - val_accuracy: 0.5629\n",
      "Epoch 969/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5768 - val_loss: 0.6837 - val_accuracy: 0.5688\n",
      "Epoch 970/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6810 - accuracy: 0.5710 - val_loss: 0.6843 - val_accuracy: 0.5671\n",
      "Epoch 971/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5776 - val_loss: 0.6832 - val_accuracy: 0.5679\n",
      "Epoch 972/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6774 - accuracy: 0.5769 - val_loss: 0.6831 - val_accuracy: 0.5679\n",
      "Epoch 973/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5701 - val_loss: 0.6841 - val_accuracy: 0.5683\n",
      "Epoch 974/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5724 - val_loss: 0.6835 - val_accuracy: 0.5669\n",
      "Epoch 975/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6792 - accuracy: 0.5758 - val_loss: 0.6834 - val_accuracy: 0.5656\n",
      "Epoch 976/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6823 - accuracy: 0.5654 - val_loss: 0.6858 - val_accuracy: 0.5690\n",
      "Epoch 977/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.5775 - val_loss: 0.6832 - val_accuracy: 0.5688\n",
      "Epoch 978/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5731 - val_loss: 0.6838 - val_accuracy: 0.5690\n",
      "Epoch 979/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6779 - accuracy: 0.5754 - val_loss: 0.6834 - val_accuracy: 0.5664\n",
      "Epoch 980/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6765 - accuracy: 0.5809 - val_loss: 0.6833 - val_accuracy: 0.5684\n",
      "Epoch 981/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5724 - val_loss: 0.6833 - val_accuracy: 0.5660\n",
      "Epoch 982/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6788 - accuracy: 0.5779 - val_loss: 0.6848 - val_accuracy: 0.5586\n",
      "Epoch 983/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6799 - accuracy: 0.5740 - val_loss: 0.6833 - val_accuracy: 0.5661\n",
      "Epoch 984/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6797 - accuracy: 0.5735 - val_loss: 0.6832 - val_accuracy: 0.5676\n",
      "Epoch 985/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6785 - accuracy: 0.5758 - val_loss: 0.6835 - val_accuracy: 0.5681\n",
      "Epoch 986/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5767 - val_loss: 0.6833 - val_accuracy: 0.5681\n",
      "Epoch 987/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5734 - val_loss: 0.6834 - val_accuracy: 0.5665\n",
      "Epoch 988/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6805 - accuracy: 0.5754 - val_loss: 0.6841 - val_accuracy: 0.5652\n",
      "Epoch 989/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6810 - accuracy: 0.5716 - val_loss: 0.6838 - val_accuracy: 0.5650\n",
      "Epoch 990/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6814 - accuracy: 0.5729 - val_loss: 0.6834 - val_accuracy: 0.5677\n",
      "Epoch 991/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6795 - accuracy: 0.5709 - val_loss: 0.6830 - val_accuracy: 0.5660\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6794 - accuracy: 0.5743 - val_loss: 0.6853 - val_accuracy: 0.5669\n",
      "Epoch 993/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6831 - accuracy: 0.5783 - val_loss: 0.6837 - val_accuracy: 0.5680\n",
      "Epoch 994/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6780 - accuracy: 0.5758 - val_loss: 0.6830 - val_accuracy: 0.5670\n",
      "Epoch 995/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5697 - val_loss: 0.6844 - val_accuracy: 0.5680\n",
      "Epoch 996/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6782 - accuracy: 0.5766 - val_loss: 0.6837 - val_accuracy: 0.5676\n",
      "Epoch 997/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5709 - val_loss: 0.6839 - val_accuracy: 0.5664\n",
      "Epoch 998/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6784 - accuracy: 0.5810 - val_loss: 0.6840 - val_accuracy: 0.5670\n",
      "Epoch 999/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6802 - accuracy: 0.5676 - val_loss: 0.6839 - val_accuracy: 0.5669\n",
      "Epoch 1000/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5761 - val_loss: 0.6851 - val_accuracy: 0.5665\n",
      "Train error: 0.42408233880996704\n",
      "Test error:  0.4334999918937683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regParam = keras.regularizers.l2(.0001) #create regularization parameter\n",
    "modelInter = tf.keras.Sequential([\n",
    "        keras.layers.Dense(units=np.shape(trainX)[1], activation='linear', kernel_regularizer=regParam),\n",
    "        keras.layers.Dense(units=125, activation='linear', kernel_regularizer=regParam),\n",
    "        keras.layers.Dense(units=100, activation='linear', kernel_regularizer=regParam),\n",
    "        keras.layers.Dense(units=75, activation='linear', kernel_regularizer=regParam),\n",
    "        keras.layers.Dense(units=50, activation='linear', kernel_regularizer=regParam),\n",
    "        keras.layers.Dense(units=25, activation='linear', kernel_regularizer=regParam),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid', kernel_regularizer=regParam)\n",
    "    ])\n",
    "\n",
    "epochs = 1000\n",
    "eIn, eOut = runModel(trainX, trainY, valX, valY, modelInter, epochs)\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "ax.plot(eIn,'-b')\n",
    "ax.plot(eOut,'-r')\n",
    "ax.set_xlabel('Epoch #')\n",
    "ax.set_ylabel('Error')\n",
    "ax.grid()\n",
    "ax.legend(['eIn', 'eOut'])\n",
    "ax.axes.set_xlim([0,epochs])\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "seeing-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in sample accuracy: 0.575917661190033\n",
      "val sample accuracy: 0.5665000081062317\n",
      "simple guess:  0.5393027184764245\n"
     ]
    }
   ],
   "source": [
    "#print accuracy if guessing the home team always wins\n",
    "\n",
    "print(\"in sample accuracy:\", 1-eIn[-1])\n",
    "print(\"val sample accuracy:\", 1-eOut[-1])\n",
    "print(\"simple guess: \", sum(np.ones(np.shape(trainY)) == trainY) / len(trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "confirmed-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\test.txt\"\n",
    "testX, testY = getDataFromFile(testFileName, pitDataList, batDataList) #8000 examples\n",
    "testX = reformatGameData(testX, batDataList, pitDataList)\n",
    "testX = applyMeanAndStd(testX, dataMeans, dataStds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "naval-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5610\n",
      "0.5609999895095825\n"
     ]
    }
   ],
   "source": [
    "testAcc = modelInter.evaluate(testX, testY)[1]\n",
    "print(testAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "adaptive-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/myModelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "#save model, from tensorflow documentation, https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model\n",
    "!mkdir saved_model\n",
    "modelInter.save('saved_model/myModelFinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "technical-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model, also from tensorflow documentation\n",
    "new_model = tf.keras.models.load_model('saved_model/myModelFinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-bunny",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
