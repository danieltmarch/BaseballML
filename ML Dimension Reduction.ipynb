{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "israeli-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-canadian",
   "metadata": {},
   "source": [
    "## Table for data entries and abbreviations\n",
    "\n",
    "#### Batting Data: G AB R H 2B 3B HR RBI BB IBB SO HBP SH SF XI ROE GDP SB CS AVG OBP SLG HAND\n",
    "\n",
    "0: G: Games, total game played <br/>\n",
    "1: AB: At bat, Total times at bat <br/>\n",
    "2: R: Runs, total runs scored <br/>\n",
    "3: H: Hits, total fair play hits <br/>\n",
    "4: 2B: Double, reaching 2nd base from batting <br/>\n",
    "5: 3B: Triple, reaching 3rd base from batting <br/>\n",
    "6: HR: Home run, scoring straight from batting (includes in field home runs) <br/>\n",
    "7: RBI: Runs batted in, total runs from this player's at bat <br/>\n",
    "8: BB: Walks, total times walked (includes intentional walks) <br/>\n",
    "9: IBB: Intentional Walk, intentionally walking batter to first base <br/>\n",
    "10: SO: Strike out, total times struck out at base <br/>\n",
    "11: HBP: Hit by pitch, total times <br/>\n",
    "12: SH: Sacrifice bunt, bunt resulting in the batter being out but advances another runner <br/>\n",
    "13: SF: Sacrifice fly, fly ball resulting in the batter being out but advances another runner <br/>\n",
    "14: XI: ?, (almost all players have 0 for this statistic) <br/>\n",
    "15: ROE: Reached on error, total times on base due to an error <br/>\n",
    "16: GDP: Grounded into double play <br/>\n",
    "17: SB: Stolen base, total bases stolen <br/>\n",
    "18: CS: Caught stealing, Total times getting out when stealing.<br/>\n",
    "19: AVG: Batting average, (total hits / total at bats) <br/>\n",
    "20: OBP: On base percentage, (total times on base / total at bats) <br/>\n",
    "21: SLG: Slugging percentage, bases per at bat ((1B + 2*2B + 3*3B + 4*HR) / AB) <br/>\n",
    "22: HAND: Handedness, batting hand (1 = right, -1 = left) <br/>\n",
    "\n",
    "\n",
    "\n",
    "#### Pitching Data: G GS CG SHO GF SV IP H BFP HR R ER BB IB SO SH SF WP HBP BK 2B 3B GDP ROE W L ERA RS PW HAND\n",
    "\n",
    "0: G: Games played, total games played <br/>\n",
    "1: GS: Games Started, threw the first pitch <br/>\n",
    "2: CG: Complete game, pitched for the entire game <br/>\n",
    "3: SHO: Shutout, pitches entire game without opposition scoring <br/>\n",
    "4: GF: Games Finished, threw the last pitch (not counted if there was only 1 pitcher for the game) <br/>\n",
    "5: SV: save, relief pitcher resulting in a win under certain conditions, https://www.mlb.com/glossary/standard-stats/save <br/>\n",
    "6: IP: Innings pitched, total innings pitched (can be partial) <br/>\n",
    "7: H: Hits, total hits allowed <br/>\n",
    "8: BFP: Total batters face, total batters at plate when pitching <br/>\n",
    "9: HR: Home runs allowed <br/>\n",
    "10: R: Runs allowed?, total runs allowed <br/>\n",
    "11: ER: Earned Run, total runs scored by the opposition due to the pitcher <br/>\n",
    "12: BB: Walk, total walks <br/>\n",
    "13: IB: Intentional walk? <br/>\n",
    "14: SO: Strikeout, total batters struck out <br/>\n",
    "15: SH: Sacrifice bunt, bunt resulting in the batter being out but advances another runner <br/>\n",
    "16: SF: Sacrifice fly, fly ball resulting in the batter being out but advances another runner <br/>\n",
    "17: WP: Wild pitches, pitch out of range for the catcher causing a runner to advance <br/>\n",
    "18: HBP: Hit by pitch?, times batter is hit by a pitch <br/>\n",
    "19: BK: Balk, number of illegal actions <br/>\n",
    "20: 2B: Doubles allowed <br/>\n",
    "21: 3B: Triples allowed <br/>\n",
    "22: GDP: Grounded double plays? <br/>\n",
    "23: ROE: Reached on error?, number of batters on base due to an error <br/>\n",
    "24: W: Win, pitched while their team took the team and won the game <br/>\n",
    "25: L: Loss, pitched while their team lost the lead and lost the game <br/>\n",
    "26: ERA: Earned run average, (allowed runs * 9 / innings pitched ) <br/>\n",
    "27: RS: Run support?, average opposition score (per game, not per inning) <br/>\n",
    "28: PW: Total player rating, linear weighting of multiple statistics, https://en.wikipedia.org/wiki/Total_player_rating <br/>\n",
    "29: HAND: Handedness, Pitching hand (1 = right, -1 = left) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "activated-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromFile(fileName, pitchingDataList, battingDataList):\n",
    "    fileData=np.loadtxt(fileName, delimiter=',') \n",
    "    [N,dim]=np.shape(fileData) #set up matrix from file\n",
    "    \n",
    "    fileX = np.zeros((N, dim))\n",
    "    dataY = np.zeros((N))\n",
    "    \n",
    "    fileX = fileData[:, 0:dim - 1] #remove output from the x array\n",
    "    dataY[:] = fileData[:, dim - 1]\n",
    "    \n",
    "    dataX = np.zeros((N, 2*len(pitchingDataList) + 18*len(battingDataList)))\n",
    "    dataXIndex = 0\n",
    "    for i in pitchingDataList: #add data for home pitcher\n",
    "        dataX[:,dataXIndex] = fileX[:,i]\n",
    "        dataXIndex = dataXIndex + 1\n",
    "    for i in range(9): #add data for home batters\n",
    "        for j in battingDataList:\n",
    "            dataX[:,dataXIndex] = fileX[:,(30 + 23*i + j)]\n",
    "            dataXIndex = dataXIndex + 1\n",
    "    for i in pitchingDataList: #add data for away pitcher\n",
    "        dataX[:,dataXIndex] = fileX[:,(30 + 23*9 + i)]\n",
    "        dataXIndex = dataXIndex + 1\n",
    "    for i in range(9): #add data for away batters\n",
    "        for j in battingDataList:\n",
    "            dataX[:,dataXIndex] = fileX[:,(2*30 + 23*(9+i) + j)]\n",
    "            dataXIndex = dataXIndex + 1\n",
    "    \n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "maritime-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanAndStd(data): #get the mean and standard deviation of data columns\n",
    "    means = [] #mean for each column\n",
    "    stds = [] #standard deviation for each column\n",
    "    for i in range(np.shape(data)[1]):\n",
    "        mean = sum(data[:,i]) / len(data) \n",
    "        means.append(mean)\n",
    "        stds.append( np.sqrt( sum((mean - data[:,i])**2)/len(data)) )\n",
    "    return means, stds\n",
    "\n",
    "def applyMeanAndStd(data, means, stds):\n",
    "    newData = data\n",
    "    for i in range(np.shape(newData)[1]):\n",
    "        newData[:,i] = (data[:,i] - means[i])/stds[i] #normalize so that mean = 0, std = 1\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "single-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(trainX, trainY, testX, testY, model, epochCount): #run and graph model results\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    historyData = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=epochCount, verbose = 1)\n",
    "    eIn = historyData.history[\"accuracy\"]\n",
    "    eOut = historyData.history[\"val_accuracy\"]\n",
    "    \n",
    "    for i in range(len(eIn)):\n",
    "        eIn[i] = 1-eIn[i]\n",
    "    for i in range(len(eOut)):\n",
    "        eOut[i] = 1-eOut[i]\n",
    "\n",
    "    print('Train error:', eIn[-1])\n",
    "    print('Test error: ', eOut[-1])\n",
    "    \n",
    "    #return error data to be plot later\n",
    "    return eIn, eOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "indie-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\train.txt\"\n",
    "valFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\val.txt\"\n",
    "#testFileName = \"F:\\\\Users\\\\Daniel\\\\Machine Learning Work\\\\Baseball work\\\\ML Data\\\\test.txt\"\n",
    "\n",
    "batDataList = [19, 20, 21, 17, 22] #on base %, hit %, slug %, bases stolen, hand\n",
    "#batDataList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "pitDataList = [26, 29] #era, hand\n",
    "#pitDataList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]\n",
    "\n",
    "trainX, trainY = getDataFromFile(trainFileName, pitDataList, batDataList)\n",
    "valX, valY = getDataFromFile(valFileName, pitDataList, batDataList)\n",
    "#testX, testY = getDataFromFile(testFileName)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "danish-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMeans, dataStds = getMeanAndStd(trainX)\n",
    "trainX = applyMeanAndStd(trainX, dataMeans, dataStds)\n",
    "valX = applyMeanAndStd(valX, dataMeans, dataStds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "commercial-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.7139 - accuracy: 0.5392 - val_loss: 0.6920 - val_accuracy: 0.5311\n",
      "Epoch 2/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6843 - accuracy: 0.5598 - val_loss: 0.6837 - val_accuracy: 0.5649\n",
      "Epoch 3/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6849 - accuracy: 0.5569 - val_loss: 0.6883 - val_accuracy: 0.5526\n",
      "Epoch 4/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6836 - accuracy: 0.5629 - val_loss: 0.6860 - val_accuracy: 0.5487\n",
      "Epoch 5/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6831 - accuracy: 0.5594 - val_loss: 0.6859 - val_accuracy: 0.5487\n",
      "Epoch 6/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6828 - accuracy: 0.5650 - val_loss: 0.6822 - val_accuracy: 0.5638\n",
      "Epoch 7/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6837 - accuracy: 0.5610 - val_loss: 0.6827 - val_accuracy: 0.5579\n",
      "Epoch 8/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6824 - accuracy: 0.5637 - val_loss: 0.6825 - val_accuracy: 0.5595\n",
      "Epoch 9/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6824 - accuracy: 0.5678 - val_loss: 0.6811 - val_accuracy: 0.5609\n",
      "Epoch 10/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5711 - val_loss: 0.6828 - val_accuracy: 0.5702\n",
      "Epoch 11/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6820 - accuracy: 0.5688 - val_loss: 0.6843 - val_accuracy: 0.5545\n",
      "Epoch 12/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6817 - accuracy: 0.5664 - val_loss: 0.6945 - val_accuracy: 0.5556\n",
      "Epoch 13/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6841 - accuracy: 0.5610 - val_loss: 0.6821 - val_accuracy: 0.5629: 0s - loss:\n",
      "Epoch 14/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5698 - val_loss: 0.6880 - val_accuracy: 0.5403\n",
      "Epoch 15/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6826 - accuracy: 0.5638 - val_loss: 0.6818 - val_accuracy: 0.5589\n",
      "Epoch 16/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5703 - val_loss: 0.6828 - val_accuracy: 0.5626\n",
      "Epoch 17/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6815 - accuracy: 0.5650 - val_loss: 0.6824 - val_accuracy: 0.5648\n",
      "Epoch 18/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5723 - val_loss: 0.6817 - val_accuracy: 0.5605\n",
      "Epoch 19/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5669 - val_loss: 0.6822 - val_accuracy: 0.5612\n",
      "Epoch 20/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5696 - val_loss: 0.6824 - val_accuracy: 0.5587\n",
      "Epoch 21/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5713 - val_loss: 0.6822 - val_accuracy: 0.5614\n",
      "Epoch 22/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6824 - accuracy: 0.5658 - val_loss: 0.6821 - val_accuracy: 0.5592\n",
      "Epoch 23/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5722 - val_loss: 0.6837 - val_accuracy: 0.5609\n",
      "Epoch 24/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5741 - val_loss: 0.6817 - val_accuracy: 0.5600\n",
      "Epoch 25/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5684 - val_loss: 0.6868 - val_accuracy: 0.5627\n",
      "Epoch 26/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5667 - val_loss: 0.6887 - val_accuracy: 0.5605\n",
      "Epoch 27/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5744 - val_loss: 0.6819 - val_accuracy: 0.5626\n",
      "Epoch 28/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6807 - accuracy: 0.5707 - val_loss: 0.6819 - val_accuracy: 0.5630\n",
      "Epoch 29/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5763 - val_loss: 0.6818 - val_accuracy: 0.5605\n",
      "Epoch 30/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5676 - val_loss: 0.6817 - val_accuracy: 0.5580\n",
      "Epoch 31/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5755 - val_loss: 0.6833 - val_accuracy: 0.5605\n",
      "Epoch 32/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5708 - val_loss: 0.6820 - val_accuracy: 0.5583\n",
      "Epoch 33/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5737 - val_loss: 0.6819 - val_accuracy: 0.5598\n",
      "Epoch 34/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5715 - val_loss: 0.6819 - val_accuracy: 0.5604\n",
      "Epoch 35/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5686 - val_loss: 0.6828 - val_accuracy: 0.5624\n",
      "Epoch 36/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5661 - val_loss: 0.6823 - val_accuracy: 0.5591\n",
      "Epoch 37/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5701 - val_loss: 0.6823 - val_accuracy: 0.5576\n",
      "Epoch 38/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5678 - val_loss: 0.6825 - val_accuracy: 0.5577\n",
      "Epoch 39/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5704 - val_loss: 0.6820 - val_accuracy: 0.5614\n",
      "Epoch 40/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5762 - val_loss: 0.6824 - val_accuracy: 0.5616\n",
      "Epoch 41/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6806 - accuracy: 0.5626 - val_loss: 0.6847 - val_accuracy: 0.5609\n",
      "Epoch 42/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6788 - accuracy: 0.5722 - val_loss: 0.6832 - val_accuracy: 0.5587\n",
      "Epoch 43/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5689 - val_loss: 0.6822 - val_accuracy: 0.5608\n",
      "Epoch 44/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5691 - val_loss: 0.6817 - val_accuracy: 0.5598\n",
      "Epoch 45/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5678 - val_loss: 0.6822 - val_accuracy: 0.5605\n",
      "Epoch 46/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5673 - val_loss: 0.6824 - val_accuracy: 0.5599\n",
      "Epoch 47/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5728 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 48/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5759 - val_loss: 0.6818 - val_accuracy: 0.5600\n",
      "Epoch 49/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5724 - val_loss: 0.6826 - val_accuracy: 0.5615\n",
      "Epoch 50/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5739 - val_loss: 0.6834 - val_accuracy: 0.5601\n",
      "Epoch 51/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6821 - accuracy: 0.5628 - val_loss: 0.6837 - val_accuracy: 0.5621\n",
      "Epoch 52/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6818 - accuracy: 0.5678 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 53/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5722 - val_loss: 0.6816 - val_accuracy: 0.5621\n",
      "Epoch 54/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5737 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 55/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5726 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 56/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5698 - val_loss: 0.6832 - val_accuracy: 0.5599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6807 - accuracy: 0.5690 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 58/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.5680 - val_loss: 0.6818 - val_accuracy: 0.5608\n",
      "Epoch 59/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5732 - val_loss: 0.6821 - val_accuracy: 0.5610\n",
      "Epoch 60/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6786 - accuracy: 0.5736 - val_loss: 0.6825 - val_accuracy: 0.5617\n",
      "Epoch 61/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6804 - accuracy: 0.5699 - val_loss: 0.6817 - val_accuracy: 0.5598\n",
      "Epoch 62/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5717 - val_loss: 0.6818 - val_accuracy: 0.5608\n",
      "Epoch 63/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5712 - val_loss: 0.6820 - val_accuracy: 0.5598\n",
      "Epoch 64/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5753 - val_loss: 0.6822 - val_accuracy: 0.5616\n",
      "Epoch 65/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6803 - accuracy: 0.5687 - val_loss: 0.6824 - val_accuracy: 0.5575s: 0.6803 - accuracy: 0. - ETA: 0s - loss: 0.6803 - accura\n",
      "Epoch 66/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5673 - val_loss: 0.6820 - val_accuracy: 0.5609\n",
      "Epoch 67/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5725 - val_loss: 0.6817 - val_accuracy: 0.5601\n",
      "Epoch 68/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5693 - val_loss: 0.6820 - val_accuracy: 0.5605\n",
      "Epoch 69/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5728 - val_loss: 0.6817 - val_accuracy: 0.5570\n",
      "Epoch 70/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5709 - val_loss: 0.6827 - val_accuracy: 0.5612\n",
      "Epoch 71/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5741 - val_loss: 0.6826 - val_accuracy: 0.5594 - ETA: 0s - loss: 0.6\n",
      "Epoch 72/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5682 - val_loss: 0.6820 - val_accuracy: 0.5602\n",
      "Epoch 73/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5755 - val_loss: 0.6827 - val_accuracy: 0.5577\n",
      "Epoch 74/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5698 - val_loss: 0.6820 - val_accuracy: 0.5591\n",
      "Epoch 75/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5704 - val_loss: 0.6823 - val_accuracy: 0.5650\n",
      "Epoch 76/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5705 - val_loss: 0.6820 - val_accuracy: 0.5609\n",
      "Epoch 77/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5715 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 78/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5706 - val_loss: 0.6820 - val_accuracy: 0.5606\n",
      "Epoch 79/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5690 - val_loss: 0.6825 - val_accuracy: 0.5592\n",
      "Epoch 80/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5739 - val_loss: 0.6818 - val_accuracy: 0.5629\n",
      "Epoch 81/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5678 - val_loss: 0.6818 - val_accuracy: 0.5634\n",
      "Epoch 82/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5687 - val_loss: 0.6821 - val_accuracy: 0.5639\n",
      "Epoch 83/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5779 - val_loss: 0.6822 - val_accuracy: 0.5611\n",
      "Epoch 84/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5743 - val_loss: 0.6817 - val_accuracy: 0.5623\n",
      "Epoch 85/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5703 - val_loss: 0.6826 - val_accuracy: 0.5601\n",
      "Epoch 86/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5690 - val_loss: 0.6819 - val_accuracy: 0.5627\n",
      "Epoch 87/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6796 - accuracy: 0.5708 - val_loss: 0.6818 - val_accuracy: 0.5629\n",
      "Epoch 88/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5749 - val_loss: 0.6815 - val_accuracy: 0.5614\n",
      "Epoch 89/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5758 - val_loss: 0.6820 - val_accuracy: 0.5630\n",
      "Epoch 90/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5729 - val_loss: 0.6817 - val_accuracy: 0.5605\n",
      "Epoch 91/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5686 - val_loss: 0.6818 - val_accuracy: 0.5634\n",
      "Epoch 92/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5780 - val_loss: 0.6823 - val_accuracy: 0.5579\n",
      "Epoch 93/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5712 - val_loss: 0.6823 - val_accuracy: 0.5634\n",
      "Epoch 94/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5742 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 95/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5755 - val_loss: 0.6819 - val_accuracy: 0.5601\n",
      "Epoch 96/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5715 - val_loss: 0.6821 - val_accuracy: 0.5621\n",
      "Epoch 97/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6816 - accuracy: 0.5685 - val_loss: 0.6826 - val_accuracy: 0.5602\n",
      "Epoch 98/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5681 - val_loss: 0.6818 - val_accuracy: 0.5617\n",
      "Epoch 99/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5719 - val_loss: 0.6818 - val_accuracy: 0.5610\n",
      "Epoch 100/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5712 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 101/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5792 - val_loss: 0.6827 - val_accuracy: 0.5598\n",
      "Epoch 102/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5740 - val_loss: 0.6822 - val_accuracy: 0.5609\n",
      "Epoch 103/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5725 - val_loss: 0.6819 - val_accuracy: 0.5600\n",
      "Epoch 104/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5725 - val_loss: 0.6818 - val_accuracy: 0.5640\n",
      "Epoch 105/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5712 - val_loss: 0.6830 - val_accuracy: 0.5625\n",
      "Epoch 106/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5744 - val_loss: 0.6818 - val_accuracy: 0.5626\n",
      "Epoch 107/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5722 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 108/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5740 - val_loss: 0.6820 - val_accuracy: 0.5611\n",
      "Epoch 109/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5755 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 110/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5707 - val_loss: 0.6817 - val_accuracy: 0.5612\n",
      "Epoch 111/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5684 - val_loss: 0.6835 - val_accuracy: 0.5576\n",
      "Epoch 112/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5705 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 113/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5713 - val_loss: 0.6822 - val_accuracy: 0.5617\n",
      "Epoch 114/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5738 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 115/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5706 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 116/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5733 - val_loss: 0.6819 - val_accuracy: 0.5624\n",
      "Epoch 117/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5742 - val_loss: 0.6821 - val_accuracy: 0.5599\n",
      "Epoch 118/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5700 - val_loss: 0.6821 - val_accuracy: 0.5605\n",
      "Epoch 119/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5668 - val_loss: 0.6821 - val_accuracy: 0.5612\n",
      "Epoch 120/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5743 - val_loss: 0.6822 - val_accuracy: 0.5617\n",
      "Epoch 121/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5715 - val_loss: 0.6821 - val_accuracy: 0.5608\n",
      "Epoch 122/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5748 - val_loss: 0.6822 - val_accuracy: 0.5623\n",
      "Epoch 123/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5747 - val_loss: 0.6821 - val_accuracy: 0.5604\n",
      "Epoch 124/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5753 - val_loss: 0.6822 - val_accuracy: 0.5608\n",
      "Epoch 125/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5776 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 126/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5762 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 127/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5737 - val_loss: 0.6824 - val_accuracy: 0.5629\n",
      "Epoch 128/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6819 - accuracy: 0.5692 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 129/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5731 - val_loss: 0.6829 - val_accuracy: 0.5621\n",
      "Epoch 130/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5731 - val_loss: 0.6827 - val_accuracy: 0.5626\n",
      "Epoch 131/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5731 - val_loss: 0.6828 - val_accuracy: 0.5627\n",
      "Epoch 132/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6817 - accuracy: 0.5716 - val_loss: 0.6820 - val_accuracy: 0.5606\n",
      "Epoch 133/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5730 - val_loss: 0.6820 - val_accuracy: 0.5614\n",
      "Epoch 134/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5756 - val_loss: 0.6821 - val_accuracy: 0.5629\n",
      "Epoch 135/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5681 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 136/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6764 - accuracy: 0.5792 - val_loss: 0.6819 - val_accuracy: 0.5642\n",
      "Epoch 137/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5738 - val_loss: 0.6826 - val_accuracy: 0.5623\n",
      "Epoch 138/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5691 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 139/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5741 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 140/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5719 - val_loss: 0.6820 - val_accuracy: 0.5606\n",
      "Epoch 141/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5681 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 142/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5735 - val_loss: 0.6823 - val_accuracy: 0.5611\n",
      "Epoch 143/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5733 - val_loss: 0.6824 - val_accuracy: 0.5573\n",
      "Epoch 144/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5713 - val_loss: 0.6820 - val_accuracy: 0.5606\n",
      "Epoch 145/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5676 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 146/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5717 - val_loss: 0.6819 - val_accuracy: 0.5608\n",
      "Epoch 147/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5676 - val_loss: 0.6818 - val_accuracy: 0.5604\n",
      "Epoch 148/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5746 - val_loss: 0.6874 - val_accuracy: 0.5600\n",
      "Epoch 149/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5734 - val_loss: 0.6844 - val_accuracy: 0.5587\n",
      "Epoch 150/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5738 - val_loss: 0.6828 - val_accuracy: 0.5612\n",
      "Epoch 151/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5728 - val_loss: 0.6820 - val_accuracy: 0.5629\n",
      "Epoch 152/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5762 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 153/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5750 - val_loss: 0.6818 - val_accuracy: 0.5641\n",
      "Epoch 154/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5690 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 155/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5737 - val_loss: 0.6820 - val_accuracy: 0.5627\n",
      "Epoch 156/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5723 - val_loss: 0.6847 - val_accuracy: 0.5610\n",
      "Epoch 157/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5769 - val_loss: 0.6835 - val_accuracy: 0.5635\n",
      "Epoch 158/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5720 - val_loss: 0.6820 - val_accuracy: 0.5601\n",
      "Epoch 159/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5690 - val_loss: 0.6819 - val_accuracy: 0.5599\n",
      "Epoch 160/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5719 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 161/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5702 - val_loss: 0.6827 - val_accuracy: 0.5587\n",
      "Epoch 162/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5723 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 163/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5742 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 164/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5727 - val_loss: 0.6822 - val_accuracy: 0.5614\n",
      "Epoch 165/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5686 - val_loss: 0.6819 - val_accuracy: 0.5627\n",
      "Epoch 166/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5681 - val_loss: 0.6830 - val_accuracy: 0.5642\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5748 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 168/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6818 - accuracy: 0.5665 - val_loss: 0.6826 - val_accuracy: 0.5625\n",
      "Epoch 169/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5714 - val_loss: 0.6817 - val_accuracy: 0.5610\n",
      "Epoch 170/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5725 - val_loss: 0.6817 - val_accuracy: 0.5611\n",
      "Epoch 171/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5703 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 172/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5736 - val_loss: 0.6823 - val_accuracy: 0.5606\n",
      "Epoch 173/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5743 - val_loss: 0.6821 - val_accuracy: 0.5616\n",
      "Epoch 174/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5696 - val_loss: 0.6820 - val_accuracy: 0.5625\n",
      "Epoch 175/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5701 - val_loss: 0.6819 - val_accuracy: 0.5599\n",
      "Epoch 176/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5733 - val_loss: 0.6818 - val_accuracy: 0.5615\n",
      "Epoch 177/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5735 - val_loss: 0.6824 - val_accuracy: 0.5592\n",
      "Epoch 178/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5738 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 179/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5696 - val_loss: 0.6818 - val_accuracy: 0.5614\n",
      "Epoch 180/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5651 - val_loss: 0.6829 - val_accuracy: 0.5624\n",
      "Epoch 181/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5719 - val_loss: 0.6819 - val_accuracy: 0.5604\n",
      "Epoch 182/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5743 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 183/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5645 - val_loss: 0.6819 - val_accuracy: 0.5635\n",
      "Epoch 184/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5731 - val_loss: 0.6818 - val_accuracy: 0.5626\n",
      "Epoch 185/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6770 - accuracy: 0.5727 - val_loss: 0.6822 - val_accuracy: 0.5601\n",
      "Epoch 186/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5744 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 187/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6815 - accuracy: 0.5704 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 188/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5727 - val_loss: 0.6844 - val_accuracy: 0.5601\n",
      "Epoch 189/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5698 - val_loss: 0.6822 - val_accuracy: 0.5623\n",
      "Epoch 190/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5704 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 191/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5701 - val_loss: 0.6874 - val_accuracy: 0.5619\n",
      "Epoch 192/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5768 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 193/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5667 - val_loss: 0.6821 - val_accuracy: 0.5635\n",
      "Epoch 194/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5736 - val_loss: 0.6822 - val_accuracy: 0.5624\n",
      "Epoch 195/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5760 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 196/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5735 - val_loss: 0.6825 - val_accuracy: 0.5617\n",
      "Epoch 197/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5741 - val_loss: 0.6821 - val_accuracy: 0.5619\n",
      "Epoch 198/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5725 - val_loss: 0.6820 - val_accuracy: 0.5629\n",
      "Epoch 199/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5728 - val_loss: 0.6820 - val_accuracy: 0.5621\n",
      "Epoch 200/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5733 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 201/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5730 - val_loss: 0.6824 - val_accuracy: 0.5608\n",
      "Epoch 202/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5754 - val_loss: 0.6821 - val_accuracy: 0.5606\n",
      "Epoch 203/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5702 - val_loss: 0.6824 - val_accuracy: 0.5639\n",
      "Epoch 204/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5694 - val_loss: 0.6820 - val_accuracy: 0.5604\n",
      "Epoch 205/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5703 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 206/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5760 - val_loss: 0.6824 - val_accuracy: 0.5617\n",
      "Epoch 207/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5779 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 208/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5714 - val_loss: 0.6819 - val_accuracy: 0.5606\n",
      "Epoch 209/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5710 - val_loss: 0.6823 - val_accuracy: 0.5608\n",
      "Epoch 210/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5732 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 211/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5732 - val_loss: 0.6817 - val_accuracy: 0.5629\n",
      "Epoch 212/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5682 - val_loss: 0.6824 - val_accuracy: 0.5638\n",
      "Epoch 213/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5693 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 214/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5760 - val_loss: 0.6821 - val_accuracy: 0.5612\n",
      "Epoch 215/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5727 - val_loss: 0.6827 - val_accuracy: 0.5623\n",
      "Epoch 216/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5728 - val_loss: 0.6818 - val_accuracy: 0.5633\n",
      "Epoch 217/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5747 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 218/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5741 - val_loss: 0.6820 - val_accuracy: 0.5627\n",
      "Epoch 219/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5747 - val_loss: 0.6818 - val_accuracy: 0.5611\n",
      "Epoch 220/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5704 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 221/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5738 - val_loss: 0.6819 - val_accuracy: 0.5599\n",
      "Epoch 222/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5684 - val_loss: 0.6822 - val_accuracy: 0.5601\n",
      "Epoch 223/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5757 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 224/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5742 - val_loss: 0.6823 - val_accuracy: 0.5624\n",
      "Epoch 225/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5718 - val_loss: 0.6827 - val_accuracy: 0.5612\n",
      "Epoch 226/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5720 - val_loss: 0.6842 - val_accuracy: 0.5631\n",
      "Epoch 227/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6824 - accuracy: 0.5673 - val_loss: 0.6823 - val_accuracy: 0.5612\n",
      "Epoch 228/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5712 - val_loss: 0.6824 - val_accuracy: 0.5626\n",
      "Epoch 229/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5751 - val_loss: 0.6819 - val_accuracy: 0.5610\n",
      "Epoch 230/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5715 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 231/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5695 - val_loss: 0.6841 - val_accuracy: 0.5571\n",
      "Epoch 232/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5769 - val_loss: 0.6817 - val_accuracy: 0.5616\n",
      "Epoch 233/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5726 - val_loss: 0.6820 - val_accuracy: 0.5584\n",
      "Epoch 234/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5717 - val_loss: 0.6824 - val_accuracy: 0.5638\n",
      "Epoch 235/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5685 - val_loss: 0.6818 - val_accuracy: 0.5590\n",
      "Epoch 236/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5758 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 237/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5718 - val_loss: 0.6828 - val_accuracy: 0.5623\n",
      "Epoch 238/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5684 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 239/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6762 - accuracy: 0.5799 - val_loss: 0.6822 - val_accuracy: 0.5595\n",
      "Epoch 240/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5689 - val_loss: 0.6817 - val_accuracy: 0.5630\n",
      "Epoch 241/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5751 - val_loss: 0.6822 - val_accuracy: 0.5599\n",
      "Epoch 242/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5665 - val_loss: 0.6825 - val_accuracy: 0.5624 0.6802 - accura\n",
      "Epoch 243/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5773 - val_loss: 0.6824 - val_accuracy: 0.5621\n",
      "Epoch 244/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5745 - val_loss: 0.6821 - val_accuracy: 0.5642\n",
      "Epoch 245/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5768 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 246/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5751 - val_loss: 0.6820 - val_accuracy: 0.5635\n",
      "Epoch 247/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5685 - val_loss: 0.6830 - val_accuracy: 0.5602\n",
      "Epoch 248/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5723 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 249/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5726 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 250/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5709 - val_loss: 0.6822 - val_accuracy: 0.5604\n",
      "Epoch 251/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6775 - accuracy: 0.5748 - val_loss: 0.6820 - val_accuracy: 0.5625\n",
      "Epoch 252/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5677 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 253/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5707 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 254/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5726 - val_loss: 0.6822 - val_accuracy: 0.5616\n",
      "Epoch 255/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5680 - val_loss: 0.6819 - val_accuracy: 0.5624\n",
      "Epoch 256/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5693 - val_loss: 0.6866 - val_accuracy: 0.5430\n",
      "Epoch 257/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6821 - accuracy: 0.5629 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 258/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5733 - val_loss: 0.6818 - val_accuracy: 0.5604\n",
      "Epoch 259/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5717 - val_loss: 0.6820 - val_accuracy: 0.5641\n",
      "Epoch 260/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5745 - val_loss: 0.6817 - val_accuracy: 0.5600\n",
      "Epoch 261/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5673 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 262/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5703 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 263/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5706 - val_loss: 0.6908 - val_accuracy: 0.5610\n",
      "Epoch 264/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6765 - accuracy: 0.5764 - val_loss: 0.6820 - val_accuracy: 0.5609\n",
      "Epoch 265/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5716 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 266/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5711 - val_loss: 0.6818 - val_accuracy: 0.5642\n",
      "Epoch 267/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5736 - val_loss: 0.6818 - val_accuracy: 0.5612\n",
      "Epoch 268/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5784 - val_loss: 0.6819 - val_accuracy: 0.5630\n",
      "Epoch 269/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5749 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 270/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5724 - val_loss: 0.6818 - val_accuracy: 0.5626\n",
      "Epoch 271/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5715 - val_loss: 0.6820 - val_accuracy: 0.5602\n",
      "Epoch 272/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5734 - val_loss: 0.6820 - val_accuracy: 0.5640\n",
      "Epoch 273/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5733 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 274/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5773 - val_loss: 0.6818 - val_accuracy: 0.5617\n",
      "Epoch 275/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5744 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 276/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5668 - val_loss: 0.6820 - val_accuracy: 0.5602\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5725 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 278/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5734 - val_loss: 0.6836 - val_accuracy: 0.5616\n",
      "Epoch 279/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5718 - val_loss: 0.6821 - val_accuracy: 0.5612\n",
      "Epoch 280/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5742 - val_loss: 0.6828 - val_accuracy: 0.5614\n",
      "Epoch 281/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5748 - val_loss: 0.6862 - val_accuracy: 0.5634\n",
      "Epoch 282/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5747 - val_loss: 0.6824 - val_accuracy: 0.5614\n",
      "Epoch 283/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5742 - val_loss: 0.6822 - val_accuracy: 0.5626\n",
      "Epoch 284/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5735 - val_loss: 0.6826 - val_accuracy: 0.5627\n",
      "Epoch 285/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5755 - val_loss: 0.6819 - val_accuracy: 0.5598\n",
      "Epoch 286/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5676 - val_loss: 0.6818 - val_accuracy: 0.5635\n",
      "Epoch 287/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5708 - val_loss: 0.6823 - val_accuracy: 0.5595\n",
      "Epoch 288/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5720 - val_loss: 0.6825 - val_accuracy: 0.5610\n",
      "Epoch 289/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5714 - val_loss: 0.6822 - val_accuracy: 0.5617\n",
      "Epoch 290/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5747 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 291/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5757 - val_loss: 0.6825 - val_accuracy: 0.5608\n",
      "Epoch 292/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5691 - val_loss: 0.6826 - val_accuracy: 0.5611\n",
      "Epoch 293/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5719 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 294/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5732 - val_loss: 0.6819 - val_accuracy: 0.5601\n",
      "Epoch 295/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5750 - val_loss: 0.6821 - val_accuracy: 0.5606\n",
      "Epoch 296/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5773 - val_loss: 0.6822 - val_accuracy: 0.5599\n",
      "Epoch 297/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5750 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 298/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.5756 - val_loss: 0.6819 - val_accuracy: 0.5604\n",
      "Epoch 299/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5698 - val_loss: 0.6817 - val_accuracy: 0.5612\n",
      "Epoch 300/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5692 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 301/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5728 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 302/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5686 - val_loss: 0.6819 - val_accuracy: 0.5630\n",
      "Epoch 303/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5726 - val_loss: 0.6845 - val_accuracy: 0.5635\n",
      "Epoch 304/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5701 - val_loss: 0.6822 - val_accuracy: 0.5617\n",
      "Epoch 305/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5740 - val_loss: 0.6820 - val_accuracy: 0.5625\n",
      "Epoch 306/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5731 - val_loss: 0.6840 - val_accuracy: 0.5633\n",
      "Epoch 307/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5712 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 308/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6775 - accuracy: 0.5739 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 309/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5690 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 310/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5670 - val_loss: 0.6835 - val_accuracy: 0.5635\n",
      "Epoch 311/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5677 - val_loss: 0.6818 - val_accuracy: 0.5648\n",
      "Epoch 312/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6806 - accuracy: 0.5718 - val_loss: 0.6832 - val_accuracy: 0.5608\n",
      "Epoch 313/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5737 - val_loss: 0.6825 - val_accuracy: 0.5620\n",
      "Epoch 314/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5744 - val_loss: 0.6818 - val_accuracy: 0.5612\n",
      "Epoch 315/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5694 - val_loss: 0.6873 - val_accuracy: 0.5616\n",
      "Epoch 316/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5710 - val_loss: 0.6820 - val_accuracy: 0.5630\n",
      "Epoch 317/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5733 - val_loss: 0.6822 - val_accuracy: 0.5636\n",
      "Epoch 318/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5746 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 319/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5686 - val_loss: 0.6817 - val_accuracy: 0.5627\n",
      "Epoch 320/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5757 - val_loss: 0.6820 - val_accuracy: 0.5601\n",
      "Epoch 321/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5716 - val_loss: 0.6823 - val_accuracy: 0.5614\n",
      "Epoch 322/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5721 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 323/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5693 - val_loss: 0.6817 - val_accuracy: 0.5611\n",
      "Epoch 324/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5680 - val_loss: 0.6821 - val_accuracy: 0.5626\n",
      "Epoch 325/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5688 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 326/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6790 - accuracy: 0.5768 - val_loss: 0.6818 - val_accuracy: 0.5610oss: 0.6790 - accuracy: \n",
      "Epoch 327/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6779 - accuracy: 0.5760 - val_loss: 0.6822 - val_accuracy: 0.5612\n",
      "Epoch 328/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5758 - val_loss: 0.6820 - val_accuracy: 0.5626: 0s - loss: 0.6792 - accuracy: 0.57\n",
      "Epoch 329/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6779 - accuracy: 0.5776 - val_loss: 0.6818 - val_accuracy: 0.5614\n",
      "Epoch 330/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5751 - val_loss: 0.6820 - val_accuracy: 0.5621\n",
      "Epoch 331/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5707 - val_loss: 0.6821 - val_accuracy: 0.5614\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5761 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 333/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5727 - val_loss: 0.6818 - val_accuracy: 0.5610\n",
      "Epoch 334/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5705 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 335/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5774 - val_loss: 0.6818 - val_accuracy: 0.5624780 - ac\n",
      "Epoch 336/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5725 - val_loss: 0.6818 - val_accuracy: 0.5615\n",
      "Epoch 337/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5728 - val_loss: 0.6818 - val_accuracy: 0.5610\n",
      "Epoch 338/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5755 - val_loss: 0.6820 - val_accuracy: 0.5625\n",
      "Epoch 339/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5729 - val_loss: 0.6818 - val_accuracy: 0.5599\n",
      "Epoch 340/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5707 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 341/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5704 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 342/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5699 - val_loss: 0.6822 - val_accuracy: 0.5611\n",
      "Epoch 343/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5725 - val_loss: 0.6818 - val_accuracy: 0.5623\n",
      "Epoch 344/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5758 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 345/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5722 - val_loss: 0.6819 - val_accuracy: 0.5631\n",
      "Epoch 346/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5742 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 347/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5708 - val_loss: 0.6821 - val_accuracy: 0.5610\n",
      "Epoch 348/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5737 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 349/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5765 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 350/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5725 - val_loss: 0.6826 - val_accuracy: 0.5615\n",
      "Epoch 351/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5742 - val_loss: 0.6826 - val_accuracy: 0.5620\n",
      "Epoch 352/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5719 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 353/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5730 - val_loss: 0.6818 - val_accuracy: 0.5633\n",
      "Epoch 354/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5727 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 355/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5748 - val_loss: 0.6818 - val_accuracy: 0.5617\n",
      "Epoch 356/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5734 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 357/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5712 - val_loss: 0.6818 - val_accuracy: 0.5629\n",
      "Epoch 358/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5700 - val_loss: 0.6822 - val_accuracy: 0.5610\n",
      "Epoch 359/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5706 - val_loss: 0.6830 - val_accuracy: 0.5623\n",
      "Epoch 360/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5706 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 361/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5719 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 362/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5726 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 363/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5745 - val_loss: 0.6819 - val_accuracy: 0.5604\n",
      "Epoch 364/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5704 - val_loss: 0.6819 - val_accuracy: 0.5601\n",
      "Epoch 365/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5693 - val_loss: 0.6818 - val_accuracy: 0.5598\n",
      "Epoch 366/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5702 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 367/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5788 - val_loss: 0.6826 - val_accuracy: 0.5616\n",
      "Epoch 368/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5726 - val_loss: 0.6820 - val_accuracy: 0.5609\n",
      "Epoch 369/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5747 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 370/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5731 - val_loss: 0.6820 - val_accuracy: 0.5630\n",
      "Epoch 371/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5695 - val_loss: 0.6823 - val_accuracy: 0.5633\n",
      "Epoch 372/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5727 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 373/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5713 - val_loss: 0.6818 - val_accuracy: 0.5606\n",
      "Epoch 374/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5740 - val_loss: 0.6826 - val_accuracy: 0.5612\n",
      "Epoch 375/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5691 - val_loss: 0.6825 - val_accuracy: 0.5624\n",
      "Epoch 376/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5720 - val_loss: 0.6823 - val_accuracy: 0.5627\n",
      "Epoch 377/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5741 - val_loss: 0.6820 - val_accuracy: 0.5629\n",
      "Epoch 378/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5689 - val_loss: 0.6821 - val_accuracy: 0.5594\n",
      "Epoch 379/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5724 - val_loss: 0.6818 - val_accuracy: 0.5608\n",
      "Epoch 380/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5735 - val_loss: 0.6897 - val_accuracy: 0.5595\n",
      "Epoch 381/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5741 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 382/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5784 - val_loss: 0.6819 - val_accuracy: 0.5602\n",
      "Epoch 383/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5713 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 384/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5768 - val_loss: 0.6818 - val_accuracy: 0.5608\n",
      "Epoch 385/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5739 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 386/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5686 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 387/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6819 - accuracy: 0.5673 - val_loss: 0.6825 - val_accuracy: 0.5634\n",
      "Epoch 388/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5719 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 389/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5791 - val_loss: 0.6819 - val_accuracy: 0.5627\n",
      "Epoch 390/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5724 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 391/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5767 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 392/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5761 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 393/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5686 - val_loss: 0.6821 - val_accuracy: 0.5612\n",
      "Epoch 394/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5698 - val_loss: 0.6817 - val_accuracy: 0.5617\n",
      "Epoch 395/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5747 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 396/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5719 - val_loss: 0.6822 - val_accuracy: 0.5605\n",
      "Epoch 397/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6818 - accuracy: 0.5648 - val_loss: 0.6831 - val_accuracy: 0.5605\n",
      "Epoch 398/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5712 - val_loss: 0.6822 - val_accuracy: 0.5621\n",
      "Epoch 399/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5754 - val_loss: 0.6821 - val_accuracy: 0.5602\n",
      "Epoch 400/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5726 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 401/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5736 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 402/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5699 - val_loss: 0.6821 - val_accuracy: 0.5616\n",
      "Epoch 403/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5754 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 404/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5754 - val_loss: 0.6830 - val_accuracy: 0.5606\n",
      "Epoch 405/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5762 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 406/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5732 - val_loss: 0.6822 - val_accuracy: 0.5627\n",
      "Epoch 407/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6816 - accuracy: 0.5707 - val_loss: 0.6825 - val_accuracy: 0.5649\n",
      "Epoch 408/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5717 - val_loss: 0.6821 - val_accuracy: 0.5594\n",
      "Epoch 409/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5757 - val_loss: 0.6826 - val_accuracy: 0.5615\n",
      "Epoch 410/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5747 - val_loss: 0.6825 - val_accuracy: 0.5605\n",
      "Epoch 411/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5712 - val_loss: 0.6825 - val_accuracy: 0.5610\n",
      "Epoch 412/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5735 - val_loss: 0.6826 - val_accuracy: 0.5617\n",
      "Epoch 413/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5772 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 414/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5716 - val_loss: 0.6821 - val_accuracy: 0.5629\n",
      "Epoch 415/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5771 - val_loss: 0.6820 - val_accuracy: 0.5587\n",
      "Epoch 416/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5703 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 417/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5750 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 418/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5706 - val_loss: 0.6827 - val_accuracy: 0.5639\n",
      "Epoch 419/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5724 - val_loss: 0.6821 - val_accuracy: 0.5605\n",
      "Epoch 420/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5717 - val_loss: 0.6822 - val_accuracy: 0.5602\n",
      "Epoch 421/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5706 - val_loss: 0.6833 - val_accuracy: 0.5616\n",
      "Epoch 422/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5681 - val_loss: 0.6826 - val_accuracy: 0.5595\n",
      "Epoch 423/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5739 - val_loss: 0.6822 - val_accuracy: 0.5586\n",
      "Epoch 424/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5690 - val_loss: 0.6818 - val_accuracy: 0.5642\n",
      "Epoch 425/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5671 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 426/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5700 - val_loss: 0.6832 - val_accuracy: 0.5621\n",
      "Epoch 427/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5698 - val_loss: 0.6822 - val_accuracy: 0.5621\n",
      "Epoch 428/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5683 - val_loss: 0.6832 - val_accuracy: 0.5614\n",
      "Epoch 429/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5648 - val_loss: 0.6821 - val_accuracy: 0.5610\n",
      "Epoch 430/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5755 - val_loss: 0.6818 - val_accuracy: 0.5614\n",
      "Epoch 431/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5727 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 432/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5741 - val_loss: 0.6840 - val_accuracy: 0.5601\n",
      "Epoch 433/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5761 - val_loss: 0.6816 - val_accuracy: 0.5605\n",
      "Epoch 434/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5764 - val_loss: 0.6822 - val_accuracy: 0.5608\n",
      "Epoch 435/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5693 - val_loss: 0.6819 - val_accuracy: 0.5638\n",
      "Epoch 436/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5714 - val_loss: 0.6822 - val_accuracy: 0.5631\n",
      "Epoch 437/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5740 - val_loss: 0.6819 - val_accuracy: 0.5626\n",
      "Epoch 438/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5760 - val_loss: 0.6822 - val_accuracy: 0.5599\n",
      "Epoch 439/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.5754 - val_loss: 0.6823 - val_accuracy: 0.5621\n",
      "Epoch 440/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5717 - val_loss: 0.6818 - val_accuracy: 0.5610\n",
      "Epoch 441/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5749 - val_loss: 0.6818 - val_accuracy: 0.5592\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5741 - val_loss: 0.6819 - val_accuracy: 0.5595\n",
      "Epoch 443/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5677 - val_loss: 0.6826 - val_accuracy: 0.5617\n",
      "Epoch 444/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5734 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 445/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5725 - val_loss: 0.6821 - val_accuracy: 0.5611\n",
      "Epoch 446/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5725 - val_loss: 0.6842 - val_accuracy: 0.5609\n",
      "Epoch 447/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5743 - val_loss: 0.6822 - val_accuracy: 0.5631\n",
      "Epoch 448/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5746 - val_loss: 0.6819 - val_accuracy: 0.5600\n",
      "Epoch 449/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5726 - val_loss: 0.6822 - val_accuracy: 0.5624\n",
      "Epoch 450/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5698 - val_loss: 0.6822 - val_accuracy: 0.5617\n",
      "Epoch 451/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5735 - val_loss: 0.6832 - val_accuracy: 0.5604\n",
      "Epoch 452/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5730 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 453/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5710 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 454/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5778 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 455/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5718 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 456/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5713 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 457/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5745 - val_loss: 0.6820 - val_accuracy: 0.5605\n",
      "Epoch 458/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5684 - val_loss: 0.6827 - val_accuracy: 0.5638\n",
      "Epoch 459/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5762 - val_loss: 0.6819 - val_accuracy: 0.5634\n",
      "Epoch 460/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5762 - val_loss: 0.6816 - val_accuracy: 0.5638\n",
      "Epoch 461/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5729 - val_loss: 0.6819 - val_accuracy: 0.5624\n",
      "Epoch 462/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5752 - val_loss: 0.6873 - val_accuracy: 0.5443\n",
      "Epoch 463/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5752 - val_loss: 0.6820 - val_accuracy: 0.5611\n",
      "Epoch 464/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5736 - val_loss: 0.6835 - val_accuracy: 0.5626\n",
      "Epoch 465/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5736 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 466/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5745 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 467/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5757 - val_loss: 0.6818 - val_accuracy: 0.5606\n",
      "Epoch 468/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5697 - val_loss: 0.6821 - val_accuracy: 0.5614\n",
      "Epoch 469/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5725 - val_loss: 0.6822 - val_accuracy: 0.5614\n",
      "Epoch 470/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5734 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 471/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5706 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 472/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5706 - val_loss: 0.6817 - val_accuracy: 0.5614\n",
      "Epoch 473/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5732 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 474/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5684 - val_loss: 0.6822 - val_accuracy: 0.5602\n",
      "Epoch 475/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5689 - val_loss: 0.6820 - val_accuracy: 0.5640\n",
      "Epoch 476/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5727 - val_loss: 0.6821 - val_accuracy: 0.5594\n",
      "Epoch 477/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5725 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 478/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5727 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 479/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5756 - val_loss: 0.6819 - val_accuracy: 0.5606\n",
      "Epoch 480/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5736 - val_loss: 0.6819 - val_accuracy: 0.5587\n",
      "Epoch 481/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5726 - val_loss: 0.6823 - val_accuracy: 0.5611\n",
      "Epoch 482/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5724 - val_loss: 0.6821 - val_accuracy: 0.5592\n",
      "Epoch 483/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5750 - val_loss: 0.6830 - val_accuracy: 0.5598\n",
      "Epoch 484/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5702 - val_loss: 0.6825 - val_accuracy: 0.5617\n",
      "Epoch 485/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5755 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 486/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5699 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 487/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5718 - val_loss: 0.6826 - val_accuracy: 0.5623\n",
      "Epoch 488/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5699 - val_loss: 0.6819 - val_accuracy: 0.5624\n",
      "Epoch 489/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5747 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 490/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5768 - val_loss: 0.6822 - val_accuracy: 0.5614\n",
      "Epoch 491/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5764 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 492/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5748 - val_loss: 0.6823 - val_accuracy: 0.5605\n",
      "Epoch 493/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6822 - val_accuracy: 0.5616\n",
      "Epoch 494/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5769 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 495/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5773 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 496/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5729 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 497/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5749 - val_loss: 0.6825 - val_accuracy: 0.5600\n",
      "Epoch 498/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5684 - val_loss: 0.6835 - val_accuracy: 0.5608\n",
      "Epoch 499/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5748 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 500/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5727 - val_loss: 0.6823 - val_accuracy: 0.5611\n",
      "Epoch 501/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5719 - val_loss: 0.6903 - val_accuracy: 0.5610\n",
      "Epoch 502/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5706 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 503/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5722 - val_loss: 0.6821 - val_accuracy: 0.5602\n",
      "Epoch 504/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5750 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 505/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5662 - val_loss: 0.6821 - val_accuracy: 0.5621\n",
      "Epoch 506/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5688 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 507/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5697 - val_loss: 0.6825 - val_accuracy: 0.5600\n",
      "Epoch 508/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5741 - val_loss: 0.6822 - val_accuracy: 0.5635\n",
      "Epoch 509/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5738 - val_loss: 0.6823 - val_accuracy: 0.5615\n",
      "Epoch 510/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5709 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 511/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5743 - val_loss: 0.6824 - val_accuracy: 0.5612\n",
      "Epoch 512/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5759 - val_loss: 0.6822 - val_accuracy: 0.5630\n",
      "Epoch 513/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5710 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 514/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5719 - val_loss: 0.6821 - val_accuracy: 0.5619\n",
      "Epoch 515/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5785 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 516/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5730 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 517/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5752 - val_loss: 0.6828 - val_accuracy: 0.5625\n",
      "Epoch 518/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5690 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 519/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5723 - val_loss: 0.6823 - val_accuracy: 0.5615\n",
      "Epoch 520/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5697 - val_loss: 0.6822 - val_accuracy: 0.5619\n",
      "Epoch 521/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5752 - val_loss: 0.6821 - val_accuracy: 0.5630\n",
      "Epoch 522/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6816 - accuracy: 0.5694 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 523/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5770 - val_loss: 0.6824 - val_accuracy: 0.5625\n",
      "Epoch 524/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5785 - val_loss: 0.6819 - val_accuracy: 0.5635\n",
      "Epoch 525/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5725 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 526/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5758 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 527/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5682 - val_loss: 0.6829 - val_accuracy: 0.5616\n",
      "Epoch 528/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5703 - val_loss: 0.6819 - val_accuracy: 0.5599\n",
      "Epoch 529/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5725 - val_loss: 0.6822 - val_accuracy: 0.5625\n",
      "Epoch 530/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5727 - val_loss: 0.6822 - val_accuracy: 0.5626\n",
      "Epoch 531/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6764 - accuracy: 0.5788 - val_loss: 0.6852 - val_accuracy: 0.5623\n",
      "Epoch 532/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5760 - val_loss: 0.6818 - val_accuracy: 0.5605\n",
      "Epoch 533/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5731 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 534/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5731 - val_loss: 0.6817 - val_accuracy: 0.5616\n",
      "Epoch 535/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5740 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 536/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5751 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 537/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5745 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 538/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5739 - val_loss: 0.6822 - val_accuracy: 0.5612\n",
      "Epoch 539/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5700 - val_loss: 0.6823 - val_accuracy: 0.5616\n",
      "Epoch 540/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5721 - val_loss: 0.6834 - val_accuracy: 0.5602\n",
      "Epoch 541/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5743 - val_loss: 0.6837 - val_accuracy: 0.5573\n",
      "Epoch 542/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5712 - val_loss: 0.6819 - val_accuracy: 0.5606\n",
      "Epoch 543/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5701 - val_loss: 0.6826 - val_accuracy: 0.5619\n",
      "Epoch 544/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5767 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 545/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5758 - val_loss: 0.6820 - val_accuracy: 0.5620\n",
      "Epoch 546/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5738 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 547/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5701 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 548/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5707 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 549/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6817 - accuracy: 0.5671 - val_loss: 0.6824 - val_accuracy: 0.5606\n",
      "Epoch 550/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6792 - accuracy: 0.5755 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 551/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5724 - val_loss: 0.6821 - val_accuracy: 0.5634\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5748 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 553/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5688 - val_loss: 0.6823 - val_accuracy: 0.5615\n",
      "Epoch 554/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5701 - val_loss: 0.6821 - val_accuracy: 0.5601\n",
      "Epoch 555/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5729 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 556/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5716 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 557/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5726 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 558/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6786 - accuracy: 0.5755 - val_loss: 0.6823 - val_accuracy: 0.5617\n",
      "Epoch 559/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.5754 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 560/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6791 - accuracy: 0.5723 - val_loss: 0.6822 - val_accuracy: 0.5604\n",
      "Epoch 561/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5714 - val_loss: 0.6831 - val_accuracy: 0.5624\n",
      "Epoch 562/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5778 - val_loss: 0.6818 - val_accuracy: 0.5611\n",
      "Epoch 563/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5714 - val_loss: 0.6821 - val_accuracy: 0.5619\n",
      "Epoch 564/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5773 - val_loss: 0.6830 - val_accuracy: 0.5624\n",
      "Epoch 565/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5713 - val_loss: 0.6822 - val_accuracy: 0.5627\n",
      "Epoch 566/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5713 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 567/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5743 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 568/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5740 - val_loss: 0.6822 - val_accuracy: 0.5631\n",
      "Epoch 569/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5700 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 570/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5712 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 571/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5727 - val_loss: 0.6818 - val_accuracy: 0.5630\n",
      "Epoch 572/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5721 - val_loss: 0.6831 - val_accuracy: 0.5615\n",
      "Epoch 573/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5716 - val_loss: 0.6819 - val_accuracy: 0.5633\n",
      "Epoch 574/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5706 - val_loss: 0.6818 - val_accuracy: 0.5641\n",
      "Epoch 575/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5707 - val_loss: 0.6819 - val_accuracy: 0.5601\n",
      "Epoch 576/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5754 - val_loss: 0.6824 - val_accuracy: 0.5581\n",
      "Epoch 577/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5681 - val_loss: 0.6821 - val_accuracy: 0.5600\n",
      "Epoch 578/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5712 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 579/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5707 - val_loss: 0.6818 - val_accuracy: 0.5610\n",
      "Epoch 580/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5729 - val_loss: 0.6821 - val_accuracy: 0.5626\n",
      "Epoch 581/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5722 - val_loss: 0.6832 - val_accuracy: 0.5655\n",
      "Epoch 582/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5712 - val_loss: 0.6828 - val_accuracy: 0.5617\n",
      "Epoch 583/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5688 - val_loss: 0.6818 - val_accuracy: 0.5610\n",
      "Epoch 584/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5697 - val_loss: 0.6819 - val_accuracy: 0.5630\n",
      "Epoch 585/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5766 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 586/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5728 - val_loss: 0.6818 - val_accuracy: 0.5627\n",
      "Epoch 587/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5762 - val_loss: 0.6828 - val_accuracy: 0.5606\n",
      "Epoch 588/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5704 - val_loss: 0.6823 - val_accuracy: 0.5616\n",
      "Epoch 589/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5725 - val_loss: 0.6822 - val_accuracy: 0.5610\n",
      "Epoch 590/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5662 - val_loss: 0.6818 - val_accuracy: 0.5605\n",
      "Epoch 591/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5748 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 592/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5704 - val_loss: 0.6824 - val_accuracy: 0.5609\n",
      "Epoch 593/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5780 - val_loss: 0.6820 - val_accuracy: 0.5629\n",
      "Epoch 594/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5689 - val_loss: 0.6821 - val_accuracy: 0.5614\n",
      "Epoch 595/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5701 - val_loss: 0.6818 - val_accuracy: 0.5611\n",
      "Epoch 596/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5740 - val_loss: 0.6818 - val_accuracy: 0.5604\n",
      "Epoch 597/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5710 - val_loss: 0.6823 - val_accuracy: 0.5624\n",
      "Epoch 598/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6823 - accuracy: 0.5651 - val_loss: 0.6822 - val_accuracy: 0.5611\n",
      "Epoch 599/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5744 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 600/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5706 - val_loss: 0.6820 - val_accuracy: 0.5592\n",
      "Epoch 601/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5724 - val_loss: 0.6825 - val_accuracy: 0.5625\n",
      "Epoch 602/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5706 - val_loss: 0.6820 - val_accuracy: 0.5614\n",
      "Epoch 603/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5691 - val_loss: 0.6823 - val_accuracy: 0.5623\n",
      "Epoch 604/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5781 - val_loss: 0.6821 - val_accuracy: 0.5644\n",
      "Epoch 605/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5769 - val_loss: 0.6824 - val_accuracy: 0.5629\n",
      "Epoch 606/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5780 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 607/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5740 - val_loss: 0.6822 - val_accuracy: 0.5614\n",
      "Epoch 608/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5719 - val_loss: 0.6818 - val_accuracy: 0.5609\n",
      "Epoch 609/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5745 - val_loss: 0.6841 - val_accuracy: 0.5620\n",
      "Epoch 610/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5719 - val_loss: 0.6828 - val_accuracy: 0.5631\n",
      "Epoch 611/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5761 - val_loss: 0.6823 - val_accuracy: 0.5623\n",
      "Epoch 612/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5707 - val_loss: 0.6825 - val_accuracy: 0.5615\n",
      "Epoch 613/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5732 - val_loss: 0.6821 - val_accuracy: 0.5599\n",
      "Epoch 614/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5687 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 615/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5736 - val_loss: 0.6821 - val_accuracy: 0.5616\n",
      "Epoch 616/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5690 - val_loss: 0.6821 - val_accuracy: 0.5601\n",
      "Epoch 617/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5742 - val_loss: 0.6824 - val_accuracy: 0.5623\n",
      "Epoch 618/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5725 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 619/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5697 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 620/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5749 - val_loss: 0.6819 - val_accuracy: 0.5606\n",
      "Epoch 621/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5716 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 622/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5708 - val_loss: 0.6816 - val_accuracy: 0.5590\n",
      "Epoch 623/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5731 - val_loss: 0.6825 - val_accuracy: 0.5602\n",
      "Epoch 624/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5691 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 625/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5736 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 626/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5756 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 627/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5706 - val_loss: 0.6819 - val_accuracy: 0.5624.680\n",
      "Epoch 628/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5768 - val_loss: 0.6823 - val_accuracy: 0.5617\n",
      "Epoch 629/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5703 - val_loss: 0.6820 - val_accuracy: 0.5611\n",
      "Epoch 630/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5753 - val_loss: 0.6820 - val_accuracy: 0.5611\n",
      "Epoch 631/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5751 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 632/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5694 - val_loss: 0.6818 - val_accuracy: 0.5600\n",
      "Epoch 633/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5725 - val_loss: 0.6821 - val_accuracy: 0.5617\n",
      "Epoch 634/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5666 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 635/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5732 - val_loss: 0.6821 - val_accuracy: 0.5610\n",
      "Epoch 636/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5749 - val_loss: 0.6832 - val_accuracy: 0.5638\n",
      "Epoch 637/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6774 - accuracy: 0.5780 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 638/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5723 - val_loss: 0.6821 - val_accuracy: 0.5608\n",
      "Epoch 639/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5737 - val_loss: 0.6827 - val_accuracy: 0.5620\n",
      "Epoch 640/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5709 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 641/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5711 - val_loss: 0.6822 - val_accuracy: 0.5612\n",
      "Epoch 642/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6820 - accuracy: 0.5661 - val_loss: 0.6821 - val_accuracy: 0.5638\n",
      "Epoch 643/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5774 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 644/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5772 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 645/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5770 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 646/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5660 - val_loss: 0.6819 - val_accuracy: 0.5604\n",
      "Epoch 647/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5753 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 648/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5718 - val_loss: 0.6821 - val_accuracy: 0.5623\n",
      "Epoch 649/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5723 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 650/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5666 - val_loss: 0.6816 - val_accuracy: 0.5596\n",
      "Epoch 651/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.6818 - val_accuracy: 0.5614\n",
      "Epoch 652/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5746 - val_loss: 0.6818 - val_accuracy: 0.5615\n",
      "Epoch 653/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5746 - val_loss: 0.6820 - val_accuracy: 0.5636\n",
      "Epoch 654/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5761 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 655/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5692 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 656/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5781 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 657/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5726 - val_loss: 0.6824 - val_accuracy: 0.5612\n",
      "Epoch 658/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6771 - accuracy: 0.5778 - val_loss: 0.6824 - val_accuracy: 0.5614\n",
      "Epoch 659/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5719 - val_loss: 0.6829 - val_accuracy: 0.5604\n",
      "Epoch 660/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5736 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 661/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5721 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5775 - val_loss: 0.6820 - val_accuracy: 0.5629\n",
      "Epoch 663/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5713 - val_loss: 0.6828 - val_accuracy: 0.5619\n",
      "Epoch 664/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5680 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 665/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5753 - val_loss: 0.6822 - val_accuracy: 0.5615\n",
      "Epoch 666/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5731 - val_loss: 0.6818 - val_accuracy: 0.5623\n",
      "Epoch 667/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5713 - val_loss: 0.6827 - val_accuracy: 0.5611\n",
      "Epoch 668/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5774 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 669/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5686 - val_loss: 0.6819 - val_accuracy: 0.5599\n",
      "Epoch 670/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5735 - val_loss: 0.6817 - val_accuracy: 0.5625\n",
      "Epoch 671/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5700 - val_loss: 0.6822 - val_accuracy: 0.5644\n",
      "Epoch 672/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5670 - val_loss: 0.6827 - val_accuracy: 0.5639\n",
      "Epoch 673/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5706 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 674/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6766 - accuracy: 0.5786 - val_loss: 0.6820 - val_accuracy: 0.5636\n",
      "Epoch 675/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5730 - val_loss: 0.6817 - val_accuracy: 0.5614\n",
      "Epoch 676/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5721 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 677/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5699 - val_loss: 0.6820 - val_accuracy: 0.5602\n",
      "Epoch 678/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5713 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 679/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5737 - val_loss: 0.6820 - val_accuracy: 0.5614\n",
      "Epoch 680/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5733 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 681/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5720 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 682/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5736 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 683/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5711 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 684/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5697 - val_loss: 0.6819 - val_accuracy: 0.5612curacy: \n",
      "Epoch 685/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5678 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 686/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5732 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 687/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5780 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 688/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5706 - val_loss: 0.6825 - val_accuracy: 0.5601\n",
      "Epoch 689/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5706 - val_loss: 0.6849 - val_accuracy: 0.5510\n",
      "Epoch 690/1000\n",
      "1018/1018 [==============================] - 3s 2ms/step - loss: 0.6787 - accuracy: 0.5720 - val_loss: 0.6818 - val_accuracy: 0.5605\n",
      "Epoch 691/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6804 - accuracy: 0.5732 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 692/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5721 - val_loss: 0.6819 - val_accuracy: 0.5608\n",
      "Epoch 693/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5734 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 694/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5758 - val_loss: 0.6820 - val_accuracy: 0.5598\n",
      "Epoch 695/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5684 - val_loss: 0.6817 - val_accuracy: 0.5611\n",
      "Epoch 696/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5698 - val_loss: 0.6823 - val_accuracy: 0.5612\n",
      "Epoch 697/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5741 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 698/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5725 - val_loss: 0.6824 - val_accuracy: 0.5615\n",
      "Epoch 699/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5744 - val_loss: 0.6822 - val_accuracy: 0.5606\n",
      "Epoch 700/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5743 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 701/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5760 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 702/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5734 - val_loss: 0.6822 - val_accuracy: 0.5616\n",
      "Epoch 703/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5784 - val_loss: 0.6826 - val_accuracy: 0.5604\n",
      "Epoch 704/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5706 - val_loss: 0.6821 - val_accuracy: 0.5611\n",
      "Epoch 705/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5714 - val_loss: 0.6826 - val_accuracy: 0.5639\n",
      "Epoch 706/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5756 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 707/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5707 - val_loss: 0.6827 - val_accuracy: 0.5624\n",
      "Epoch 708/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5719 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 709/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5713 - val_loss: 0.6832 - val_accuracy: 0.5616\n",
      "Epoch 710/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5707 - val_loss: 0.6823 - val_accuracy: 0.5625\n",
      "Epoch 711/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5729 - val_loss: 0.6818 - val_accuracy: 0.5627\n",
      "Epoch 712/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5718 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 713/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6775 - accuracy: 0.5757 - val_loss: 0.6818 - val_accuracy: 0.5626\n",
      "Epoch 714/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5743 - val_loss: 0.6820 - val_accuracy: 0.5592\n",
      "Epoch 715/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5729 - val_loss: 0.6824 - val_accuracy: 0.5599\n",
      "Epoch 716/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5711 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 717/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5711 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 718/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5723 - val_loss: 0.6818 - val_accuracy: 0.5604\n",
      "Epoch 719/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5709 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 720/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5734 - val_loss: 0.6821 - val_accuracy: 0.5630\n",
      "Epoch 721/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5724 - val_loss: 0.6818 - val_accuracy: 0.5611\n",
      "Epoch 722/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5724 - val_loss: 0.6823 - val_accuracy: 0.5612\n",
      "Epoch 723/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5687 - val_loss: 0.6824 - val_accuracy: 0.5633\n",
      "Epoch 724/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5751 - val_loss: 0.6821 - val_accuracy: 0.5612\n",
      "Epoch 725/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5713 - val_loss: 0.6818 - val_accuracy: 0.5626\n",
      "Epoch 726/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5736 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 727/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5732 - val_loss: 0.6827 - val_accuracy: 0.5635\n",
      "Epoch 728/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5747 - val_loss: 0.6819 - val_accuracy: 0.5631\n",
      "Epoch 729/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5713 - val_loss: 0.6815 - val_accuracy: 0.5614\n",
      "Epoch 730/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5726 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 731/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5745 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 732/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5727 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 733/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5727 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 734/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5724 - val_loss: 0.6818 - val_accuracy: 0.5626\n",
      "Epoch 735/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5762 - val_loss: 0.6829 - val_accuracy: 0.5631\n",
      "Epoch 736/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5724 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 737/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5726 - val_loss: 0.6820 - val_accuracy: 0.5601\n",
      "Epoch 738/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.6816 - val_accuracy: 0.5600\n",
      "Epoch 739/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5766 - val_loss: 0.6828 - val_accuracy: 0.5619\n",
      "Epoch 740/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5701 - val_loss: 0.6830 - val_accuracy: 0.5612\n",
      "Epoch 741/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5721 - val_loss: 0.6819 - val_accuracy: 0.5601\n",
      "Epoch 742/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5705 - val_loss: 0.6822 - val_accuracy: 0.5604\n",
      "Epoch 743/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5742 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 744/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5675 - val_loss: 0.6820 - val_accuracy: 0.5612\n",
      "Epoch 745/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5744 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 746/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5742 - val_loss: 0.6818 - val_accuracy: 0.5605\n",
      "Epoch 747/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5751 - val_loss: 0.6820 - val_accuracy: 0.5604\n",
      "Epoch 748/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5742 - val_loss: 0.6829 - val_accuracy: 0.5602\n",
      "Epoch 749/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5752 - val_loss: 0.6820 - val_accuracy: 0.5596\n",
      "Epoch 750/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5678 - val_loss: 0.6823 - val_accuracy: 0.5609\n",
      "Epoch 751/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5694 - val_loss: 0.6822 - val_accuracy: 0.5609\n",
      "Epoch 752/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5695 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 753/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5714 - val_loss: 0.6825 - val_accuracy: 0.5594\n",
      "Epoch 754/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5698 - val_loss: 0.6820 - val_accuracy: 0.5611\n",
      "Epoch 755/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5783 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 756/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6765 - accuracy: 0.5765 - val_loss: 0.6817 - val_accuracy: 0.5617\n",
      "Epoch 757/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5706 - val_loss: 0.6823 - val_accuracy: 0.5608 0.6792 - accura\n",
      "Epoch 758/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5742 - val_loss: 0.6820 - val_accuracy: 0.5606\n",
      "Epoch 759/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5726 - val_loss: 0.6822 - val_accuracy: 0.5635\n",
      "Epoch 760/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5687 - val_loss: 0.6822 - val_accuracy: 0.5636\n",
      "Epoch 761/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5766 - val_loss: 0.6821 - val_accuracy: 0.5590\n",
      "Epoch 762/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5753 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 763/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5744 - val_loss: 0.6825 - val_accuracy: 0.5624\n",
      "Epoch 764/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5689 - val_loss: 0.6821 - val_accuracy: 0.5604\n",
      "Epoch 765/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5715 - val_loss: 0.6823 - val_accuracy: 0.5612\n",
      "Epoch 766/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5710 - val_loss: 0.6818 - val_accuracy: 0.5614\n",
      "Epoch 767/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5736 - val_loss: 0.6820 - val_accuracy: 0.5616\n",
      "Epoch 768/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5728 - val_loss: 0.6823 - val_accuracy: 0.5614\n",
      "Epoch 769/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5734 - val_loss: 0.6823 - val_accuracy: 0.5616\n",
      "Epoch 770/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5701 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 771/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5662 - val_loss: 0.6828 - val_accuracy: 0.5620\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5700 - val_loss: 0.6836 - val_accuracy: 0.5631\n",
      "Epoch 773/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5715 - val_loss: 0.6821 - val_accuracy: 0.5619\n",
      "Epoch 774/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5731 - val_loss: 0.6840 - val_accuracy: 0.5641\n",
      "Epoch 775/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5689 - val_loss: 0.6822 - val_accuracy: 0.5634\n",
      "Epoch 776/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5748 - val_loss: 0.6825 - val_accuracy: 0.5619 - ETA: 0s - loss: 0.6775 - \n",
      "Epoch 777/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5752 - val_loss: 0.6821 - val_accuracy: 0.5590\n",
      "Epoch 778/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.5737 - val_loss: 0.6819 - val_accuracy: 0.5616\n",
      "Epoch 779/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5798 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 780/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5736 - val_loss: 0.6817 - val_accuracy: 0.5624\n",
      "Epoch 781/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5688 - val_loss: 0.6824 - val_accuracy: 0.5611\n",
      "Epoch 782/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5708 - val_loss: 0.6820 - val_accuracy: 0.5609\n",
      "Epoch 783/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5723 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 784/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5759 - val_loss: 0.6818 - val_accuracy: 0.5617\n",
      "Epoch 785/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5764 - val_loss: 0.6862 - val_accuracy: 0.5439\n",
      "Epoch 786/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5715 - val_loss: 0.6825 - val_accuracy: 0.5610\n",
      "Epoch 787/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5722 - val_loss: 0.6823 - val_accuracy: 0.5601\n",
      "Epoch 788/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5696 - val_loss: 0.6913 - val_accuracy: 0.5584\n",
      "Epoch 789/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5691 - val_loss: 0.6829 - val_accuracy: 0.5604\n",
      "Epoch 790/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5725 - val_loss: 0.6820 - val_accuracy: 0.5611\n",
      "Epoch 791/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5725 - val_loss: 0.6832 - val_accuracy: 0.5630\n",
      "Epoch 792/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5722 - val_loss: 0.6823 - val_accuracy: 0.5605\n",
      "Epoch 793/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5713 - val_loss: 0.6822 - val_accuracy: 0.5616\n",
      "Epoch 794/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5707 - val_loss: 0.6822 - val_accuracy: 0.5617\n",
      "Epoch 795/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5701 - val_loss: 0.6820 - val_accuracy: 0.5627\n",
      "Epoch 796/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5751 - val_loss: 0.6829 - val_accuracy: 0.5606\n",
      "Epoch 797/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6810 - accuracy: 0.5699 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 798/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5692 - val_loss: 0.6827 - val_accuracy: 0.5612\n",
      "Epoch 799/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5749 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 800/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6797 - accuracy: 0.5694 - val_loss: 0.6837 - val_accuracy: 0.5611\n",
      "Epoch 801/1000\n",
      "1018/1018 [==============================] - 3s 3ms/step - loss: 0.6787 - accuracy: 0.5734 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 802/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5778 - val_loss: 0.6819 - val_accuracy: 0.5630\n",
      "Epoch 803/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5718 - val_loss: 0.6818 - val_accuracy: 0.5614\n",
      "Epoch 804/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5737 - val_loss: 0.6818 - val_accuracy: 0.5602\n",
      "Epoch 805/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5710 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 806/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5706 - val_loss: 0.6818 - val_accuracy: 0.5617\n",
      "Epoch 807/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5640 - val_loss: 0.6825 - val_accuracy: 0.5606\n",
      "Epoch 808/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5703 - val_loss: 0.6821 - val_accuracy: 0.5621\n",
      "Epoch 809/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5780 - val_loss: 0.6817 - val_accuracy: 0.5623\n",
      "Epoch 810/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5701 - val_loss: 0.6821 - val_accuracy: 0.5604\n",
      "Epoch 811/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5744 - val_loss: 0.6818 - val_accuracy: 0.5601\n",
      "Epoch 812/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5691 - val_loss: 0.6843 - val_accuracy: 0.5600\n",
      "Epoch 813/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5742 - val_loss: 0.6818 - val_accuracy: 0.5616\n",
      "Epoch 814/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5734 - val_loss: 0.6824 - val_accuracy: 0.5598\n",
      "Epoch 815/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5746 - val_loss: 0.6819 - val_accuracy: 0.5606accuracy: 0. - E\n",
      "Epoch 816/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5714 - val_loss: 0.6819 - val_accuracy: 0.5610\n",
      "Epoch 817/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5743 - val_loss: 0.6821 - val_accuracy: 0.5627\n",
      "Epoch 818/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5678 - val_loss: 0.6817 - val_accuracy: 0.5595\n",
      "Epoch 819/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5778 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 820/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5784 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 821/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5772 - val_loss: 0.6818 - val_accuracy: 0.5604\n",
      "Epoch 822/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5713 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 823/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5761 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 824/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5743 - val_loss: 0.6818 - val_accuracy: 0.5623\n",
      "Epoch 825/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5726 - val_loss: 0.6819 - val_accuracy: 0.5612TA: 0s - loss: 0.6791 - accuracy: 0.57\n",
      "Epoch 826/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5677 - val_loss: 0.6824 - val_accuracy: 0.5623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5765 - val_loss: 0.6822 - val_accuracy: 0.5630\n",
      "Epoch 828/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5752 - val_loss: 0.6823 - val_accuracy: 0.5624\n",
      "Epoch 829/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5730 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 830/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5735 - val_loss: 0.6827 - val_accuracy: 0.5599\n",
      "Epoch 831/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5709 - val_loss: 0.6818 - val_accuracy: 0.5639\n",
      "Epoch 832/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5696 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 833/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5703 - val_loss: 0.6820 - val_accuracy: 0.5601\n",
      "Epoch 834/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5735 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 835/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5686 - val_loss: 0.6828 - val_accuracy: 0.5617\n",
      "Epoch 836/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5707 - val_loss: 0.6821 - val_accuracy: 0.5631\n",
      "Epoch 837/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5706 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 838/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5707 - val_loss: 0.6818 - val_accuracy: 0.5600\n",
      "Epoch 839/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5753 - val_loss: 0.6818 - val_accuracy: 0.5625\n",
      "Epoch 840/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.5698 - val_loss: 0.6818 - val_accuracy: 0.5623\n",
      "Epoch 841/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5712 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 842/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5726 - val_loss: 0.6819 - val_accuracy: 0.5602\n",
      "Epoch 843/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5711 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 844/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5767 - val_loss: 0.6819 - val_accuracy: 0.5624\n",
      "Epoch 845/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5735 - val_loss: 0.6824 - val_accuracy: 0.5605\n",
      "Epoch 846/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5752 - val_loss: 0.6824 - val_accuracy: 0.5612\n",
      "Epoch 847/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5713 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 848/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5683 - val_loss: 0.6824 - val_accuracy: 0.5611\n",
      "Epoch 849/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5742 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 850/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5719 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 851/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5755 - val_loss: 0.6819 - val_accuracy: 0.5608\n",
      "Epoch 852/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5735 - val_loss: 0.6818 - val_accuracy: 0.5627\n",
      "Epoch 853/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6829 - val_accuracy: 0.5642\n",
      "Epoch 854/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5706 - val_loss: 0.6822 - val_accuracy: 0.5623\n",
      "Epoch 855/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5707 - val_loss: 0.6827 - val_accuracy: 0.5591\n",
      "Epoch 856/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5693 - val_loss: 0.6819 - val_accuracy: 0.5609\n",
      "Epoch 857/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5726 - val_loss: 0.6821 - val_accuracy: 0.5604\n",
      "Epoch 858/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6771 - accuracy: 0.5741 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 859/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5740 - val_loss: 0.6821 - val_accuracy: 0.5611\n",
      "Epoch 860/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5701 - val_loss: 0.6819 - val_accuracy: 0.5626\n",
      "Epoch 861/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5742 - val_loss: 0.6824 - val_accuracy: 0.5612\n",
      "Epoch 862/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5696 - val_loss: 0.6818 - val_accuracy: 0.5630\n",
      "Epoch 863/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5747 - val_loss: 0.6828 - val_accuracy: 0.5631\n",
      "Epoch 864/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5723 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 865/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5734 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 866/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5779 - val_loss: 0.6821 - val_accuracy: 0.5641\n",
      "Epoch 867/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5702 - val_loss: 0.6821 - val_accuracy: 0.5624\n",
      "Epoch 868/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5760 - val_loss: 0.6822 - val_accuracy: 0.5614\n",
      "Epoch 869/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5720 - val_loss: 0.6818 - val_accuracy: 0.5621\n",
      "Epoch 870/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5745 - val_loss: 0.6933 - val_accuracy: 0.5576\n",
      "Epoch 871/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5739 - val_loss: 0.6820 - val_accuracy: 0.5620\n",
      "Epoch 872/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5748 - val_loss: 0.6822 - val_accuracy: 0.5631\n",
      "Epoch 873/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5705 - val_loss: 0.6819 - val_accuracy: 0.5620\n",
      "Epoch 874/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5749 - val_loss: 0.6821 - val_accuracy: 0.5606\n",
      "Epoch 875/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5672 - val_loss: 0.6828 - val_accuracy: 0.5621\n",
      "Epoch 876/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5717 - val_loss: 0.6822 - val_accuracy: 0.5620\n",
      "Epoch 877/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5735 - val_loss: 0.6821 - val_accuracy: 0.5625\n",
      "Epoch 878/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5702 - val_loss: 0.6821 - val_accuracy: 0.5626\n",
      "Epoch 879/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5727 - val_loss: 0.6820 - val_accuracy: 0.5625\n",
      "Epoch 880/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5717 - val_loss: 0.6824 - val_accuracy: 0.5630\n",
      "Epoch 881/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5755 - val_loss: 0.6821 - val_accuracy: 0.5630\n",
      "Epoch 882/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6812 - accuracy: 0.5684 - val_loss: 0.6820 - val_accuracy: 0.5623\n",
      "Epoch 883/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6817 - accuracy: 0.5667 - val_loss: 0.6830 - val_accuracy: 0.5620\n",
      "Epoch 884/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5743 - val_loss: 0.6819 - val_accuracy: 0.5626\n",
      "Epoch 885/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5774 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 886/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5784 - val_loss: 0.6819 - val_accuracy: 0.5625\n",
      "Epoch 887/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5718 - val_loss: 0.6823 - val_accuracy: 0.5615\n",
      "Epoch 888/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5739 - val_loss: 0.6824 - val_accuracy: 0.5600\n",
      "Epoch 889/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5763 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 890/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5730 - val_loss: 0.6820 - val_accuracy: 0.5610\n",
      "Epoch 891/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5774 - val_loss: 0.6825 - val_accuracy: 0.5601\n",
      "Epoch 892/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5714 - val_loss: 0.6828 - val_accuracy: 0.5598\n",
      "Epoch 893/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5734 - val_loss: 0.6824 - val_accuracy: 0.5615\n",
      "Epoch 894/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5712 - val_loss: 0.6820 - val_accuracy: 0.5599\n",
      "Epoch 895/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5755 - val_loss: 0.6821 - val_accuracy: 0.5625\n",
      "Epoch 896/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5794 - val_loss: 0.6820 - val_accuracy: 0.5633\n",
      "Epoch 897/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5691 - val_loss: 0.6818 - val_accuracy: 0.5620\n",
      "Epoch 898/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5724 - val_loss: 0.6820 - val_accuracy: 0.5606\n",
      "Epoch 899/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5729 - val_loss: 0.6821 - val_accuracy: 0.5614\n",
      "Epoch 900/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5718 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 901/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5694 - val_loss: 0.6819 - val_accuracy: 0.5606\n",
      "Epoch 902/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5724 - val_loss: 0.6826 - val_accuracy: 0.5608\n",
      "Epoch 903/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5739 - val_loss: 0.6819 - val_accuracy: 0.5634\n",
      "Epoch 904/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5751 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 905/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5740 - val_loss: 0.6819 - val_accuracy: 0.5627\n",
      "Epoch 906/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5754 - val_loss: 0.6835 - val_accuracy: 0.5610\n",
      "Epoch 907/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5718 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 908/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5778 - val_loss: 0.6820 - val_accuracy: 0.5619\n",
      "Epoch 909/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5731 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 910/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5717 - val_loss: 0.6825 - val_accuracy: 0.5617\n",
      "Epoch 911/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5703 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 912/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5700 - val_loss: 0.6820 - val_accuracy: 0.5629\n",
      "Epoch 913/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5716 - val_loss: 0.6818 - val_accuracy: 0.5608\n",
      "Epoch 914/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5711 - val_loss: 0.6835 - val_accuracy: 0.5612\n",
      "Epoch 915/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5775 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 916/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5751 - val_loss: 0.6824 - val_accuracy: 0.5599\n",
      "Epoch 917/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5700 - val_loss: 0.6822 - val_accuracy: 0.5627\n",
      "Epoch 918/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5697 - val_loss: 0.6820 - val_accuracy: 0.5620\n",
      "Epoch 919/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5766 - val_loss: 0.6820 - val_accuracy: 0.5620\n",
      "Epoch 920/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5701 - val_loss: 0.6819 - val_accuracy: 0.5610\n",
      "Epoch 921/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.5740 - val_loss: 0.6819 - val_accuracy: 0.5614\n",
      "Epoch 922/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5718 - val_loss: 0.6819 - val_accuracy: 0.5635\n",
      "Epoch 923/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5741 - val_loss: 0.6830 - val_accuracy: 0.5616\n",
      "Epoch 924/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5745 - val_loss: 0.6819 - val_accuracy: 0.5621\n",
      "Epoch 925/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5708 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 926/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5752 - val_loss: 0.6821 - val_accuracy: 0.5620\n",
      "Epoch 927/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5712 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 928/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5707 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 929/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.5794 - val_loss: 0.6823 - val_accuracy: 0.5615\n",
      "Epoch 930/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6797 - accuracy: 0.5729 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 931/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5728 - val_loss: 0.6822 - val_accuracy: 0.5612\n",
      "Epoch 932/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5673 - val_loss: 0.6819 - val_accuracy: 0.5605\n",
      "Epoch 933/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5688 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 934/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5746 - val_loss: 0.6819 - val_accuracy: 0.5602\n",
      "Epoch 935/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5708 - val_loss: 0.6828 - val_accuracy: 0.5604\n",
      "Epoch 936/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6819 - accuracy: 0.5672 - val_loss: 0.6819 - val_accuracy: 0.5619\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5696 - val_loss: 0.6822 - val_accuracy: 0.5606\n",
      "Epoch 938/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5712 - val_loss: 0.6822 - val_accuracy: 0.5624\n",
      "Epoch 939/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5745 - val_loss: 0.6819 - val_accuracy: 0.5624\n",
      "Epoch 940/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5747 - val_loss: 0.6823 - val_accuracy: 0.5605\n",
      "Epoch 941/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5755 - val_loss: 0.6818 - val_accuracy: 0.5619\n",
      "Epoch 942/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5741 - val_loss: 0.6817 - val_accuracy: 0.5640: 0.\n",
      "Epoch 943/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5724 - val_loss: 0.6826 - val_accuracy: 0.5612\n",
      "Epoch 944/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5741 - val_loss: 0.6822 - val_accuracy: 0.5608\n",
      "Epoch 945/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5764 - val_loss: 0.6821 - val_accuracy: 0.5602\n",
      "Epoch 946/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5770 - val_loss: 0.6822 - val_accuracy: 0.5610\n",
      "Epoch 947/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5714 - val_loss: 0.6818 - val_accuracy: 0.5623\n",
      "Epoch 948/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5727 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 949/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5666 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 950/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5723 - val_loss: 0.6822 - val_accuracy: 0.5626\n",
      "Epoch 951/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5737 - val_loss: 0.6826 - val_accuracy: 0.5636\n",
      "Epoch 952/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5716 - val_loss: 0.6819 - val_accuracy: 0.5612\n",
      "Epoch 953/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5747 - val_loss: 0.6820 - val_accuracy: 0.5630\n",
      "Epoch 954/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5748 - val_loss: 0.6820 - val_accuracy: 0.5638\n",
      "Epoch 955/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5693 - val_loss: 0.6827 - val_accuracy: 0.5616\n",
      "Epoch 956/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5751 - val_loss: 0.6819 - val_accuracy: 0.5623\n",
      "Epoch 957/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5770 - val_loss: 0.6821 - val_accuracy: 0.5608\n",
      "Epoch 958/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5714 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 959/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5679 - val_loss: 0.6820 - val_accuracy: 0.5617\n",
      "Epoch 960/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5736 - val_loss: 0.6819 - val_accuracy: 0.5610\n",
      "Epoch 961/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5721 - val_loss: 0.6822 - val_accuracy: 0.5599\n",
      "Epoch 962/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5739 - val_loss: 0.6821 - val_accuracy: 0.5617\n",
      "Epoch 963/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5717 - val_loss: 0.6818 - val_accuracy: 0.5624\n",
      "Epoch 964/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5727 - val_loss: 0.6820 - val_accuracy: 0.5627\n",
      "Epoch 965/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5676 - val_loss: 0.6823 - val_accuracy: 0.5633\n",
      "Epoch 966/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5711 - val_loss: 0.6821 - val_accuracy: 0.5610\n",
      "Epoch 967/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5738 - val_loss: 0.6827 - val_accuracy: 0.5634\n",
      "Epoch 968/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5708 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 969/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5729 - val_loss: 0.6824 - val_accuracy: 0.5615\n",
      "Epoch 970/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5729 - val_loss: 0.6816 - val_accuracy: 0.5641\n",
      "Epoch 971/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5681 - val_loss: 0.6821 - val_accuracy: 0.5600\n",
      "Epoch 972/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6801 - accuracy: 0.5695 - val_loss: 0.6820 - val_accuracy: 0.5614\n",
      "Epoch 973/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5749 - val_loss: 0.6825 - val_accuracy: 0.5621\n",
      "Epoch 974/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5772 - val_loss: 0.6821 - val_accuracy: 0.5617\n",
      "Epoch 975/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5714 - val_loss: 0.6819 - val_accuracy: 0.5606\n",
      "Epoch 976/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6815 - accuracy: 0.5674 - val_loss: 0.6821 - val_accuracy: 0.5617\n",
      "Epoch 977/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5689 - val_loss: 0.6824 - val_accuracy: 0.5612\n",
      "Epoch 978/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5665 - val_loss: 0.6825 - val_accuracy: 0.5630\n",
      "Epoch 979/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5754 - val_loss: 0.6823 - val_accuracy: 0.5614\n",
      "Epoch 980/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5753 - val_loss: 0.6819 - val_accuracy: 0.5611\n",
      "Epoch 981/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6794 - accuracy: 0.5742 - val_loss: 0.6834 - val_accuracy: 0.5620\n",
      "Epoch 982/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5706 - val_loss: 0.6824 - val_accuracy: 0.5626\n",
      "Epoch 983/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5691 - val_loss: 0.6821 - val_accuracy: 0.5611\n",
      "Epoch 984/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.5706 - val_loss: 0.6820 - val_accuracy: 0.5608\n",
      "Epoch 985/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5750 - val_loss: 0.6823 - val_accuracy: 0.5631\n",
      "Epoch 986/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5696 - val_loss: 0.6820 - val_accuracy: 0.5633\n",
      "Epoch 987/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.5703 - val_loss: 0.6824 - val_accuracy: 0.5606\n",
      "Epoch 988/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5744 - val_loss: 0.6840 - val_accuracy: 0.5629\n",
      "Epoch 989/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5735 - val_loss: 0.6819 - val_accuracy: 0.5626\n",
      "Epoch 990/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5745 - val_loss: 0.6819 - val_accuracy: 0.5595\n",
      "Epoch 991/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6803 - accuracy: 0.5691 - val_loss: 0.6823 - val_accuracy: 0.5626\n",
      "Epoch 992/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5738 - val_loss: 0.6818 - val_accuracy: 0.5612\n",
      "Epoch 993/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5729 - val_loss: 0.6819 - val_accuracy: 0.5629\n",
      "Epoch 994/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5717 - val_loss: 0.6819 - val_accuracy: 0.56150s - loss: 0.6792 \n",
      "Epoch 995/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5763 - val_loss: 0.6824 - val_accuracy: 0.5611\n",
      "Epoch 996/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5748 - val_loss: 0.6818 - val_accuracy: 0.5612\n",
      "Epoch 997/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5727 - val_loss: 0.6819 - val_accuracy: 0.5602\n",
      "Epoch 998/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5752 - val_loss: 0.6820 - val_accuracy: 0.5624\n",
      "Epoch 999/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5745 - val_loss: 0.6821 - val_accuracy: 0.5609\n",
      "Epoch 1000/1000\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.6817 - val_accuracy: 0.5621\n",
      "Train error: 0.42743051052093506\n",
      "Test error:  0.437874972820282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelInter = tf.keras.Sequential([\n",
    "        keras.layers.Dense(units=np.shape(trainX)[1], activation='linear'),\n",
    "        keras.layers.Dense(units=75, activation='linear'),\n",
    "        keras.layers.Dense(units=75, activation='linear'),\n",
    "        keras.layers.Dense(units=50, activation='linear'),\n",
    "        keras.layers.Dense(units=50, activation='linear'),\n",
    "        keras.layers.Dense(units=25, activation='linear'),\n",
    "        keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "epochs = 1000\n",
    "eIn, eOut = runModel(trainX, trainY, valX, valY, modelInter, epochs)\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "ax.plot(eIn,'-b')\n",
    "ax.plot(eOut,'-r')\n",
    "ax.set_xlabel('Epoch #')\n",
    "ax.set_ylabel('Error')\n",
    "ax.grid()\n",
    "ax.legend(['eIn', 'eOut'])\n",
    "ax.axes.set_xlim([0,epochs])\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "certified-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5631250143051147"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - eOut[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
